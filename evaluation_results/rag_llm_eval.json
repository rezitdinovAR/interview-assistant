{
  "timestamp": "2025-12-25T19:29:31.453552",
  "total_samples": 30,
  "metrics": {
    "faithfulness": 0.5725228033722735,
    "answer_relevancy": 0.7888877139665318,
    "context_precision": 0.2501526251370574,
    "context_recall": 0.2782569920500955
  },
  "samples": [
    {
      "index": 1,
      "question": "Опишите жадный алгоритм по построению решающих деревьев?",
      "ground_truth": "Алгоритм:\r\nНачинаем с корня — берём весь обучающий датасет\r\nВыбираем лучший признак и значение для сплита (критерия ветвления)\r\nРазбиваем данные на две части по этому сплиту\r\nПовторяем шаги для каждой части — рекурсивно строим поддеревья\r\nОстанавливаемся, если выполнен критерий остановки; тогда вершина становится листом\r\nКритерии ветвления:\r\ngini или entropy - классификация\r\nmse или mae - регрессия\r\nКритерий остановки:\r\nдостигнута максимальная глубина\r\nв узле мало или много объектов\r\nприрост информации от нового сплита слишком мал",
      "model_answer": "На основе предоставленного контекста, жадный алгоритм построения решающих деревьев — это итеративный процесс, который на каждом шаге выбирает наилучшее (локально оптимальное) разбиение данных в текущем узле по выбранному критерию качества, не учитывая глобальную оптимальность итогового дерева.\n\n**Этапы жадного алгоритма, описанные в контексте:**\n\n1.  **Выбор признака и порога:** На каждом узле алгоритм перебирает все возможные признаки и пороги разбиения, чтобы найти те, которые максимизируют выигрыш в \"информативности\" или минимизируют \"хаотичность\" (например, снижают критерий Джини, энтропию или среднеквадратичную ошибку). Формально, для узла `R` ищется разбиение, которое максимизирует:\n    `|R|⋅S(R) − |R_right|⋅S(R_right) − |R_left|⋅S(R_left) → max`,\n    где `S(R)` — значение оценочной функции (например, дисперсия для регрессии или критерий Джини для классификации) в узле, а `|⋅|` — количество объектов.\n\n2.  **Критерии качества (информативности):** Контекст упоминает несколько критериев, которые используются для оценки качества разбиения:\n    *   **Для классификации:** Критерий Джини (`H(X_m) = Σ p_k (1 - p_k)`) или энтропия (`H(X_m) = - Σ p_k log p_k`), где `p_k` — доля объектов класса `k` в узле.\n    *   **Для регрессии:** Часто используется среднеквадратичная ошибка (MSE, `L2`).\n\n3.  **Работа с признаками:**\n    *   **Вещественные признаки:** Перебираются пороги, упорядочивающие значения признака.\n    *   **Категориальные признаки:** Для избежания полного перебора всех подмножеств категорий (`2^(M-1)` вариантов) используется эвристика упорядочивания. Например, для бинарной классификации категории упорядочиваются по возрастанию доли положительного класса, а для регрессии с MSE — по среднему значению целевой переменной. После упорядочивания с ними работают как с вещественными, что позволяет найти оптимальный сплит за линейное время.\n\n**Итог и ограничения алгоритма:**\nПризнак и порог разбиения выбираются так, чтобы наилучшим образом (с точки зрения выбранного критерия) разделить данные, делая дочерние узлы максимально однородными. Однако, как отмечено в контексте, этот жадный подход **не гарантирует построения глобально оптимального дерева** (пример — задача XOR, которую жадный алгоритм не может решить оптимально). Также бывают ситуации, когда критерий, оптимальный для одной метрики (например, MSE), не приводит к оптимальному дереву для другой (например, MAE).",
      "contexts": [
        "L до первого члена в окрестности точки k−1 (x i )): L(y i ,a k−1 (x i )+b(x i ))≈L(y i ,a k−1 (x i ))+b(x i ) ∂z ∂L(y i ,z) z=a k−1 (x i ) =L(y i ,a k−1 (x i ))+b(x i )g i k−1 Избавившись от постоянных членов, мы получим следующую оптимизационную задачу: b k ≈ argminb∈B b∈B argmin i=1 ∑ N b(x i )g i k−1 Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют b ( x i ) b(x i ), пропорциональные значениям k−1 . Поэтому на каждой итерации базовые алгоритмы b k b k обучаются предсказывать значения антиградиента функции потерь по текущим предсказаниям композиции. Итак, использованная нами интуиция шага в сторону «уменьшения остатка» удивительным образом привела к оптимальным смещениям в случае квадратичной функции потерь, но для других функций потерь это не так: для них смещение происходит в сторону антиградиента. Получается, что в общем случае на каждой итерации базовые алгоритмы должны приближать значения антиградиента функции потерь. Однако есть частный случай, в котором в качестве таргета для базового алгоритма выгоднее использовать именно «остатки» — это касается функции потерь MAE. Её производная равна -1, 0 или +1. Приближая базовым алгоритмом антиградиент MAE, количество итераций до сходимости будет расти пропорционально масштабу таргета. То есть, если домножить целевое значение на 10, то потребуется в 10 раз больше итераций градиентного бустинга. Использование остатков в качестве таргета для базового алгоритма не имеет такой проблемы. Аналогичные рассуждения верны также для функции MAPE, в которой проблема с масштабом таргета может проявляться еще сильнее. Обучение базового алгоритма При построении очередного базового алгоритма b k + 1 b k+1 мы решаем задачу регрессии с таргетом, равным антиградиенту функции потерь исходной задачи на предсказании +…+b k . Теоретически можно воспользоваться любым методом построения регрессионного дерева. Важно выбрать оценочную функцию S S, которая будет показывать, насколько текущая структура дерева хорошо приближает антиградиент. Её нужно будет использовать для построения критерия ветвления: max ⁡ , ∣R∣⋅S(R)−∣R right ∣⋅S(R right )−∣R left ∣⋅S(R left )→max, где S ( R ) S(R) — значение функции S S в вершине S(R left ),S(R right ) — значения в левом и правом сыновьях R R после добавления предиката, ∣ ⋅ ∣ ∣⋅∣ — количество элементов, пришедших в вершину. Например, можно использовать следующие оценочные функции: (g,p)= i=1 Cosine(g,p)=− i=1 i=1 ∑ N g i 2 i=1 где p i p i — предсказание дерева на объекте — антиградиент, на который учится дерево, p=p i i=1 g=g i N . Функция L 2 L 2 представляет собой среднеквадратичную ошибку, а функция Cosine определяет близость через косинусное расстояние между векторами предсказаний и антиградиентов. В итоге обучение базового алгоритма проходит в два шага: по функции потерь вычисляется целевая переменная для обучения следующего базового алгоритма: ∂L(y i ,z) z=a k (x i ) строится регрессионное дерево на обучающей выборке ,−g i k ), минимизирующее выбранную оценочную функцию. На практике Поскольку для построения градиентного бустинга достаточно уметь считать градиент функции потерь по предсказаниям, с его помощью можно решать широкий спектр задач. В библиотеках градиентного",
        "Вопрос: * Выбирается тот признак и порог, которые дают наибольшее уменьшение хаотичности (например, снижение критерия Джини или энтропии).\n  ",
        "Итог:\nПризнак и порог разбиения выбираются так, чтобы наилучшим образом разделить данные, делая узлы максимально однородными.\n         * ",
        "Что такое жадный алгоритм построения дерева?\nОтвет: Жадный алгоритм строит дерево решений шаг за шагом, выбирая на каждом этапе лучшее разбиение по текущему критерию качества.\nЭтапы жадного алгоритма:",
        "Вопрос: * Деревья в градиентном бустинге обычно короче, поэтому предсказания делаются быстрее.",
        "Градиентный бустинг\nКак работает градиентный бустинг?\nОтвет: Градиентный бустинг обучается последовательным исправлением ошибок предыдущих моделей с использованием остаточной ошибки (антиградиента) в качестве целевой переменной.\nЭтапы:",
        "в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба». Поиск ближайших соседей: точные методы Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие эвристики хоть и могут давать некоторый выигрыш по времени, но не улучшат асимптотическую сложность. Второй — k-d-деревья, о которых стоит поговорить подробнее. K-d-деревья Представим на секунду, что у нас есть всего лишь один признак, то есть объекты выражаются вещественными числами, а не векторами. В этом случае для поиска ближайшего соседа напрашивается всем вам известное бинарное дерево поиска, которое позволяет находить элементы за логарифмическое время. Оказывается, существует аналог данной структуры в многомерном пространстве, который называется k-d-дерево (k-d tree, сокращение от k-dimensional tree). Как и в обычном дереве поиска, в k-d-дереве каждый узел является объектом обучающей выборки, который особым образом делит пространство на два полупространства. Таким образом, всё пространство оказывается поделено на множество малых областей, и такое деление оказывается очень полезным при поиске ближайших соседей. Рассмотрим подробнее, как строится такое дерево. Трудность в применении обычного дерева поиска состоит в том, что мы не можем напрямую сравнить два вектора так же, как два вещественных числа. Чтобы эту проблему преодолеть, узлы дерева будут делить пространство лишь по одной оси. При движении вниз по дереву оси, по которым точки делят пространство, циклически сменяют друг друга. Например, в двумерном пространстве корень будет отвечать за деление по x-координате, его сыновья — за деление по y-координате, а внуки — снова за x-координату, и т. д. Посмотрим, как это работает на примере: Источник На картинке выше корень ( 30 , 40 ) (30,40) делит все точки по оси х: слева оказываются точки, у которых x < 30 x<30, а справа — те, у которых x ⩾ 30 x⩾30. Аналогично левый сын корня ( 5 , 25 ) (5,25) делит своё поддерево по оси y: слева оказываются точки, у которых y < 25 y<25, а справа — те, у которых y ⩾ 25 y⩾25. Остаётся вопрос — как выбирать точки, которые будут делить пространство пополам? Чтобы дерево было сбалансированным, нужно находить точку с медианой, соответствующей уровню поддерева координаты. На практике часто ограничиваются выбором случайной точки или любой эвристикой по приближённому поиску медианы (например, медиана некоторого подмножества точек). Это позволяет ускорить построение дерева, но убирает все гарантии на его сбалансированность. Добавлять новые точки можно так же, как и в одномерном дереве поиска. Спускаясь по дереву, можно однозначно определить лист, к которому нужно подвесить новую точку, чтобы не нарушить все свойства дерева. При добавлении большого количества точек, однако, дерево может перестать быть сбалансированным, и нужно проводить ребалансировку. Также существуют варианты k-d-деревьев, которые сохраняют сбалансированность при добавлении / удалении точек. Поговорим теперь про",
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа"
      ]
    },
    {
      "index": 2,
      "question": "В чём разница между классификацией и регрессией в деревьях?",
      "ground_truth": "Классификация:\r\nпредсказываем метки классов\r\nИспользуем gini или энтропию\r\nсамый популярный класс по объектам в листе (мода)\r\nРегрессия:\r\nпредсказываем числовое значение\r\nОптимизируем mse/mae во время сплита\r\nИспользуем среднее / медиану в листе как предсказание",
      "model_answer": "На основе предоставленного контекста, разница между классификацией и регрессией в деревьях решений заключается в типе предсказываемого значения (таргета) и, как следствие, в критериях, используемых для построения дерева и формирования прогнозов в листьях.\n\n### Ключевые различия:\n\n1.  **Тип предсказания (таргета):**\n    *   **Классификация:** Множество возможных ответов `Y` — это конечный набор классов. В контексте упоминаются:\n        *   **Бинарная классификация:** `Y = {0, 1}` (например, есть ли на картинке банан).\n        *   **Многоклассовая классификация:** `Y = {1, …, K}` (например, определение предметной области статьи).\n    *   **Регрессия:** Множество возможных ответов `Y` — это вещественные числа (`Y = R`) или вектор вещественных чисел (`Y = R^M`). Примеры: предсказание продолжительности поездки, спроса на товар или погоды (температура, влажность).\n\n2.  **Прогноз в листьях дерева:**\n    *   **Классификация:** Лист дерева содержит прогноз **класса**. В контексте это описывается как предсказание распределения вероятностей классов `(c_1, …, c_K)`, где оптимальным прогнозом являются выборочные оценки частот классов `(p_1, …, p_K)` в данном листе.\n    *   **Регрессия:** Лист дерева содержит **числовое значение** (или вектор). В контексте для задачи регрессии с функцией потерь MSE (среднеквадратичная ошибка) оптимальным прогнозом в листе будет **среднее значение таргета** объектов, попавших в этот лист.\n\n3.  **Критерии для выбора разбиения (сплита):**\n    Для выбора наилучшего признака и порога разбиения в узле используются разные меры \"информативности\" (или хаотичности), которые минимизируются.\n    *   **Для классификации** в контексте упоминаются:\n        *   **Критерий Джини:** `H(X_m) = Σ p_k * (1 - p_k)`. Интерпретируется как математическое ожидание числа ошибок при случайном присваивании меток.\n        *   **Энтропийный критерий (информационный выигрыш):** `H(X_m) = - Σ p_k * log(p_k)`.\n    *   **Для регрессии** (с функцией потерь MSE) оптимальным критерием является минимизация **среднеквадратичной ошибки (MSE)**. В контексте также упоминается, что для категориальных признаков в задаче регрессии значения можно упорядочивать по **среднему значению таргета** для нахождения оптимального сплита.\n\n### Общее в построении деревьев:\nНесмотря на различия, общий алгоритм построения дерева для обеих задач жадный и рекурсивный:\n1.  Выбирается признак и порог разбиения, которые наилучшим образом (согласно критерию для задачи) разделяют данные в текущем узле.\n2.  Данные разделяются на два подмножества.\n3.  Процесс повторяется для каждого подмножества, пока не будет выполнено условие остановки (например, достигнута максимальная глубина или в листе мало объектов).\n4.  В **листьях** формируется итоговый прогноз: **класс (или распределение вероятностей)** для классификации или **числовое значение (чаще всего среднее)** для регрессии.\n\n**Итог:** Деревья решений — универсальный алгоритм, который может решать как задачи классификации (предсказывая метки класса), так и задачи регрессии (предсказывая числа). Адаптация происходит через изменение целевой переменной (таргета), критерия оптимизации при построении дерева и правила формирования конечного прогноза в листьях.",
      "contexts": [
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,",
        "20. Возьмём также бэггинг над 10 решающими деревьями глубины 7 в качестве базовых классификаторов и тоже 100 раз обучим его на случайных выборках размера 20. Если изобразить предсказания обученных моделей на каждой из 100 итераций, то можно увидеть примерно такую картину: 4 По этому рисунку видно, что общая дисперсия предсказаний в зависимости от обучающего множества у бэггинга значительно ниже, чем у отдельных деревьев, а в среднем предсказания деревьев и бэггинга не отличаются. Чтобы подтвердить это наблюдение, мы можем изобразить смещение и разброс случайных деревьев и бэггинга в зависимости от максимальной глубины: 4 На графике видно, как значительно бэггинг сократил дисперсию. На самом деле, дисперсия уменьшилась практически в 10 раз, что равняется числу базовых алгоритмов ( k k), которые бэггинг использовал для предсказания: 4 Код для отрисовки картинок и подсчёта смещения и разброса можно найти тут. Random Forest В предыдущем разделе мы сделали предположение, что базовые алгоритмы некоррелированы, и за счёт этого получили очень сильное уменьшение дисперсии у ансамбля относительно входящих в него базовых алгоритмов. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках. Поэтому будет странно, если корреляция на самом деле нулевая. Но на практике оказывается, что строгое выполнение этого предположения не обязательно. Достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга. На этом строится развитие идеи бэггинга для решающих деревьев — случайный лес. Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. Будем строить по следующей схеме: Для построения i i-го дерева: Сначала, как в обычном бэггинге, из обучающей выборки X X выбирается с возвращением случайная подвыборка X i X i того же размера, что и X X. В процессе обучения каждого дерева в каждой вершине случайно выбираются n < N n<N признаков, где N N — полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации). Profit. Мы построили Random Forest (случайный лес) — комбинацию бэггинга и метода случайных подпространств над решающими деревьями. Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее. Какая должна быть глубина деревьев в случайном лесу? Ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. Разброс мы уменьшаем с помощью процедуры бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость. Поэтому при изменении обучающей подвыборки предсказание на тестовом объекте будет стабильным, но не точным (низкая дисперсия, высокое смещение). Наоборот, у глубоких деревьев нет проблем запомнить подвыборку подробно. Поэтому предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко",
        "Вопрос: Деревья\n  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "Определение порогов для категориальных и числовых признаков\nhttps://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e\n  \n  ",
        "Что такое дерево решений, и как оно работает?\nОтвет: Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.\nКаждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).\nПример:\nВ медицинской задаче:\n         * Вершина 1: \"Возраст > 40 лет?\"\n         * Да → Вершина 2: \"Курит?\"\n         * Нет → Прогноз: \"Низкий риск заболевания\".\n         * Вершина 2:\n         * Да → Прогноз: \"Высокий риск заболевания\".\n         * Нет → Прогноз: \"Средний риск заболевания\".\n  ",
        "  ",
        "Как строится дерево решений?\nВыбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:",
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа",
        "и весах w w. Оно имеет вид p(y∣X,w)= i ∏ p(y i ∣x i ,w) и для распределения Бернулли его можно выписать следующим образом: p(y∣X,w)= (1−p i ) 1−y i где p i p i – это вероятность, посчитанная из ответов модели. Оптимизировать произведение неудобно, хочется иметь дело с суммой, так что мы перейдём к логарифмическому правдоподобию и подставим формулу для вероятности, которую мы получили выше: log log ℓ(w,X,y)= i ∑ (y i log(p i )+(1−y i )log(1−p i ))= log log log(σ(⟨w,x i ⟩))+(1−y i )log(1−σ(⟨w,x i ⟩))) Если заметить, что σ(−z)= 1+e =1−σ(z), то выражение можно переписать проще: log log ℓ(w,X,y)= i ∑ (y i log(σ(⟨w,x i ⟩))+(1−y i )log(σ(−⟨w,x i ⟩))) Нас интересует w w, для которого правдоподобие максимально. Чтобы получить функцию потерь, которую мы будем минимизировать, умножим его на минус один: log log L(w,X,y)=− i ∑ (y i log(σ(⟨w,x i ⟩))+(1−y i )log(σ(−⟨w,x i ⟩))) В отличие от линейной регрессии, для логистической нет явной формулы решения. Деваться некуда, будем использовать градиентный спуск. К счастью, градиент устроен очень просто: L(y,X,w)=− −σ(⟨w,x i ⟩)) Предсказание модели будет вычисляться, как мы договаривались, следующим образом: p=σ(⟨w,x i ⟩) Это вероятность положительного класса, а как от неё перейти к предсказанию самого класса? В других методах нам достаточно было посчитать знак предсказания, но теперь все наши предсказания положительные и находятся в диапазоне от 0 до 1. Что же делать? Интуитивным и не совсем (и даже совсем не) правильным является ответ «взять порог 0.5». Более корректным будет подобрать этот порог отдельно, для уже построенной регрессии минимизируя нужную вам метрику на отложенной тестовой выборке. Например, сделать так, чтобы доля положительных и отрицательных классов примерно совпадала с реальной. Отдельно заметим, что метод называется логистической регрессией, а не логистической классификацией именно потому, что предсказываем мы не классы, а вещественные числа – логиты. Вопрос на подумать. Проверьте, что, если метки классов – это ± 1 ±1, а не 0 0 и 1 1, то функцию потерь для логистической регрессии можно записать в более компактном виде: log L(w,X,y)= i=1 ∑ N log(1+e −y i ⟨w,x i ⟩ ) Вопрос на подумать. Правда ли разделяющая поверхность модели логистической регрессии является гиперплоскостью? Вопрос на подумать. Допустим, что матрица объекты-признаки X X имеет полный ранг по столбцам (то есть все её столбцы линейно независимы). Верно ли, что решение задачи восстановления логистической регрессии единственно? Вопрос на подумать. На картинке ниже представлены результаты работы на одном и том же датасете трёх моделей логистической регрессии с разными коэффициентами L 2 L 2 -регуляризации: 1 Наверху показаны предсказанные вероятности положительного класса, внизу – вид разделяющей поверхности. Как вам кажется, какие картинки соответствуют самому большому коэффициенту регуляризации, а какие – самому маленькому? Почему? Многоклассовая классификация В этом разделе мы будем следовать изложению из лекций Евгения Соколова. Пусть каждый объект нашей выборки относится к одному из K K классов: Y={1,…,K}. Чтобы предсказывать эти классы с помощью линейных моделей, нам придётся свести задачу многоклассовой классификации к набору бинарных, которые мы уже хорошо умеем решать. Мы разберём два самых популярных способа это сделать – one-vs-all и all-vs-all, а проиллюстрировать"
      ]
    },
    {
      "index": 3,
      "question": "Как оценить важность признаков по дереву?",
      "ground_truth": "Обычно важность признака измеряется как суммарное снижение impurity (Gini или энтропии), которое произошло благодаря разбиениям по этому признаку, по всем уровням дерева.\r\nВ ансамблях деревьев (например, в Random Forest) эти значения усредняются по всем деревьям.",
      "model_answer": "На основе предоставленного контекста можно выделить несколько ключевых принципов оценки важности признаков в решающих деревьях и ансамблях (например, Random Forest), хотя прямой формулы в тексте не приведено. Вот основные подходы, следующие из контекста:\n\n1.  **Критерии информативности при построении дерева:** В контексте подробно описаны критерии, используемые для выбора признаков и точек разбиения в узлах дерева (сплитов). К ним относятся:\n    *   **Энтропия (информационный выигрыш):** `H(X_m) = -∑ p_k log p_k`\n    *   **Критерий Джини:** `H(X_m) = ∑ p_k (1 - p_k)`\n    *   **MSE (для регрессии):** Упоминается минимизация суммы квадратов ошибок.\n    Важность признака логически вытекает из того, насколько его использование для разбиения уменьшает значение выбранного критерия неопределенности (энтропии, Джини, MSE) во всем дереве.\n\n2.  **Алгоритм оценки важности в ансамблях (Random Forest):** Контекст описывает Random Forest как комбинацию бэггинга и **метода случайных подпространств**. Это ключ к пониманию одной из распространенных методик оценки важности:\n    *   В процессе обучения каждого дерева **в каждой вершине случайно выбирается подмножество признаков** (`n < N`), и среди них ищется оптимальный сплит.\n    *   Из этого следует, что признак, который consistently выбирается для лучшего разбиения среди случайного набора кандидатов и значительно уменьшает неопределенность, является важным.\n    *   **Общая идея:** Важность признака в ансамбле можно агрегировать (например, усреднить) по всем деревьям, измеряя, насколько его использование улучшает критерий качества (снижает Джини/энтропию или MSE) во всех узлах, где он был использован. Часто также учитывают долю выборки, на которую влияет это разбиение.\n\n3.  **Интерпретация критерия Джини:** Контекст дает полезную интерпретацию, которая помогает понять, что измеряет важность на основе Джини:\n    *   `H(X_m)` (критерий Джини) равен **математическому ожиданию числа ошибок классификации**, если присваивать метки случайно согласно распределению классов в узле.\n    *   Следовательно, уменьшение этого значения при разбиении признаком напрямую связано с ожидаемым снижением ошибки классификации, что является мерой важности признака.\n\n**Итоговый ответ, основанный на контексте:**\n\nВажность признаков в решающем дереве (и в ансамбле, таком как Random Forest) оценивается на основе того, насколько эффективно этот признак снижает неопределенность (разбивает данные) при построении модели. Основные метрики для этого — **критерий Джини** или **энтропия** (информационный выигрыш). В ансамбле, построенном по принципу Random Forest (где в каждом узле дерева выбирается случайное подмножество признаков для поиска лучшего разбиения), важность признака агрегируется по всем деревьям. Чаще всего она вычисляется как суммарное уменьшение выбранного критерия неопределенности (например, индекса Джини) во всех узлах, где использовался данный признак, взвешенное по количеству образцов в этих узлах. Признак, который часто и эффективно используется для создания «чистых» дочерних узлов, получает высокую оценку важности.",
      "contexts": [
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа",
        "20. Возьмём также бэггинг над 10 решающими деревьями глубины 7 в качестве базовых классификаторов и тоже 100 раз обучим его на случайных выборках размера 20. Если изобразить предсказания обученных моделей на каждой из 100 итераций, то можно увидеть примерно такую картину: 4 По этому рисунку видно, что общая дисперсия предсказаний в зависимости от обучающего множества у бэггинга значительно ниже, чем у отдельных деревьев, а в среднем предсказания деревьев и бэггинга не отличаются. Чтобы подтвердить это наблюдение, мы можем изобразить смещение и разброс случайных деревьев и бэггинга в зависимости от максимальной глубины: 4 На графике видно, как значительно бэггинг сократил дисперсию. На самом деле, дисперсия уменьшилась практически в 10 раз, что равняется числу базовых алгоритмов ( k k), которые бэггинг использовал для предсказания: 4 Код для отрисовки картинок и подсчёта смещения и разброса можно найти тут. Random Forest В предыдущем разделе мы сделали предположение, что базовые алгоритмы некоррелированы, и за счёт этого получили очень сильное уменьшение дисперсии у ансамбля относительно входящих в него базовых алгоритмов. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках. Поэтому будет странно, если корреляция на самом деле нулевая. Но на практике оказывается, что строгое выполнение этого предположения не обязательно. Достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга. На этом строится развитие идеи бэггинга для решающих деревьев — случайный лес. Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. Будем строить по следующей схеме: Для построения i i-го дерева: Сначала, как в обычном бэггинге, из обучающей выборки X X выбирается с возвращением случайная подвыборка X i X i того же размера, что и X X. В процессе обучения каждого дерева в каждой вершине случайно выбираются n < N n<N признаков, где N N — полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации). Profit. Мы построили Random Forest (случайный лес) — комбинацию бэггинга и метода случайных подпространств над решающими деревьями. Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее. Какая должна быть глубина деревьев в случайном лесу? Ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. Разброс мы уменьшаем с помощью процедуры бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость. Поэтому при изменении обучающей подвыборки предсказание на тестовом объекте будет стабильным, но не точным (низкая дисперсия, высокое смещение). Наоборот, у глубоких деревьев нет проблем запомнить подвыборку подробно. Поэтому предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,",
        "Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зрения error rate модели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная нами доля ошибочных классификаций не даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Точность и полнота Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем",
        "Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зрения error rate модели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная нами доля ошибочных классификаций не даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Точность и полнота Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем"
      ]
    },
    {
      "index": 4,
      "question": "Как можно регуляризировать решающее дерево?",
      "ground_truth": "Ограничить максимальную глубину дерева (max_depth)\r\nЗадать минимальное количество объектов в узле (min_samples_split, min_samples_leaf)\r\nОграничить максимальное число признаков для выбора сплита (max_features)\r\nИспользовать pruning (обрезку лишних веток после обучения)\r\nmax_leaf_nodes — ограничивает общее число листьев в дереве\r\nmin_impurity_decrease - минимальный прирост критерия сплита",
      "model_answer": "На основе предоставленного контекста можно выделить несколько способов регуляризации решающего дерева, направленных на борьбу с переобучением:\n\n1. **Ограничение максимальной глубины дерева (глубина)**. Как указано в контексте, глубина дерева напрямую влияет на его способность запоминать данные: неглубокие деревья имеют высокое смещение и низкую дисперсию, а глубокие — наоборот. Ограничение глубины предотвращает создание слишком сложных правил, которые подстраиваются под шум в обучающих данных.\n\n2. **Использование ансамблевых методов, таких как случайный лес (Random Forest)**. Этот метод комбинирует бэггинг (усреднение предсказаний множества деревьев, обученных на разных подвыборках) и метод случайных подпространств (выбор случайного подмножества признаков для каждого разбиения). Это снижает дисперсию модели и уменьшает переобучение, как показано в контексте: \"дисперсия уменьшилась практически в 10 раз\".\n\n3. **Контроль за параметрами разбиения в узлах**. Хотя в контексте явно не указаны параметры типа минимального числа объектов в листе или минимального уменьшения неопределённости для разбиения, они являются стандартными методами регуляризации. Они предотвращают создание узлов, которые захватывают слишком мало данных или не дают значимого улучшения критерия (например, энтропии или критерия Джини).\n\n4. **Выбор критерия информативности**. Контекст упоминает, что для разных задач могут быть предпочтительны разные критерии (например, MSE для регрессии или критерий Джини для классификации). Выбор критерия, менее склонного к переобучению, также может служить формой регуляризации.\n\n5. **Ранняя остановка**. Хотя в контексте прямо не описана, ранняя остановка при построении дерева (например, прекращение разделения, если улучшение незначительно) является распространённым приёмом.\n\nТаким образом, регуляризация решающего дерева достигается через ограничение его сложности, использование ансамблей и тщательный выбор параметров построения.",
      "contexts": [
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,",
        "Вопрос: Деревья\n  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "Определение порогов для категориальных и числовых признаков\nhttps://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e\n  \n  ",
        "Что такое дерево решений, и как оно работает?\nОтвет: Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.\nКаждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).\nПример:\nВ медицинской задаче:\n         * Вершина 1: \"Возраст > 40 лет?\"\n         * Да → Вершина 2: \"Курит?\"\n         * Нет → Прогноз: \"Низкий риск заболевания\".\n         * Вершина 2:\n         * Да → Прогноз: \"Высокий риск заболевания\".\n         * Нет → Прогноз: \"Средний риск заболевания\".\n  ",
        "  ",
        "Как строится дерево решений?\nВыбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:",
        "20. Возьмём также бэггинг над 10 решающими деревьями глубины 7 в качестве базовых классификаторов и тоже 100 раз обучим его на случайных выборках размера 20. Если изобразить предсказания обученных моделей на каждой из 100 итераций, то можно увидеть примерно такую картину: 4 По этому рисунку видно, что общая дисперсия предсказаний в зависимости от обучающего множества у бэггинга значительно ниже, чем у отдельных деревьев, а в среднем предсказания деревьев и бэггинга не отличаются. Чтобы подтвердить это наблюдение, мы можем изобразить смещение и разброс случайных деревьев и бэггинга в зависимости от максимальной глубины: 4 На графике видно, как значительно бэггинг сократил дисперсию. На самом деле, дисперсия уменьшилась практически в 10 раз, что равняется числу базовых алгоритмов ( k k), которые бэггинг использовал для предсказания: 4 Код для отрисовки картинок и подсчёта смещения и разброса можно найти тут. Random Forest В предыдущем разделе мы сделали предположение, что базовые алгоритмы некоррелированы, и за счёт этого получили очень сильное уменьшение дисперсии у ансамбля относительно входящих в него базовых алгоритмов. Однако в реальной жизни добиться этого сложно: ведь базовые алгоритмы учили одну и ту же зависимость на пересекающихся выборках. Поэтому будет странно, если корреляция на самом деле нулевая. Но на практике оказывается, что строгое выполнение этого предположения не обязательно. Достаточно, чтобы алгоритмы были в некоторой степени не похожи друг на друга. На этом строится развитие идеи бэггинга для решающих деревьев — случайный лес. Построим ансамбль алгоритмов, где базовый алгоритм — это решающее дерево. Будем строить по следующей схеме: Для построения i i-го дерева: Сначала, как в обычном бэггинге, из обучающей выборки X X выбирается с возвращением случайная подвыборка X i X i того же размера, что и X X. В процессе обучения каждого дерева в каждой вершине случайно выбираются n < N n<N признаков, где N N — полное число признаков (метод случайных подпространств), и среди них ищется оптимальный сплит. Такой приём как раз позволяет управлять степенью скоррелированности базовых алгоритмов. Чтобы получить предсказание ансамбля на тестовом объекте, усредняем отдельные ответы деревьев (для регрессии) или берём самый популярный класс (для классификации). Profit. Мы построили Random Forest (случайный лес) — комбинацию бэггинга и метода случайных подпространств над решающими деревьями. Внимательный читатель мог заметить, что при построении случайного леса у специалиста по машинному обучению есть несколько степеней свободы. Давайте обсудим их подробнее. Какая должна быть глубина деревьев в случайном лесу? Ошибка модели (на которую мы можем повлиять) состоит из смещения и разброса. Разброс мы уменьшаем с помощью процедуры бэггинга. На смещение бэггинг не влияет, а хочется, чтобы у леса оно было небольшим. Поэтому смещение должно быть небольшим у самих деревьев, из которых строится ансамбль. У неглубоких деревьев малое число параметров, то есть дерево способно запомнить только верхнеуровневые статистики обучающей подвыборки. Они во всех подвыборках будут похожи, но будут не очень подробно описывать целевую зависимость. Поэтому при изменении обучающей подвыборки предсказание на тестовом объекте будет стабильным, но не точным (низкая дисперсия, высокое смещение). Наоборот, у глубоких деревьев нет проблем запомнить подвыборку подробно. Поэтому предсказание на тестовом объекте будет сильнее меняться в зависимости от обучающей подвыборки, зато в среднем будет близко",
        "Вопрос: Какие ещё методы помогают бороться с переобучением, кроме регуляризации?\nОтвет: "
      ]
    },
    {
      "index": 5,
      "question": "Что такое бустинг?",
      "ground_truth": "Бустинг — это метод ансамблирования, в котором модели обучаются последовательно. Каждая последующая модель пытается исправить ошибки предыдущих. Например, слабые модели (например, слабые деревья) обучаются на ошибках предыдущих моделей, усиливая их предсказания на тяжёлых объектах.",
      "model_answer": "Бустинг — это метод ансамблирования, в котором модели (обычно простые, например, деревья небольшой глубины) обучаются последовательно, каждая новая модель корректирует ошибки предыдущих. В градиентном бустинге, который является основным практическим вариантом, каждая следующая модель обучается на антиградиенте функции потерь, что позволяет минимизировать ошибку шаг за шагом.\n\nИз контекста:\n- Итоговый прогноз в бустинге — это сумма всех индивидуальных предсказаний деревьев, скорректированная на каждом этапе.\n- В качестве базовых алгоритмов часто выбирают модели с высоким смещением и небольшим разбросом, например, деревья глубиной 2–3 уровня, чтобы избежать переобучения и ускорить обучение.\n- Градиентный бустинг доминирует в работе с табличными данными благодаря своей эффективности.\n\nТаким образом, бустинг строит сильную модель путем комбинации множества слабых моделей, последовательно улучшая общий результат.",
      "contexts": [
        "Вопрос: Итоговый прогноз — это сумма всех индивидуальных предсказаний деревьев, скорректированная на каждом этапе.",
        "Может ли градиентный бустинг стать хуже при увеличении количества деревьев?\nОтвет: Да, градиентный бустинг может переобучиться с увеличением числа деревьев. Если деревьев становится слишком много, модель начинает \"запоминать\" тренировочные данные, что ухудшает ее обобщающую способность на новых данных.\nКак предотвратить переобучение:",
        "L до первого члена в окрестности точки k−1 (x i )): L(y i ,a k−1 (x i )+b(x i ))≈L(y i ,a k−1 (x i ))+b(x i ) ∂z ∂L(y i ,z) z=a k−1 (x i ) =L(y i ,a k−1 (x i ))+b(x i )g i k−1 Избавившись от постоянных членов, мы получим следующую оптимизационную задачу: b k ≈ argminb∈B b∈B argmin i=1 ∑ N b(x i )g i k−1 Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют b ( x i ) b(x i ), пропорциональные значениям k−1 . Поэтому на каждой итерации базовые алгоритмы b k b k обучаются предсказывать значения антиградиента функции потерь по текущим предсказаниям композиции. Итак, использованная нами интуиция шага в сторону «уменьшения остатка» удивительным образом привела к оптимальным смещениям в случае квадратичной функции потерь, но для других функций потерь это не так: для них смещение происходит в сторону антиградиента. Получается, что в общем случае на каждой итерации базовые алгоритмы должны приближать значения антиградиента функции потерь. Однако есть частный случай, в котором в качестве таргета для базового алгоритма выгоднее использовать именно «остатки» — это касается функции потерь MAE. Её производная равна -1, 0 или +1. Приближая базовым алгоритмом антиградиент MAE, количество итераций до сходимости будет расти пропорционально масштабу таргета. То есть, если домножить целевое значение на 10, то потребуется в 10 раз больше итераций градиентного бустинга. Использование остатков в качестве таргета для базового алгоритма не имеет такой проблемы. Аналогичные рассуждения верны также для функции MAPE, в которой проблема с масштабом таргета может проявляться еще сильнее. Обучение базового алгоритма При построении очередного базового алгоритма b k + 1 b k+1 мы решаем задачу регрессии с таргетом, равным антиградиенту функции потерь исходной задачи на предсказании +…+b k . Теоретически можно воспользоваться любым методом построения регрессионного дерева. Важно выбрать оценочную функцию S S, которая будет показывать, насколько текущая структура дерева хорошо приближает антиградиент. Её нужно будет использовать для построения критерия ветвления: max ⁡ , ∣R∣⋅S(R)−∣R right ∣⋅S(R right )−∣R left ∣⋅S(R left )→max, где S ( R ) S(R) — значение функции S S в вершине S(R left ),S(R right ) — значения в левом и правом сыновьях R R после добавления предиката, ∣ ⋅ ∣ ∣⋅∣ — количество элементов, пришедших в вершину. Например, можно использовать следующие оценочные функции: (g,p)= i=1 Cosine(g,p)=− i=1 i=1 ∑ N g i 2 i=1 где p i p i — предсказание дерева на объекте — антиградиент, на который учится дерево, p=p i i=1 g=g i N . Функция L 2 L 2 представляет собой среднеквадратичную ошибку, а функция Cosine определяет близость через косинусное расстояние между векторами предсказаний и антиградиентов. В итоге обучение базового алгоритма проходит в два шага: по функции потерь вычисляется целевая переменная для обучения следующего базового алгоритма: ∂L(y i ,z) z=a k (x i ) строится регрессионное дерево на обучающей выборке ,−g i k ), минимизирующее выбранную оценочную функцию. На практике Поскольку для построения градиентного бустинга достаточно уметь считать градиент функции потерь по предсказаниям, с его помощью можно решать широкий спектр задач. В библиотеках градиентного",
        "Вопрос: Что такое регуляризация и зачем она нужна?\nОтвет: Регуляризация — это техника, используемая для предотвращения переобучения (overfitting) моделей машинного обучения путем добавления штрафных (регуляризационных) членов к функции потерь модели. Регуляризация помогает уменьшить сложность модели и сделать её более способной к обобщению, а не к запоминанию деталей тренировочных данных. Модели с большим количеством параметров могут быть склонны к переобучению, так как они легко запоминают случайные шумы и особенности данных. Регуляризация вводит штраф за слишком большие значения параметров модели, что заставляет модель искать более простые и обобщенные решения. \nОсновные задачи регуляризации:",
        "Вопрос: Почему в градиентном бустинге используют деревья небольшой глубины?\nОтвет: В градиентном бустинге обычно применяются деревья небольшой глубины (3–6 уровней), чтобы:",
        "качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике является градиентный бустинг, о котором подробно рассказывается в соответствующем параграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети). Стекинг Стекинг (stacking) — алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем: он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) Обучение стекинга проходит в несколько этапов: общая выборка разделяется на тренировочную и тестовую тренировочная выборка делится на n n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются ( n − 1 ) (n−1) фолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались Автор изображения — Steven Yu. на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи Автор изображения — Steven Yu. Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве — переобучения в данном случае возникнуть не должно. Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называют блендингом (blending). Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать. Почитать по теме Лекция Евгения Соколова про bias-variance decomposition и бэггинг Блог-пост про ансамбли от Joseph Rocca Блог-пост про стекинг и блендинг от Steven Yu Знак вопроса Пройдите квиз по параграфу Чтобы закрепить пройденный материал Сообщить об ошибке Предыдущий параграф 2.3. Решающие деревья Обучение древесных моделей для классификации и регрессии. Эффективное построение решающих деревьев Следующий параграф 2.5. Градиентный бустинг Как устроено самое мощное семейство не-нейросетевых моделей: градиентный"
      ]
    },
    {
      "index": 6,
      "question": "Почему градиентный бустинг называется градиентным? Где там градиент?",
      "ground_truth": "Когда мы говорим, что обучаемся на ошибках предыдущих моделей, мы:\r\nМы фиксируем функцию потерь. Она зависит от целевых значений и от текущей композиции\r\nL(y, F(x))\r\nДобавляя новый базовых алгоритм в наш ансамбль / композицию, хотим минимизировать функцию потерь\r\nДля этого можем посчитать градиент этой функции потерь (градиент берем по предсказаниям ансамбля)\r\nИ обучать следующее дерево на антиградиент\r\nТаким образом мы обучаемся на ошибках, но не совсем на остатках (разницы между предсказанием и таргетом), а на значение антиградиента, что, например, для функции потерь mse одно и то же.     Формула градиента                                                                                                                      ",
      "model_answer": "Градиентный бустинг называется градиентным, потому что на каждой итерации он обучает новый базовый алгоритм (например, дерево) приближать не остатки, а **антиградиент функции потерь** по текущим предсказаниям ансамбля.\n\nСогласно контексту:\n1.  **Цель обучения базового алгоритма:** На шаге `k+1` решается задача регрессии, где целевой переменной (таргетом) является антиградиент исходной функции потерь, вычисленный на предсказании текущей композиции `a_k(x_i)`:\n    `-g_i^k = - ∂L(y_i, z) / ∂z`, где `z = a_k(x_i)`.\n2.  **Связь с градиентным спуском:** Этот процесс аналогичен градиентному спуску в пространстве функций. Каждое новое дерево (`b_{k+1}`) представляет собой \"шаг\" в направлении, противоположном градиенту функции потерь, что минимизирует ошибку.\n3.  **Частный случай:** Для квадратичной функции потерь (MSE) антиградиент пропорционален остаткам (`y_i - a_k(x_i)`), что интуитивно соответствует \"исправлению ошибки\". Однако для произвольных функций потерь (например, MAE, logloss) базовый алгоритм обучается именно на антиградиент, что является общим и строго обоснованным подходом.\n\nТаким образом, \"градиентность\" метода заключается в использовании **градиента функции потерь** для определения цели, которую должно предсказывать каждое следующее дерево в последовательности.",
      "contexts": [
        "L до первого члена в окрестности точки k−1 (x i )): L(y i ,a k−1 (x i )+b(x i ))≈L(y i ,a k−1 (x i ))+b(x i ) ∂z ∂L(y i ,z) z=a k−1 (x i ) =L(y i ,a k−1 (x i ))+b(x i )g i k−1 Избавившись от постоянных членов, мы получим следующую оптимизационную задачу: b k ≈ argminb∈B b∈B argmin i=1 ∑ N b(x i )g i k−1 Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют b ( x i ) b(x i ), пропорциональные значениям k−1 . Поэтому на каждой итерации базовые алгоритмы b k b k обучаются предсказывать значения антиградиента функции потерь по текущим предсказаниям композиции. Итак, использованная нами интуиция шага в сторону «уменьшения остатка» удивительным образом привела к оптимальным смещениям в случае квадратичной функции потерь, но для других функций потерь это не так: для них смещение происходит в сторону антиградиента. Получается, что в общем случае на каждой итерации базовые алгоритмы должны приближать значения антиградиента функции потерь. Однако есть частный случай, в котором в качестве таргета для базового алгоритма выгоднее использовать именно «остатки» — это касается функции потерь MAE. Её производная равна -1, 0 или +1. Приближая базовым алгоритмом антиградиент MAE, количество итераций до сходимости будет расти пропорционально масштабу таргета. То есть, если домножить целевое значение на 10, то потребуется в 10 раз больше итераций градиентного бустинга. Использование остатков в качестве таргета для базового алгоритма не имеет такой проблемы. Аналогичные рассуждения верны также для функции MAPE, в которой проблема с масштабом таргета может проявляться еще сильнее. Обучение базового алгоритма При построении очередного базового алгоритма b k + 1 b k+1 мы решаем задачу регрессии с таргетом, равным антиградиенту функции потерь исходной задачи на предсказании +…+b k . Теоретически можно воспользоваться любым методом построения регрессионного дерева. Важно выбрать оценочную функцию S S, которая будет показывать, насколько текущая структура дерева хорошо приближает антиградиент. Её нужно будет использовать для построения критерия ветвления: max ⁡ , ∣R∣⋅S(R)−∣R right ∣⋅S(R right )−∣R left ∣⋅S(R left )→max, где S ( R ) S(R) — значение функции S S в вершине S(R left ),S(R right ) — значения в левом и правом сыновьях R R после добавления предиката, ∣ ⋅ ∣ ∣⋅∣ — количество элементов, пришедших в вершину. Например, можно использовать следующие оценочные функции: (g,p)= i=1 Cosine(g,p)=− i=1 i=1 ∑ N g i 2 i=1 где p i p i — предсказание дерева на объекте — антиградиент, на который учится дерево, p=p i i=1 g=g i N . Функция L 2 L 2 представляет собой среднеквадратичную ошибку, а функция Cosine определяет близость через косинусное расстояние между векторами предсказаний и антиградиентов. В итоге обучение базового алгоритма проходит в два шага: по функции потерь вычисляется целевая переменная для обучения следующего базового алгоритма: ∂L(y i ,z) z=a k (x i ) строится регрессионное дерево на обучающей выборке ,−g i k ), минимизирующее выбранную оценочную функцию. На практике Поскольку для построения градиентного бустинга достаточно уметь считать градиент функции потерь по предсказаниям, с его помощью можно решать широкий спектр задач. В библиотеках градиентного",
        "качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике является градиентный бустинг, о котором подробно рассказывается в соответствующем параграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети). Стекинг Стекинг (stacking) — алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем: он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) Обучение стекинга проходит в несколько этапов: общая выборка разделяется на тренировочную и тестовую тренировочная выборка делится на n n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются ( n − 1 ) (n−1) фолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались Автор изображения — Steven Yu. на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи Автор изображения — Steven Yu. Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве — переобучения в данном случае возникнуть не должно. Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называют блендингом (blending). Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать. Почитать по теме Лекция Евгения Соколова про bias-variance decomposition и бэггинг Блог-пост про ансамбли от Joseph Rocca Блог-пост про стекинг и блендинг от Steven Yu Знак вопроса Пройдите квиз по параграфу Чтобы закрепить пройденный материал Сообщить об ошибке Предыдущий параграф 2.3. Решающие деревья Обучение древесных моделей для классификации и регрессии. Эффективное построение решающих деревьев Следующий параграф 2.5. Градиентный бустинг Как устроено самое мощное семейство не-нейросетевых моделей: градиентный",
        "Вопрос: Итоговый прогноз — это сумма всех индивидуальных предсказаний деревьев, скорректированная на каждом этапе.",
        "Может ли градиентный бустинг стать хуже при увеличении количества деревьев?\nОтвет: Да, градиентный бустинг может переобучиться с увеличением числа деревьев. Если деревьев становится слишком много, модель начинает \"запоминать\" тренировочные данные, что ухудшает ее обобщающую способность на новых данных.\nКак предотвратить переобучение:",
        "Вопрос: Как формируется итоговый прогноз в градиентном бустинге?\nОтвет: Итоговый прогноз в градиентном бустинге формируется путем последовательного суммирования предсказаний всех слабых моделей в ансамбле.\nЭтапы:",
        "Вопрос: Какой глубины деревья используются в случайном лесе и градиентном бустинге?\nОтвет: * Случайный лес:\nИспользуются глубокие деревья (большая глубина, часто без ограничения), чтобы максимально улавливать закономерности в данных.\n            * Градиентный бустинг:\nИспользуются неглубокие деревья (3-6 уровней), чтобы каждое дерево выполняло небольшую корректировку и предотвращалось переобучение.",
        "Может ли градиентный бустинг переобучиться с увеличением количества деревьев?"
      ]
    },
    {
      "index": 7,
      "question": "Какие есть плюсы и минусы метрических моделей и knn в особенности?",
      "ground_truth": "Плюсы:\r\nПростота — легко реализовать, легко объяснить.\r\nНет обучения — не нужно долго тренировать модель.\r\nИнтерпретируемость — можно объяснить решение через похожие примеры: “мы присвоили этот класс, потому что рядом был вот этот объект”.\r\nРаботают на любых признаках (если выбрать подходящую метрику): числовые, бинарные, категориальные.\r\n\r\nМинусы:\r\nМедленные предсказания — при большом количестве данных или признаков тормозят.\r\nЧувствительность к масштабу признаков — без нормализации всё ломается.\r\nПроклятие размерности — в высоких размерностях расстояния теряют смысл.\r\nЧувствительность к шуму и выбросам — особенно при маленьком k.\r\nХранение всей выборки — нужны память и ресурсы для хранения и поиска.",
      "model_answer": "На основе предоставленного контекста можно выделить следующие плюсы и минусы метрических моделей в целом и метода k-ближайших соседей (k-NN) в частности.\n\n### Плюсы метрических моделей и k-NN:\n\n1.  **Простота реализации и интуитивная понятность:** Алгоритм k-NN, описанный в контексте, основан на простой идее поиска ближайших объектов и голосования большинства (формула (2)). Его легко понять и реализовать.\n2.  **Отсутствие явной фазы обучения:** Контекст прямо указывает, что \"формально фаза обучения отсутствует\". Модель просто запоминает обучающую выборку, что делает \"обучение\" быстрым.\n3.  **Адаптивность к данным:** Поскольку модель использует всю выборку, она может строить очень сложные, нелинейные границы решений, подстраиваясь под конкретные данные.\n4.  **Универсальность применения:** Методы поиска ближайших соседей, лежащие в основе k-NN, имеют широкую область применения, выходящую за рамки ML (например, информационно-поисковые системы, рекомендации).\n5.  **Возможность оценки вероятностей:** Алгоритм позволяет эвристически оценивать вероятность класса для нового объекта как долю соседей, принадлежащих к этому классу.\n6.  **Гибкость выбора метрики:** Можно использовать различные функции расстояния (евклидово, манхэттенское, косинусное и т.д.), адаптируя алгоритм к специфике данных (например, косинусное расстояние для текстов).\n\n### Минусы метрических моделей и k-NN:\n\n1.  **Высокая вычислительная сложность предсказания:** Для классификации нового объекта необходимо вычислить расстояния до всех объектов обучающей выборки. Это может быть очень затратно на больших данных, хотя контекст упоминает методы ускорения (k-d-деревья, эвристики).\n2.  **Склонность к переобучению (overfitting):** В контексте прямо сказано: \"алгоритм может легко переобучиться\". Это происходит из-за того, что \"параметрами алгоритма можно считать всю обучающую выборку\", и при малом числе соседей (например, k=1) границы классов становятся излишне сложными и чувствительными к шуму.\n3.  **Чувствительность к дисбалансу классов и выбросам:** Хотя в контексте прямо не обсуждается, использование голосования большинства может давать плохие результаты, если один класс значительно преобладает. Некоторые метрики (например, манхэттенская) более устойчивы к выбросам, чем евклидова.\n4.  **Необходимость выбора метрики и параметра k:** Качество модели сильно зависит от выбора функции расстояния ρ и числа соседей k. Их оптимальные значения не известны заранее и должны подбираться.\n5.  **Проблемы с высокоразмерными данными (\"проклятие размерности\"):** Хотя в контексте не упомянуто явно, эффективность метрических методов, основанных на расстояниях, часто падает в пространствах с большим числом признаков, так как понятие близости теряет смысл.\n6.  **Требования к данным:** Модель требует хранения всей обучающей выборки, что может быть проблемой при ограниченных ресурсах. Также она чувствительна к масштабированию признаков.\n\n**Вывод из контекста:** K-NN — это простой и мощный алгоритм, способный строить сложные границы решений без явного обучения. Однако его главные недостатки — вычислительная затратность на больших выборках и риск переобучения при неудачном выборе параметров — требуют осторожного применения и использования специальных структур данных (как k-d-деревья) для оптимизации.",
      "contexts": [
        "классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто встречающийся класс среди объектов из (u): a ( u ) = argmax⁡y∈Y (2) a(u)= y∈Y argmax i=1 ∑ k I[y u (i) =y](2) Формула может показаться страшной, но на самом деле всё довольно просто: для каждой метки класса y ∈ Y y∈Y количество соседей u u с такой меткой можно посчитать, просто просуммировав по всем соседям индикаторы событий, соответствующих тому, что метка соседа равна y y. Легко заметить, что этот алгоритм позволяет также оценивать вероятности классов. Для этого достаточно просто посчитать частоты классов соседей: P(u∼y)= k ∑ i=1 k I[y u (i) =y] Стоит, однако, понимать, что, хоть такая функция и удовлетворяет свойствам вероятности (она неотрицательна, аддитивна и ограничена единицей), это не более чем эвристика. Несмотря на то что формально фаза обучения отсутствует, алгоритм может легко переобучиться. Вы можете убедиться в этом сами, использовав маленькое количество соседей (например, одного или двух), — границы классов оказываются довольно сложными. Происходит это из-за того, что параметрами алгоритма можно считать всю обучающую выборку, довольно большую по размеру. Из-за этого алгоритму легко подстроиться под конкретные данные. По ссылке вы можете увидеть интерактивный пример работы алгоритма. Автор примера - Анастасия Чирикова. Выбор метрики Может возникнуть закономерный вопрос, как же правильно выбрать функцию расстояния ρ ρ. В подавляющем большинстве случаев обычное евклидово расстояние ρ(x,y)= будет хорошим выбором. Однако в некоторых случаях другие функции будут подходить лучше, поэтому давайте разберём ещё несколько функций, наиболее используемых на практике. 2 Манхэттенская метрика ρ(x,y)= Часто используется в высокоразмерных пространствах из-за лучшей устойчивости к выбросам. Представим, что два объекта в 1000-размерном пространстве почти идентичны, но сильно отличаются по одному из признаков. Это почти наверняка свидетельствует о выбросе в этом признаке, и объекты, скорее всего, очень близки. Однако евклидово расстояние усилит различие в единственном признаке и сделает их более далёкими друг от друга. Этого недостатка лишена манхэттенская метрика — в ней вместо квадрата используется модуль. Метрика Минковского ρ(x,y)=( 1/p Является обобщением евклидовой ( p = 2 p=2) и манхэттенской ( p = 1 p=1) метрик. Косинусное расстояние cos ρ(x,y)=1−cosθ=1− ∥x∥∥y∥ x⋅y Эта метрика хороша тем, что не зависит от норм векторов. Такое поведение бывает полезно в некоторых задачах, например при поиске похожих документов. В качестве признаков там часто используются количества слов. При этом интуитивно кажется, что если в тексте использовать каждое слово в два раза больше, то тема этого текста поменяться не должна. Поэтому как раз в этом случае нам не важна норма вектор-признака, и в задачах, связанных с текстами, часто применяется именно",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба». Поиск ближайших соседей: точные методы Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие эвристики хоть и могут давать некоторый выигрыш по времени, но не улучшат асимптотическую сложность. Второй — k-d-деревья, о которых стоит поговорить подробнее. K-d-деревья Представим на секунду, что у нас есть всего лишь один признак, то есть объекты выражаются вещественными числами, а не векторами. В этом случае для поиска ближайшего соседа напрашивается всем вам известное бинарное дерево поиска, которое позволяет находить элементы за логарифмическое время. Оказывается, существует аналог данной структуры в многомерном пространстве, который называется k-d-дерево (k-d tree, сокращение от k-dimensional tree). Как и в обычном дереве поиска, в k-d-дереве каждый узел является объектом обучающей выборки, который особым образом делит пространство на два полупространства. Таким образом, всё пространство оказывается поделено на множество малых областей, и такое деление оказывается очень полезным при поиске ближайших соседей. Рассмотрим подробнее, как строится такое дерево. Трудность в применении обычного дерева поиска состоит в том, что мы не можем напрямую сравнить два вектора так же, как два вещественных числа. Чтобы эту проблему преодолеть, узлы дерева будут делить пространство лишь по одной оси. При движении вниз по дереву оси, по которым точки делят пространство, циклически сменяют друг друга. Например, в двумерном пространстве корень будет отвечать за деление по x-координате, его сыновья — за деление по y-координате, а внуки — снова за x-координату, и т. д. Посмотрим, как это работает на примере: Источник На картинке выше корень ( 30 , 40 ) (30,40) делит все точки по оси х: слева оказываются точки, у которых x < 30 x<30, а справа — те, у которых x ⩾ 30 x⩾30. Аналогично левый сын корня ( 5 , 25 ) (5,25) делит своё поддерево по оси y: слева оказываются точки, у которых y < 25 y<25, а справа — те, у которых y ⩾ 25 y⩾25. Остаётся вопрос — как выбирать точки, которые будут делить пространство пополам? Чтобы дерево было сбалансированным, нужно находить точку с медианой, соответствующей уровню поддерева координаты. На практике часто ограничиваются выбором случайной точки или любой эвристикой по приближённому поиску медианы (например, медиана некоторого подмножества точек). Это позволяет ускорить построение дерева, но убирает все гарантии на его сбалансированность. Добавлять новые точки можно так же, как и в одномерном дереве поиска. Спускаясь по дереву, можно однозначно определить лист, к которому нужно подвесить новую точку, чтобы не нарушить все свойства дерева. При добавлении большого количества точек, однако, дерево может перестать быть сбалансированным, и нужно проводить ребалансировку. Также существуют варианты k-d-деревьев, которые сохраняют сбалансированность при добавлении / удалении точек. Поговорим теперь про",
        "Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зрения error rate модели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная нами доля ошибочных классификаций не даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Точность и полнота Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем"
      ]
    },
    {
      "index": 8,
      "question": "В задаче классификации дисбаланс классов 95:5. Как решить проблему?",
      "ground_truth": "from imblearn.over_sampling import SMOTE\r\nfrom imblearn.under_sampling import RandomUnderSampler\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n# Пример несбалансированных данных\r\nX = df[['A', 'C']]\r\ny = pd.Series([0, 0, 0, 0, 1])  # 4:1\r\n\r\n# SMOTE (oversampling)\r\nsmote = SMOTE(random_state=42)\r\nX_resampled, y_resampled = smote.fit_resample(X, y)\r\n\r\n# Undersampling\r\nrus = RandomUnderSampler(random_state=42)\r\nX_under, y_under = rus.fit_resample(X, y)",
      "model_answer": "На основе предоставленного контекста, проблема дисбаланса классов (95:5) делает стандартную метрику Accuracy неинформативной и даже обманчивой. Dummy-классификатор, который всегда предсказывает мажоритарный класс (95%), достигнет Accuracy около 0.95, что формально высоко, но бесполезно, так как он полностью игнорирует миноритарный класс.\n\nКонтекст предлагает следующие ключевые подходы к решению:\n\n1. **Использовать метрики, устойчивые к дисбалансу, вместо Accuracy**. Поскольку Accuracy сильно зависит от TN (истинно отрицательных случаев мажоритарного класса), нужно перейти к метрикам, фокусирующимся на качестве предсказания положительного (миноритарного) класса:\n    *   **Precision (Точность)**: `TP / (TP + FP)`. Показывает, насколько мы уверены в положительных предсказаниях. Важна, когда цена ложного срабатывания (FP) высока (например, при запуске спутника).\n    *   **Recall (Полнота)**: `TP / (TP + FN)`. Показывает, какую долю объектов миноритарного класса мы нашли. Критически важна, когда пропуск положительного объекта (FN) стоит дорого (например, в диагностике опухолей).\n    *   **F1-мера (или Fβ-мера)**: Гармоническое среднее Precision и Recall. Позволяет сравнивать модели одним числом, учитывая оба аспекта. Fβ позволяет задать приоритет одной из метрик.\n\n2. **Принять осознанное решение о важности ошибок (FP vs FN)**. Выбор между Precision и Recall зависит от предметной области:\n    *   Если важнее **не пропустить** объект миноритарного класса (например, болезнь), нужно максимизировать Recall (допуская больше FP).\n    *   Если важнее **быть уверенным** в каждом положительном предсказании (например, при спам-фильтрации), нужно максимизировать Precision.\n\n3. **Работать с вероятностями и порогом классификации**. Многие модели (например, логистическая регрессия) выдают вероятность принадлежности к классу. Вместо стандартного порога 0.5 можно выбрать другой порог, чтобы сместить баланс между Precision и Recall в нужную сторону (например, снизить порог для увеличения Recall).\n\n**Итог:** Проблему дисбаланса классов 95:5 нельзя решить только на уровне данных (например, oversampling). Критически важно **правильно оценивать модель**, используя Precision, Recall, F1, и **управлять порогом классификации** в соответствии с бизнес-требованиями (что важнее — минимизировать FP или FN?). Это позволяет строить модели, полезные для задачи, несмотря на дисбаланс.",
      "contexts": [
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зрения error rate модели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная нами доля ошибочных классификаций не даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Точность и полнота Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем",
        "Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зрения error rate модели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная нами доля ошибочных классификаций не даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Точность и полнота Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем"
      ]
    },
    {
      "index": 9,
      "question": "Как обнаружить выбросы в данных?",
      "ground_truth": "from scipy import stats\r\n\r\n# Метод z-score\r\nz_scores = np.abs(stats.zscore(df[['A', 'C']]))\r\noutliers_z = (z_scores > 3).any(axis=1)\r\n\r\n# IQR метод\r\nQ1 = df[['A', 'C']].quantile(0.25)\r\nQ3 = df[['A', 'C']].quantile(0.75)\r\nIQR = Q3 - Q1\r\noutliers_iqr = ((df[['A', 'C']] < (Q1 - 1.5 * IQR)) | \r\n                (df[['A', 'C']] > (Q3 + 1.5 * IQR))).any(axis=1)",
      "model_answer": "На основе предоставленного контекста можно выделить несколько ключевых идей, связанных с обнаружением выбросов, хотя прямо эта тема не раскрыта. Контекст фокусируется на прогнозировании временных рядов, оценке моделей и общих принципах машинного обучения. Вот как эти принципы можно применить к задаче обнаружения выбросов:\n\n1.  **Анализ остатков модели:** В контексте упоминается, что при построении прогноза (например, линейной регрессии по времени) в остатках (разности между истинными значениями и прогнозом) может оставаться много информации. **Выбросы часто проявляются как аномально большие остатки (ошибки прогноза)**. Построив модель, улавливающую основную закономерность (тренд, сезонность), можно анализировать точки, где реальные данные сильно отклоняются от предсказанных.\n\n2.  **Важность разделения на train/test:** Контекст подчеркивает необходимость разделения данных на обучающую и тестовую выборки для оценки обобщающей способности модели. Этот же принцип критически важен для корректного обнаружения выбросов:\n    *   Модель должна обучаться на \"чистых\" данных (или данных, где выбросы обработаны особым образом), чтобы выучить истинные закономерности.\n    *   **Переобученная модель** (как на правом графике с \"запомнившей\" данные функцией) может принять выбросы за часть закономерности и не обнаружить их. Нужна модель оптимальной сложности, которая улавливает общие зависимости, но не шум.\n\n3.  **Метрические методы (KNN):** В контексте описывается алгоритм k-ближайших соседей (KNN) как пример \"ленивого\" обучения, который классифицирует объект на основе его соседей. **Этот принцип можно использовать для обнаружения выбросов:**\n    *   Выбросом может считаться объект, который находится на значительном расстоянии от своих `k` ближайших соседей в пространстве признаков.\n    *   Для временного ряда признаками могут быть, например, лаги (предыдущие значения `y_{t-1}, ..., y_{t-p}`), как упоминается в разделе о прогнозировании.\n\n4.  **Статистические подходы (распределения):** Раздел о распределениях и методе моментов косвенно указывает на классический статистический подход:\n    *   Если предположить, что данные следуют определенному распределению (например, нормальному), то **выбросами можно считать наблюдения, попадающие в крайние \"хвосты\" распределения** (например, за пределами 3 стандартных отклонений от среднего).\n    *   Контекст напоминает, что выбор семейства распределений (симметричное, как нормальное, или нет) важен для корректности такого подхода.\n\n**Итог:** Прямого алгоритма обнаружения выбросов в контексте нет, но из него следует, что выбросы — это точки, которые:\n*   Сильно нарушают общие закономерности, выученные моделью (анализ остатков).\n*   Существенно отличаются от своих \"соседей\" в пространстве данных (подход, аналогичный KNN).\n*   Крайне маловероятны с точки зрения предполагаемого распределения данных.\n\nДля их обнаружения необходимо сначала определить базовую модель или закономерность (тренд, сезонность, распределение), а затем идентифицировать точки, которые этой модели резко противоречат. При этом важно избегать переобучения, чтобы модель не интерпретировала шум или выбросы как часть закономерности.",
      "contexts": [
        "вызвана тем, что люди обычно больше потребляют электричество днем, чем ночью. Недельная сезонность вызвана более высоким потреблением электричества по будням. Если бы мы посмотрели данные за несколько лет, то увидели бы еще одну сезонность – годовую, например, вызванную тем, что в теплое время года работает больше кондиционеров. ex Почему бы нам не построить прогноз простыми методами, например, линейной регрессией по времени? Общий тренд так можно уловить. Но в остатках (то есть в разности между истинными значениями и прогнозом) этой модели будет достаточно много информации, которую хотелось бы как-то учесть. ex Можно также добавить квадрат значения времени. Тогда можно уловить квадратичный тренд, но не более. ex Прогнозирование с помощью сведения к задаче регрессии Давайте для начала поймем, что мы вообще хотим сделать. Посмотрим на этот график, на котором показаны продажи одного из товаров в магазине за разные года. ts Мы знаем значения ряда (зеленые) до момента времени t t, в данном случае за 4 года с 2013 по 2016 включительно. Предположим также, что в данный момент мы отмечаем Новый год 2017. В этот момент мы хотели бы предсказать (синее) будущие значения ряда (оранжевое) за весь 2017 год на основе четырехлетней истории продаж. Основная идея – подадим известные (зеленые) значения ряда в какую-то регрессионную функцию, получив тем самым предсказания. При этом можем брать не все известные значения ряда, а только p p последних значений. Иначе говоря, модель имеет вид =f(y t−1 ,…,y t−p ), где f f – произвольная функция. Ее можно построить некоторым известным методом машинного обучения, например, линейной регрессией, решающими деревьями, бустингами, нейронными сетями (как сверточными, так и рекуррентными). Разберёмся, какие признаки мы подадим на вход регрессии. Признаки Общий принцип На практике при генерации идей о том, какие признаки можно создавать для построения модели, рекомендуется строить следующий график. На нем нужно отметить момент времени t t и мысленно поставить себя в этот момент времени. Затем нужно подумать, какие данные нам при этом доступны. В модель можно брать любые признаки, которые доступны к моменту времени t t. Если все данные поступают сразу, то можно брать все признаки, которые зависят только от значений до момента времени t t. В реальности часть данных может поступать с задержкой. Например, если данные загружаются в базу данных раз в сутки в полночь, то в полдень нам не доступны данные за последние 12 часов. 1 Также нужно помнить о том, на сколько времени вперед нужно сделать прогноз. Например, пусть у нас задача состоит в том, чтобы построить прогнозы продаж в магазине с целью планирования новых поставок. После того, как на основе прогноза мы примем решение о составе товаров в новой поставке, необходимо сначала собрать данные товары на складе, потом отправить машину в магазин, и затем еще разложить товар на полки в магазине. На эту процедуру может уходить от нескольких часов до нескольких дней. Тем самым еще до момента начала формирования новой поставки модель прогнозирования продаж должна построить прогноз спроса на товар к тому моменту, когда его выложат на полки. Даты Посмотрим на то, какие признаки можно извлечь Пусть дана какая-то дата: 13.04.2021 09:00. Отсюда можно получить следующие",
        "какая у построенной модели обобщающая способность, то есть насколько она способна выучить общие закономерности, присущие не только обучающей выборке, и давать адекватные предсказания на новых данных. Для того чтобы предохранить себя от конфуза, поступают обычно так: делят выборку с данными на две части: обучающую выборку и тестовую выборку (train и test). Обучающую выборку используют для собственно обучения модели, а метрики считают на тестовой. Такой подход позволяет отделить модели, которые просто удачно подстроились к обучающим данным, от моделей, в которых произошла генерализация (generalization), то есть от таких, которые на самом деле кое-что поняли о том, как устроены данные, и могут выдавать полезные предсказания для объектов, которых не видели. Например, рассмотрим три модели регрессионной зависимости, построенные на одном и том же синтетическом датасете с одним-единственным признаком. Жёлтым нарисованы точки обучающей выборки. Здесь мы представим, что есть «истинная» закономерность (пунктир), которая искажена шумом (погрешности измерения, влияние других факторов и т.д.). three Левая, линейная модель недостаточно хороша: она сделала, что могла, но плохо приближает зависимость, особенно при маленьких и при больших x x. Правая «запомнила» всю обучающую выборку (и в самом деле, чтобы вычислить значение этой функции, нам надо знать координаты всех исходных точек) вместо того, чтобы моделировать исходную зависимость. Наконец, центральная, хоть и не проходит через точки обучающей выборки, довольно неплохо моделирует истинную зависимость. Алгоритм, избыточно подстроившийся под данные, называют переобученным. С увеличением сложности модели ошибка на обучающей выборке падает. Во многих задачах очень сложная модель будет работать примерно так же, как модель, «просто запомнившая всю обучающую выборку», но с генерализацией всё будет плохо: ведь выученные закономерности будут слишком специфическими, подогнанными под то, что происходит на обучающей выборке. Мы видим это на трёх графиках сверху: линейная функция очень проста, но и закономерность приближает лишь очень грубо; на правом же графике мы видим довольно хитрую функцию, которая точно подобрана под значения из обучающей выборки, но явно слишком эксцентрична, чтобы соответствовать какой-то природной зависимости. Оптимальная же генерализация достигается на модели не слишком сложной и не слишком простой. В качестве иллюстрации для того же самого датасета рассмотрим модели вида y = многочлен степени D y = многочлен степени D Ясно, что с ростом D D сложность модели растёт, и она достигает всё лучшего качества на обучающей выборке. А что, если у нас есть ещё тестовая выборка? Каким будет качество на ней? Вот так могут выглядеть графики среднеквадратичного отклонения (MSE) для обучающей и тестовой выборок: train Мы видим здесь типичную для классических моделей картину: MSE на обучающей выборке падает (может быть, даже до нуля), а на тестовой сперва падает, а затем начинает снова расти. Замечание. Для моделей глубинного обучения всё немного интереснее: в некоторых ситуациях есть грань, за которой метрика на тестовой выборке снова начинает падать. Но об этом в своё время. Пока давайте запомним, что слишком сложная модель — это вредно, а переобучение — боль. Точный способ выбрать алгоритм оптимальной сложности по данной задаче нам пока неизвестен, хотя какую-то теоретическую базу имеющимся философским наблюдениям мы дадим в главе про теорию обучения; при этом есть хорошо продуманная методология сравнения разных моделей и выбора среди них оптимальной —",
        "Смысл метрических методов очень хорошо раскрывает фраза «Скажи мне, кто твой друг, и я скажу, кто ты». Алгоритмы этого класса почти не имеют фазы обучения. Вместо этого они просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут объекты, похожие на целевой. Такой процесс называют lazy learning, потому что никакого обучения, по сути, не происходит. Также метрические модели являются непараметрическими, потому что они не делают явных допущений о глобальных законах, которым подчиняются данные. Так, линейная регрессия основывается на предположении о том, что изучаемая закономерность линейная (с неизвестными коэффициентами, которые восстанавливаются по выборке), а линейная бинарная классификация — что существует гиперплоскость, неплохо разделяющая классы. Метрические методы же локальны: они исходят из допущения, что свойства объекта можно узнать, имея представление о его соседях. Указанные выше свойства могут быть полезными, особенно в случае сложно устроенных данных, для которых мы не можем придумать глобальную модель. Однако с другой стороны, из-за lazy learning алгоритм становится абсолютно неприменимым при большом количестве данных. Несмотря на то, что эти алгоритмы очень просты для понимания, они довольно точны и хорошо интерпретируемы — и часто используются как минимум в качестве бейзлайнов в разных задачах. В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методе k-ближайших соседей (k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах. Например, у алгоритмов поиска ближайших соседей, — неотъемлемой часть метода, — намного более широкая область применения. Плюс ко всему KNN — очень простой и легко интерпретируемый алгоритм, поэтому изучить его всё равно полезно. Мы обсудим подробнее его преимущества, недостатки, область его применения, а также возможные обобщения. Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей. Метод k-ближайших соседей (KNN) Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): 2 Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто",
        "Самые главные семейства распределений в жизни любого data scientist’а Мотивация: метод моментов Метод моментов — это ещё один способ, наряду с методом максимального правдоподобия, оценки параметров распределения по данным ,…,x N . Суть его в том, что мы выражаем через параметры распределения теоретические значения моментов =Ex k нашей случайной величины, затем считаем их выборочные оценки , приравниваем их все друг к другу и, решая полученную систему, находим оценки параметров. Можно доказать, что полученные оценки являются состоятельными, хотя могут быть смещены. Пример 1. Оценим параметры нормального распределения N(μ,σ 2 ) с помощью метода моментов. Теоретические моменты равны =μ,μ 2 =σ 2 +μ 2 Запишем систему: Из неё очевидным образом находим Легко видеть, что полученные оценки совпадают с оценками максимального правдоподобия Пример 2. Оценим параметр μ μ логнормального распределения exp ⁡ ( − ( log p(x)= x 2πσ 2 1 exp(− 2σ 2 (logx−μ) 2 ) при известном σ 2 σ 2 . Будет ли оценка совпадать с оценкой, полученной с помощью метода максимального правдоподобия? Теоретическое математическое ожидание равно exp exp(μ+ 2 σ 2 ), откуда мы сразу находим оценку μ ^ = log =log( Теперь запишем логарифм правдоподобия: log log l(X)=− i ∑ logx (logx i −μ) 2 +const Дифференцируя по μ μ и приравнивая производную к нулю, получаем log ⁡ x i μ MLE = N 1 i ∑ logx i что вовсе не совпадает с оценкой выше. Несколько приукрасив ситуацию, можно сделать вывод, что первые два выборочных момента позволяют если не править миром, то уверенно восстанавливать параметры распределений. А теперь давайте представим, что мы посчитали , а семейство распределений пока не выбрали. Как же совершить этот судьбоносный выбор? Давайте посмотрим на следующие три семейства и подумаем, в каком из них мы бы стали искать распределение, зная его истинные матожидание и дисперсию? 10 Почему-то хочется сказать, что в первом. Почему? Второе не симметрично — но почему мы так думаем? Если мы выберем третье, то добавим дополнительную информацию как минимум о том, что у распределения конечный носитель. А с чего бы? У нас такой инфомации вроде бы нет. Общая идея такова: мы будем искать распределение, которое удовлетворяет только явно заданным нами ограничениям и не отражает никакого дополнительного знания о нём. Но чтобы эти нестрогие рассуждения превратить в формулы, придётся немного обогатить наш математический аппарат и научиться измерять количество информации. Энтропия и дивергенция Кульбака-Лейблера Измерять «знание» можно с помощью энтропии Шэннона. Она определяется как log ⁡ P ( x ) H(P)=− x ∑ P(x)logP(x) для дискретного распределения и log H(p)=−∫p(x)logp(x)dx для непрерывного. В классическом определении логарифм двоичный, хотя, конечно, варианты с разным основанием отличаются лишь умножением на константу. Неформально можно представлять, что энтропия показывает, насколько сложно предсказать значение случайной величины. Чуть более строго — сколько в среднем бит нужно потратить, чтобы передать информацию о её значении. Пример 1. Рассмотрим схему Бернулли с вероятностью успеха p p. Энтропия её результата равна log log ⁡ 2 p −(1−p)⋅log 2 (1−p)−p⋅log 2 p Давайте посмотрим на график этой функции: 10 Минимальное значение (нулевое) энтропия принимает при p∈{0,1}. В самом деле, для такого эксперимента мы всегда",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,"
      ]
    },
    {
      "index": 10,
      "question": "Как закодировать категориальный признак с множеством уникальных значений?",
      "ground_truth": "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n\r\n# Label Encoding для ordinal признаков\r\nle = LabelEncoder()\r\ndf['B_encoded'] = le.fit_transform(df['B'])\r\n\r\n# One-Hot Encoding для nominal признаков\r\nohe = OneHotEncoder(sparse_output=False, drop='first')\r\nB_ohe = ohe.fit_transform(df[['B']])\r\ndf_ohe = pd.DataFrame(B_ohe, columns=ohe.get_feature_names_out(['B']))",
      "model_answer": "Согласно контексту, категориальные признаки с множеством уникальных значений (большое M) представляют проблему, так как количество возможных сплитов (разбиений) для них растёт экспоненциально (M-1 вариантов), и прямой перебор всех комбинаций становится вычислительно неэффективным.\n\nДля решения этой проблемы в контексте деревьев решений предлагается не прямое кодирование, а **упорядочивание категорий** по релевантному критерию, чтобы затем применять бинарные сплиты, как для вещественных признаков. Это позволяет сократить перебор до линейного числа вариантов.\n\nКонкретные методы упорядочивания из контекста:\n1.  **Для задачи бинарной классификации:** Категории упорядочиваются по неубыванию доли объектов положительного класса. После этого можно искать оптимальный порог для разбиения.\n2.  **Для задачи регрессии с MSE:** Категории упорядочиваются по среднему значению целевой переменной (таргета) для объектов в каждой категории.\n\n**Важный вывод из контекста:** Если выбрать сплит на основе такого упорядоченного признака, оптимизируя критерий Джини или энтропию (для классификации) или MSE (для регрессии), то этот сплит будет оптимальным среди всех возможных M-1 сплитов для данного категориального признака.\n\nТаким образом, вместо классического кодирования (One-Hot, Label Encoding) в алгоритмах, основанных на деревьях, категориальный признак с множеством значений эффективно обрабатывается через **сортировку его значений по статистике целевой переменной** и последующее применение порогового правила.",
      "contexts": [
        "Вопрос: Как линейная регрессия обрабатывает категориальные признаки?\nОтвет: Категориальные признаки преобразуются в числовую форму с помощью методов:",
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа",
        "В этом разделе вы познакомитесь с нейросетями для работы с данными, имеющими вид последовательностей некоторых токенов. Это может быть музыка или видео, временные ряды или траектория движения робота, последовательности аминокислот в белке или много чего ещё, но одним из самых богатых источников таких данных является Natural Language Processing (NLP). Как следует из названия, Natural Language Processing (обработка естественного языка) — это область data science, посвященная анализу текстов, написанных на естественных (человеческих) языках. С задачами обработки текста мы встречаемся каждый день, например, когда просим Siri или Алису включить любимую песню или добавить напоминание в календарь, когда используем автодополнение при вводе поискового запроса или проверяем орфографию и пунктуацию с помощью специальных программ. Вот ещё несколько примеров задач, относящихся к обработке естественного языка: классификация документов (по темам, рубрикам, жанрам и так далее); определение спама; определение частей речи; исправление орфографических ошибок и опечаток; поиск ключевых слов, синонимов / антонимов в тексте; распознавание именованных сущностей (имен, названий географических объектов, дат, номеров телефонов, адресов); определение эмоциональной окраски текста (sentiment analysis); поиск релевантных документов по запросу, а также их ранжирование; задача суммаризации (автоматическое составление краткого пересказа текста); автоматический перевод с одного языка на другой (машинный перевод); диалоговые системы и чат-боты; вопросно-ответные системы (выбор ответа из нескольких предложенных вариантов или вопросы с открытым ответом); кроме того, к NLP также относят задачу распознавания речи (Automated Speech Recognition, ASR). Для работы с такими данными есть несколько возможных режимов: Many-to-one. На вход подается последовательность объектов, на выходе один объект. Пример 2: классификация текстов или видео. Пример 2: тематическая классификация. По предложению нефиксированной длины генерируем вектор вероятностей упоминания заранее фиксированных тем во входном предложении. Размерность выходного вектора постоянна и равна количеству тем. One-to-many. На вход подается один объект, на выходе последовательность объектов. Пример: генерация заголовка к изображению (image captioning). Many-to-many. На входе и выходе последовательности нефиксированной длины. Примеры: машинный перевод, суммаризация текста, генерация заголовка к статье. Синхронизированный вариант many-to-many. На входе и выходе последовательности одинаковой длины, токены входной явно сопоставлены соответствующим токенам выходной. Пример: генерация покадровых субтитров к видео, PoS-tagging (part of speech tagging, для каждого слова в предложении предсказываем, что это за часть речи). sec Мы начнём с архитектур, в которых размер выхода предсказуемым образом зависит от размера входа: many-to-one и синхронизованном варианте many-to-many — но в итоге доберёмся и до остальных. Word Embeddings Перед тем, как рассказать об архитектурах, которые часто используются для работы с текстами, надо разобраться, каким образом можно кодировать текстовые данные: ведь нужно их превратить во что-то векторное, прежде чем подавать на вход нейросети. К векторизации текстов есть два базовых подхода: векторизовать текст целиком, превращая его в один вектор; векторизовать отдельные структурные единицы, превращая текст в последовательность векторов. Первые, статистические подходы к векторизации следовали первому подходу и рассматривали текст как неупорядоченный набор («мешок») токенов (обычно токенами являются слова). Тем самым, тексты «Я не люблю ML» и «Я люблю не ML» получали одинаковые векторизации, то есть по ходу терялась существенная информация. Поэтому мы лишь коротко упомянем о них. Обратимся теперь к другому подходу и подумаем, как сопоставить векторы (эмбеддинги) словам. Допустим, что у нас одно и то же",
        "Смысл метрических методов очень хорошо раскрывает фраза «Скажи мне, кто твой друг, и я скажу, кто ты». Алгоритмы этого класса почти не имеют фазы обучения. Вместо этого они просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут объекты, похожие на целевой. Такой процесс называют lazy learning, потому что никакого обучения, по сути, не происходит. Также метрические модели являются непараметрическими, потому что они не делают явных допущений о глобальных законах, которым подчиняются данные. Так, линейная регрессия основывается на предположении о том, что изучаемая закономерность линейная (с неизвестными коэффициентами, которые восстанавливаются по выборке), а линейная бинарная классификация — что существует гиперплоскость, неплохо разделяющая классы. Метрические методы же локальны: они исходят из допущения, что свойства объекта можно узнать, имея представление о его соседях. Указанные выше свойства могут быть полезными, особенно в случае сложно устроенных данных, для которых мы не можем придумать глобальную модель. Однако с другой стороны, из-за lazy learning алгоритм становится абсолютно неприменимым при большом количестве данных. Несмотря на то, что эти алгоритмы очень просты для понимания, они довольно точны и хорошо интерпретируемы — и часто используются как минимум в качестве бейзлайнов в разных задачах. В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методе k-ближайших соседей (k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах. Например, у алгоритмов поиска ближайших соседей, — неотъемлемой часть метода, — намного более широкая область применения. Плюс ко всему KNN — очень простой и легко интерпретируемый алгоритм, поэтому изучить его всё равно полезно. Мы обсудим подробнее его преимущества, недостатки, область его применения, а также возможные обобщения. Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей. Метод k-ближайших соседей (KNN) Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): 2 Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,"
      ]
    },
    {
      "index": 11,
      "question": "В DataFrame есть колонки с пропусками (числовые и категориальные). Как вы будете их обрабатывать?",
      "ground_truth": "import pandas as pd\r\nimport numpy as np\r\nfrom sklearn.impute import SimpleImputer\r\n\r\n# Создадим пример данных\r\ndf = pd.DataFrame({\r\n    'A': [1, 2, np.nan, 4, 5],\r\n    'B': ['cat', 'dog', np.nan, 'cat', 'dog'],\r\n    'C': [10, np.nan, np.nan, 40, 50]\r\n})\r\n\r\n# Для числовых - медиана\r\nnum_imputer = SimpleImputer(strategy='median')\r\ndf[['A', 'C']] = num_imputer.fit_transform(df[['A', 'C']])\r\n\r\n# Для категориальных - мода\r\ncat_imputer = SimpleImputer(strategy='most_frequent')\r\ndf[['B']] = cat_imputer.fit_transform(df[['B']])",
      "model_answer": "На основе предоставленного контекста, в котором рассматриваются методы обработки данных в библиотеках 🤗 Datasets и Pandas, а также общие подходы к работе с признаками в машинном обучении, можно предложить следующую стратегию обработки пропусков в DataFrame:\n\n1. **Разделение признаков по типам**: Первым шагом необходимо разделить колонки на числовые и категориальные, как это подразумевается в вопросе и встречается в контексте при обсуждении обработки признаков.\n\n2. **Для числовых колонок**:\n   - Заполнение средним или медианным значением по колонке — это стандартный подход, который позволяет сохранить распределение данных.\n   - В контексте упоминается, что для временных рядов можно использовать признаки, основанные на предыдущих значениях (например, `y_{t-1}, ..., y_{t-p}`). Это может быть адаптировано для заполнения пропусков в числовых последовательностях с использованием интерполяции или значений соседних строк.\n\n3. **Для категориальных колонок**:\n   - Заполнение наиболее частым значением (модой) — простой и эффективный метод.\n   - Создание отдельной категории для пропусков (например, \"Unknown\") — это позволяет модели учитывать факт отсутствия данных как отдельный сигнал.\n\n4. **Использование метрических методов**: В контексте упоминается метод k-ближайших соседей (KNN) как пример lazy learning. Его можно адаптировать для заполнения пропусков: для объекта с пропуском найти k ближайших объектов и взять среднее (для числовых) или моду (для категориальных) значений из соседей.\n\n5. **Интеграция с библиотеками**: Как показано в контексте, данные можно конвертировать между форматами (например, из Dataset в Pandas DataFrame). После заполнения пропусков в Pandas с помощью методов вроде `fillna()`, данные можно вернуть в исходный формат для дальнейшего обучения модели.\n\n6. **Учет временных зависимостей**: Если данные имеют временную структуру (как в примерах с временными рядами), заполнение должно учитывать сезонность и тренды, например, с помощью линейной регрессии по времени или других методов, упомянутых в контексте.\n\nВажно: Выбор конкретного метода зависит от природы данных и задачи, а также от доли пропусков. Если пропусков слишком много, может потребоваться более сложное моделирование или даже удаление колонок.",
      "contexts": [
        "Вопрос: Как линейная регрессия обрабатывает категориальные признаки?\nОтвет: Категориальные признаки преобразуются в числовую форму с помощью методов:",
        "'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'], num_rows: 206772 }) test: Dataset({ features: ['attention_mask', 'condition', 'date', 'drugName', 'input_ids', 'patient_id', 'rating', 'review', 'review_length', 'token_type_ids', 'usefulCount'], num_rows: 68876 }) }) ``` We get the same number of training features as before, but here we’ve kept all the old fields. If you need them for some post-processing after applying your model, you might want to use this approach. You’ve now seen how 🤗 Datasets can be used to preprocess a dataset in various ways. Although the processing functions of 🤗 Datasets will cover most of your model training needs, there may be times when you’ll need to switch to Pandas to access more powerful features, like `DataFrame.groupby()` or high-level APIs for visualization. Fortunately, 🤗 Datasets is designed to be interoperable with libraries such as Pandas, NumPy, PyTorch, TensorFlow, and JAX. Let’s take a look at how this works. ## From Dataset s to DataFrame s and back To enable the conversion between various third-party libraries, 🤗 Datasets provides a `Dataset.set_format()` function. This function only changes the *output format* of the dataset, so you can easily switch to another format without affecting the underlying *data format*, which is Apache Arrow. The formatting is done in place. To demonstrate, let’s convert our dataset to Pandas: ``` drug_dataset.set_format(\"pandas\") ``` Now when we access elements of the dataset we get a `pandas.DataFrame` instead of a dictionary: ``` drug_dataset[\"train\"][:3] ``` patient_id drugName condition review rating date usefulCount review_length 0 95260 Guanfacine adhd \"My son is halfway through his fourth week of Intuniv...\" 8.0 April 27, 2010 192 141 1 92703 Lybrel birth control \"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects...\" 5.0 December 14, 2009 17 134 2 138000 Ortho Evra birth control \"This is my first time using any form of birth control...\" 8.0 November 3, 2015 10 89 Let’s create a `pandas.DataFrame` for the whole training set by selecting all the elements of `drug_dataset[\"train\"]`: ``` train_df = drug_dataset[\"train\"][:] ``` > 🚨 Under the hood,Dataset.set_format()changes the return format for the dataset’s__getitem__()dunder method. This means that when we want to create a new object liketrain_dffrom aDatasetin the\"pandas\"format, we need to slice the whole dataset to obtain apandas.DataFrame. You can verify for yourself that the type ofdrug_dataset[\"train\"]isDataset, irrespective of the output format. From here we can use all the Pandas functionality that we want. For example, we can do fancy chaining to compute the class distribution among the `condition` entries: ``` frequencies = ( train_df[\"condition\"] .value_counts() .to_frame() .reset_index() .rename(columns={\"index\": \"condition\", \"count\": \"frequency\"}) ) frequencies.head() ``` condition frequency 0 birth control 27655 1 depression 8023 2 acne 5209 3 anxiety 4991 4 pain 4744 And once we’re done with our Pandas analysis, we can always create a new `Dataset` object by using the `Dataset.from_pandas()` function as follows: ``` from datasets import Dataset freq_dataset = Dataset.from_pandas(frequencies) freq_dataset ``` ``` Dataset({ features: ['condition', 'frequency'], num_rows: 819 }) ``` > ✏️Try it out!Compute",
        "В этом разделе вы познакомитесь с нейросетями для работы с данными, имеющими вид последовательностей некоторых токенов. Это может быть музыка или видео, временные ряды или траектория движения робота, последовательности аминокислот в белке или много чего ещё, но одним из самых богатых источников таких данных является Natural Language Processing (NLP). Как следует из названия, Natural Language Processing (обработка естественного языка) — это область data science, посвященная анализу текстов, написанных на естественных (человеческих) языках. С задачами обработки текста мы встречаемся каждый день, например, когда просим Siri или Алису включить любимую песню или добавить напоминание в календарь, когда используем автодополнение при вводе поискового запроса или проверяем орфографию и пунктуацию с помощью специальных программ. Вот ещё несколько примеров задач, относящихся к обработке естественного языка: классификация документов (по темам, рубрикам, жанрам и так далее); определение спама; определение частей речи; исправление орфографических ошибок и опечаток; поиск ключевых слов, синонимов / антонимов в тексте; распознавание именованных сущностей (имен, названий географических объектов, дат, номеров телефонов, адресов); определение эмоциональной окраски текста (sentiment analysis); поиск релевантных документов по запросу, а также их ранжирование; задача суммаризации (автоматическое составление краткого пересказа текста); автоматический перевод с одного языка на другой (машинный перевод); диалоговые системы и чат-боты; вопросно-ответные системы (выбор ответа из нескольких предложенных вариантов или вопросы с открытым ответом); кроме того, к NLP также относят задачу распознавания речи (Automated Speech Recognition, ASR). Для работы с такими данными есть несколько возможных режимов: Many-to-one. На вход подается последовательность объектов, на выходе один объект. Пример 2: классификация текстов или видео. Пример 2: тематическая классификация. По предложению нефиксированной длины генерируем вектор вероятностей упоминания заранее фиксированных тем во входном предложении. Размерность выходного вектора постоянна и равна количеству тем. One-to-many. На вход подается один объект, на выходе последовательность объектов. Пример: генерация заголовка к изображению (image captioning). Many-to-many. На входе и выходе последовательности нефиксированной длины. Примеры: машинный перевод, суммаризация текста, генерация заголовка к статье. Синхронизированный вариант many-to-many. На входе и выходе последовательности одинаковой длины, токены входной явно сопоставлены соответствующим токенам выходной. Пример: генерация покадровых субтитров к видео, PoS-tagging (part of speech tagging, для каждого слова в предложении предсказываем, что это за часть речи). sec Мы начнём с архитектур, в которых размер выхода предсказуемым образом зависит от размера входа: many-to-one и синхронизованном варианте many-to-many — но в итоге доберёмся и до остальных. Word Embeddings Перед тем, как рассказать об архитектурах, которые часто используются для работы с текстами, надо разобраться, каким образом можно кодировать текстовые данные: ведь нужно их превратить во что-то векторное, прежде чем подавать на вход нейросети. К векторизации текстов есть два базовых подхода: векторизовать текст целиком, превращая его в один вектор; векторизовать отдельные структурные единицы, превращая текст в последовательность векторов. Первые, статистические подходы к векторизации следовали первому подходу и рассматривали текст как неупорядоченный набор («мешок») токенов (обычно токенами являются слова). Тем самым, тексты «Я не люблю ML» и «Я люблю не ML» получали одинаковые векторизации, то есть по ходу терялась существенная информация. Поэтому мы лишь коротко упомянем о них. Обратимся теперь к другому подходу и подумаем, как сопоставить векторы (эмбеддинги) словам. Допустим, что у нас одно и то же",
        "вызвана тем, что люди обычно больше потребляют электричество днем, чем ночью. Недельная сезонность вызвана более высоким потреблением электричества по будням. Если бы мы посмотрели данные за несколько лет, то увидели бы еще одну сезонность – годовую, например, вызванную тем, что в теплое время года работает больше кондиционеров. ex Почему бы нам не построить прогноз простыми методами, например, линейной регрессией по времени? Общий тренд так можно уловить. Но в остатках (то есть в разности между истинными значениями и прогнозом) этой модели будет достаточно много информации, которую хотелось бы как-то учесть. ex Можно также добавить квадрат значения времени. Тогда можно уловить квадратичный тренд, но не более. ex Прогнозирование с помощью сведения к задаче регрессии Давайте для начала поймем, что мы вообще хотим сделать. Посмотрим на этот график, на котором показаны продажи одного из товаров в магазине за разные года. ts Мы знаем значения ряда (зеленые) до момента времени t t, в данном случае за 4 года с 2013 по 2016 включительно. Предположим также, что в данный момент мы отмечаем Новый год 2017. В этот момент мы хотели бы предсказать (синее) будущие значения ряда (оранжевое) за весь 2017 год на основе четырехлетней истории продаж. Основная идея – подадим известные (зеленые) значения ряда в какую-то регрессионную функцию, получив тем самым предсказания. При этом можем брать не все известные значения ряда, а только p p последних значений. Иначе говоря, модель имеет вид =f(y t−1 ,…,y t−p ), где f f – произвольная функция. Ее можно построить некоторым известным методом машинного обучения, например, линейной регрессией, решающими деревьями, бустингами, нейронными сетями (как сверточными, так и рекуррентными). Разберёмся, какие признаки мы подадим на вход регрессии. Признаки Общий принцип На практике при генерации идей о том, какие признаки можно создавать для построения модели, рекомендуется строить следующий график. На нем нужно отметить момент времени t t и мысленно поставить себя в этот момент времени. Затем нужно подумать, какие данные нам при этом доступны. В модель можно брать любые признаки, которые доступны к моменту времени t t. Если все данные поступают сразу, то можно брать все признаки, которые зависят только от значений до момента времени t t. В реальности часть данных может поступать с задержкой. Например, если данные загружаются в базу данных раз в сутки в полночь, то в полдень нам не доступны данные за последние 12 часов. 1 Также нужно помнить о том, на сколько времени вперед нужно сделать прогноз. Например, пусть у нас задача состоит в том, чтобы построить прогнозы продаж в магазине с целью планирования новых поставок. После того, как на основе прогноза мы примем решение о составе товаров в новой поставке, необходимо сначала собрать данные товары на складе, потом отправить машину в магазин, и затем еще разложить товар на полки в магазине. На эту процедуру может уходить от нескольких часов до нескольких дней. Тем самым еще до момента начала формирования новой поставки модель прогнозирования продаж должна построить прогноз спроса на товар к тому моменту, когда его выложат на полки. Даты Посмотрим на то, какие признаки можно извлечь Пусть дана какая-то дата: 13.04.2021 09:00. Отсюда можно получить следующие",
        "Смысл метрических методов очень хорошо раскрывает фраза «Скажи мне, кто твой друг, и я скажу, кто ты». Алгоритмы этого класса почти не имеют фазы обучения. Вместо этого они просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут объекты, похожие на целевой. Такой процесс называют lazy learning, потому что никакого обучения, по сути, не происходит. Также метрические модели являются непараметрическими, потому что они не делают явных допущений о глобальных законах, которым подчиняются данные. Так, линейная регрессия основывается на предположении о том, что изучаемая закономерность линейная (с неизвестными коэффициентами, которые восстанавливаются по выборке), а линейная бинарная классификация — что существует гиперплоскость, неплохо разделяющая классы. Метрические методы же локальны: они исходят из допущения, что свойства объекта можно узнать, имея представление о его соседях. Указанные выше свойства могут быть полезными, особенно в случае сложно устроенных данных, для которых мы не можем придумать глобальную модель. Однако с другой стороны, из-за lazy learning алгоритм становится абсолютно неприменимым при большом количестве данных. Несмотря на то, что эти алгоритмы очень просты для понимания, они довольно точны и хорошо интерпретируемы — и часто используются как минимум в качестве бейзлайнов в разных задачах. В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методе k-ближайших соседей (k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах. Например, у алгоритмов поиска ближайших соседей, — неотъемлемой часть метода, — намного более широкая область применения. Плюс ко всему KNN — очень простой и легко интерпретируемый алгоритм, поэтому изучить его всё равно полезно. Мы обсудим подробнее его преимущества, недостатки, область его применения, а также возможные обобщения. Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей. Метод k-ближайших соседей (KNN) Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): 2 Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто"
      ]
    },
    {
      "index": 12,
      "question": "Определить важность признаков в модели RandomForestClassifier?",
      "ground_truth": "from sklearn.ensemble import RandomForestClassifier\r\nimport matplotlib.pyplot as plt\r\n\r\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\r\nmodel.fit(X, y)\r\n\r\n# Важность признаков\r\nimportances = pd.DataFrame({\r\n    'feature': X.columns,\r\n    'importance': model.feature_importances_\r\n}).sort_values('importance', ascending=False)\r\n\r\nplt.barh(importances['feature'], importances['importance'])\r\nplt.xlabel('Feature Importance')\r\nplt.show()",
      "model_answer": "Основываясь на предоставленном контексте, можно выделить ключевые принципы, лежащие в основе определения важности признаков в модели `RandomForestClassifier`:\n\n1.  **Критерии информативности**: В контексте обсуждаются критерии, которые используются для оценки качества разбиения в деревьях решений (составляющих случайный лес). Два основных критерия для задач классификации — это **критерий Джини (Gini impurity)** и **энтропийный критерий (information gain)**. Важность признака в лесу напрямую связана с тем, насколько эффективно он уменьшает выбранный критерий неопределенности (например, энтропию или индекс Джини) при разбиениях во всех деревьях.\n\n2.  **Принцип расчета важности (на основе контекста)**: Хотя в явном виде формула не приведена, из описания логики деревьев следует, что важность признака определяется его совокупным вкладом в уменьшение неопределенности (энтропии или индекса Джини) во всех узлах всех деревьев леса. Признак, который чаще и/или на более ранних (крупных) разбиениях позволяет значительно уменьшить неопределенность, получает более высокий вес.\n\n3.  **Обработка категориальных признаков**: Контекст подчеркивает, что для эффективной работы с категориальными признаками в деревьях их значения упорядочивают. Для бинарной классификации — по возрастанию доли положительного класса, для регрессии (или при использовании MSE-критерия) — по среднему значению целевой переменной. Эта упорядоченность позволяет находить оптимальные сплиты. В `RandomForestClassifier` подобные методы используются для оценки важности категориальных признаков наравне с числовыми.\n\n4.  **Интерпретируемость важности (на основе примера с Джини)**: Критерий Джини имеет вероятностную интерпретацию: он равен матожиданию доли объектов, которые будут классифицированы неправильно, если метка выбирается случайно согласно распределению классов в узле. Признак, сильно уменьшающий этот критерий, тем самым повышает «чистоту» (однородность) дочерних узлов по классам, что и является мерой его важности для модели.\n\n**Итог:** В `RandomForestClassifier` важность признаков определяется **статистическим агрегированием** того, насколько успешно каждый признак разделяет данные, используя критерии неопределенности (Джини или энтропию), по всем деревьям в ансамбле. Это позволяет ранжировать признаки по их вкладу в predictive power модели.",
      "contexts": [
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа",
        "Сравним результаты Легко заметить, что каждая из двух моделей лучше классификатора-пустышки, однако давайте попробуем сравнить их между собой. С точки зрения error rate модели практически одинаковы: 5/143 для леса против 4/143 для SVM. Посмотрим на структуру ошибок чуть более внимательно: лес — (FP = 4, FN = 1), SVM — (FP = 1, FN = 3). Какая из моделей предпочтительнее? Замечание: Мы сравниваем несколько классификаторов на основании их предсказаний на отложенной выборке. Насколько ошибки данных классификаторов зависят от разбиения исходного набора данных? Иногда в процессе оценки качества мы будем получать модели, чьи показатели эффективности будут статистически неразличимыми. Пусть мы учли предыдущее замечание и эти модели действительно статистически значимо ошибаются в разную сторону. Мы встретились с очевидной вещью: на матрицах нет отношения порядка. Когда мы сравнивали dummy-классификатор и случайный лес с помощью Accuracy, мы всю сложную структуру ошибок свели к одному числу, так как на вещественных числах отношение порядка есть. Сводить оценку модели к одному числу очень удобно, однако не стоит забывать, что у вашей модели есть много аспектов качества. Что же всё-таки важнее уменьшить: FP или FN? Вернёмся к задаче: FP — доля доброкачественных опухолей, которым ошибочно присваивается метка злокачественной; FN — доля злокачественных опухолей, которые классификатор пропускает. В такой постановке становится понятно, что при сравнении выиграет модель с меньшим FN (то есть лес в нашем примере), ведь каждая не обнаруженная опухоль может стоить человеческой жизни. Рассмотрим теперь другую задачу: по данным о погоде предсказать, будет ли успешным запуск спутника. FN в такой постановке — это ошибочное предсказание неуспеха, то есть не более, чем упущенный шанс (если вас, конечно не уволят за срыв сроков). С FP всё серьёзней: если вы предскажете удачный запуск спутника, а на деле он потерпит крушение из-за погодных условий, то ваши потери будут в разы существеннее. Итак, из примеров мы видим, что в текущем виде введенная нами доля ошибочных классификаций не даст нам возможности учесть неравную важность FP и FN. Поэтому введем две новые метрики: точность и полноту. Точность и полнота Accuracy - это метрика, которая характеризует качество модели, агрегированное по всем классам. Это полезно, когда классы для нас имеют одинаковое значение. В случае, если это не так, accuracy может быть обманчивой. Рассмотрим ситуацию, когда положительный класс это событие редкое. Возьмем в качестве примера поисковую систему - в нашем хранилище хранятся миллиарды документов, а релевантных к конкретному поисковому запросу на несколько порядков меньше. Пусть мы хотим решить задачу бинарной классификации «документ d релевантен по запросу q». Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем"
      ]
    },
    {
      "index": 13,
      "question": "Напишите метод определения оптимизации гиперпараметров модели используя библиотеку sklearn?",
      "ground_truth": "from sklearn.model_selection import GridSearchCV\r\n\r\nparam_grid = {\r\n    'n_estimators': [50, 100, 200],\r\n    'max_depth': [None, 10, 20],\r\n    'min_samples_split': [2, 5, 10]\r\n}\r\n\r\nmodel = RandomForestClassifier(random_state=42)\r\ngrid_search = GridSearchCV(model, param_grid, \r\n                          cv=3, \r\n                          scoring='accuracy',\r\n                          n_jobs=-1)\r\ngrid_search.fit(X, y)\r\n\r\nprint(f'Best params: {grid_search.best_params_}')\r\nprint(f'Best score: {grid_search.best_score_:.3f}')",
      "model_answer": "На основе предоставленного контекста, который в основном посвящён общим концепциям машинного обучения (переобучение, валидация, онлайн-обучение), можно дать следующий ответ, соответствующий стилю и терминологии контекста.\n\nДля определения оптимальных гиперпараметров модели с использованием библиотеки `scikit-learn` (sklearn) стандартным и рекомендуемым подходом является **GridSearchCV** в сочетании с **K-Fold кросс-валидацией**, что напрямую следует из методологии, описанной в контексте для предотвращения переобучения и точной оценки обобщающей способности.\n\nВот базовый метод:\n\n1.  **Разделение данных:** Разделите исходный набор данных на обучающую (`train`) и тестовую (`test`) выборки. Тестовая выборка должна быть отложена и использована **только для финальной оценки** модели, выбранной в результате оптимизации.\n2.  **Определение сетки параметров:** Создайте словарь (`param_grid`), где ключами являются имена гиперпараметров модели, а значениями — списки возможных значений для перебора (например, `'learning_rate': [0.01, 0.1, 0.3]`).\n3.  **Создание объекта GridSearchCV:** Инициализируйте `GridSearchCV`, передав ему:\n    *   Модель-оценщик (estimator).\n    *   Сетку параметров (`param_grid`).\n    *   Метрику для оценки качества (scoring).\n    *   Стратегию кросс-валидации, например, `cv=5` для 5-fold кросс-валидации. Это соответствует упомянутой в контексте практике \"K-Fold кросс-валидации для более точной оценки, где данные многократно разделяются на обучающую и валидационную выборки\".\n4.  **Обучение (подбор параметров):** Вызовите метод `.fit()` на объекте `GridSearchCV`, передав обучающие данные. Алгоритм автоматически выполнит кросс-валидацию для каждой комбинации гиперпараметров из сетки, обучая модель на `k-1` подвыборках и валидируя на оставшейся, чтобы выбрать конфигурацию с наилучшим средним качеством на валидационных фолдах.\n5.  **Оценка лучшей модели:** После подбора лучшую модель (с оптимальными гиперпараметрами, переобученную на всей предоставленной обучающей выборке) можно получить через `grid_search.best_estimator_`. Её итоговую обобщающую способность следует оценить на отложенной тестовой выборке с помощью `.score()` или расчёта выбранной метрики.\n\n**Пример кода (иллюстрация):**\n```python\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# 1. Разделение данных\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# 2. Определение модели и сетки параметров\nmodel = GradientBoostingRegressor()\nparam_grid = {\n    'n_estimators': [100, 200],\n    'learning_rate': [0.01, 0.1, 0.3], # Пример из контекста\n    'max_depth': [3, 5]\n}\n\n# 3. Создание объекта GridSearchCV с кросс-валидацией\ngrid_search = GridSearchCV(estimator=model,\n                           param_grid=param_grid,\n                           scoring='neg_mean_squared_error', # Используем MSE, как в примере про переобучение\n                           cv=5, # K-Fold CV\n                           n_jobs=-1)\n\n# 4. Обучение и подбор параметров\ngrid_search.fit(X_train, y_train)\n\n# 5. Оценка лучшей модели на тестовой выборке\nbest_model = grid_search.best_estimator_\ntest_score = best_model.score(X_test, y_test)\nprint(f\"Лучшие параметры: {grid_search.best_params_}\")\nprint(f\"Качество на тесте: {test_score}\")\n```\n\n**Альтернативные методы, упомянутые в контексте косвенно:**\n*   **RandomizedSearchCV:** Эффективная альтернатива полному перебору, особенно когда пространство параметров велико. Случайным образом выбирает и проверяет заданное количество комбинаций.\n*   **Последовательная оптимизация (BayesianOptimization, Optuna):** Более сложные методы, которые строят вероятностную модель функции качества от гиперпараметров и выбирают следующую точку для проверки на основе предыдущих результатов. В контексте об этом говорят в разделе про онлайн-обучение и эволюцию методов оптимизации (SGD, Adam), но уже применительно к выборке гиперпараметров.\n\nЭтот методология позволяет систематически находить конфигурацию модели, которая обеспечивает баланс между сложностью и обобщающей способностью, минимизируя риск переобучения, что и является основной целью, описанной в контексте.",
      "contexts": [
        "Вопрос: * Используется для настройки гиперпараметров модели и выбора оптимальной конфигурации.\n                        * Пример: выбор лучшего значения learningrate в градиентном бустинге.\n                        * На практике часто применяется K-Fold кросс-валидация для более точной оценки, где данные многократно разделяются на обучающую и валидационную выборки.",
        "Какие существуют методы борьбы с переобучением?\nОтвет: Переобучение возникает, когда модель слишком хорошо \"запоминает\" тренировочные данные, теряя способность обобщать на новых. Методы борьбы включают:",
        "какая у построенной модели обобщающая способность, то есть насколько она способна выучить общие закономерности, присущие не только обучающей выборке, и давать адекватные предсказания на новых данных. Для того чтобы предохранить себя от конфуза, поступают обычно так: делят выборку с данными на две части: обучающую выборку и тестовую выборку (train и test). Обучающую выборку используют для собственно обучения модели, а метрики считают на тестовой. Такой подход позволяет отделить модели, которые просто удачно подстроились к обучающим данным, от моделей, в которых произошла генерализация (generalization), то есть от таких, которые на самом деле кое-что поняли о том, как устроены данные, и могут выдавать полезные предсказания для объектов, которых не видели. Например, рассмотрим три модели регрессионной зависимости, построенные на одном и том же синтетическом датасете с одним-единственным признаком. Жёлтым нарисованы точки обучающей выборки. Здесь мы представим, что есть «истинная» закономерность (пунктир), которая искажена шумом (погрешности измерения, влияние других факторов и т.д.). three Левая, линейная модель недостаточно хороша: она сделала, что могла, но плохо приближает зависимость, особенно при маленьких и при больших x x. Правая «запомнила» всю обучающую выборку (и в самом деле, чтобы вычислить значение этой функции, нам надо знать координаты всех исходных точек) вместо того, чтобы моделировать исходную зависимость. Наконец, центральная, хоть и не проходит через точки обучающей выборки, довольно неплохо моделирует истинную зависимость. Алгоритм, избыточно подстроившийся под данные, называют переобученным. С увеличением сложности модели ошибка на обучающей выборке падает. Во многих задачах очень сложная модель будет работать примерно так же, как модель, «просто запомнившая всю обучающую выборку», но с генерализацией всё будет плохо: ведь выученные закономерности будут слишком специфическими, подогнанными под то, что происходит на обучающей выборке. Мы видим это на трёх графиках сверху: линейная функция очень проста, но и закономерность приближает лишь очень грубо; на правом же графике мы видим довольно хитрую функцию, которая точно подобрана под значения из обучающей выборки, но явно слишком эксцентрична, чтобы соответствовать какой-то природной зависимости. Оптимальная же генерализация достигается на модели не слишком сложной и не слишком простой. В качестве иллюстрации для того же самого датасета рассмотрим модели вида y = многочлен степени D y = многочлен степени D Ясно, что с ростом D D сложность модели растёт, и она достигает всё лучшего качества на обучающей выборке. А что, если у нас есть ещё тестовая выборка? Каким будет качество на ней? Вот так могут выглядеть графики среднеквадратичного отклонения (MSE) для обучающей и тестовой выборок: train Мы видим здесь типичную для классических моделей картину: MSE на обучающей выборке падает (может быть, даже до нуля), а на тестовой сперва падает, а затем начинает снова расти. Замечание. Для моделей глубинного обучения всё немного интереснее: в некоторых ситуациях есть грань, за которой метрика на тестовой выборке снова начинает падать. Но об этом в своё время. Пока давайте запомним, что слишком сложная модель — это вредно, а переобучение — боль. Точный способ выбрать алгоритм оптимальной сложности по данной задаче нам пока неизвестен, хотя какую-то теоретическую базу имеющимся философским наблюдениям мы дадим в главе про теорию обучения; при этом есть хорошо продуманная методология сравнения разных моделей и выбора среди них оптимальной —",
        "О чём раздел про онлайн-обучение, кому и зачем его читать? Во многих случаях обучение ML-модели ― это однократный процесс, после которого она не меняется и только используется для предсказания. А что, если к нам постоянно поступает новая информация и мы должны её учитывать? Тогда модель должна уметь обновляться при поступлении нового объекта или батча объектов. Грубо говоря, этим и занимается онлайн-оптимизация. Можно заметить, что обновление модели на батче объектов проходит и в процессе стохастической оптимизации, ― и это сходство не случайно. Оказывается, что все известные вам методы стохастической оптимизации первого порядка ― такие как SGD, AdaGrad, Adam, AMSgrad и другие ― являются в первую очередь алгоритмами онлайн-обучения. Чтобы в этом убедиться, достаточно открыть эти статьи и увидеть, для какой задачи выводятся гарантии на сходимость. Постановка задачи онлайн-обучения является одновременно математически простой и очень общей, соединяя три больших темы: «Классическое» онлайн обучение. Стохастическую оптимизацию на фиксированном датасете. Мы покажем, что любой алгоритм онлайн обучения можно переформулировать, как алгоритм стохастической оптимизации; при этом из гарантий на сходимость, полученных для онлайн обучения, автоматически будет следовать сходимость на фиксированном датасете. Adversarial обучение. Данный текст является в первую очередь систематизирующим. Мы постараемся достичь следующих целей: Подведем единую математическую базу, необходимую для вдумчивого чтения статей по оптимизации. Это будет полезно ML-теоретикам. Покажем, как исторически развивались методы оптимизации, как из одного метода получался другой, какие проблемы они решали и ― главное ― актуальны ли эти проблемы сейчас. Разберём все «именные» методы оптимизации на набор базовых концепций и покажем, как вы можете самостоятельно их сочетать, создавая оптимальный метод для решения своей задачи. Спойлер: базовых концепций намного меньше, чем наименований методов. Эти знания будут полезны ML-инженерам. Пройдемся по относительно нишевым темам, таким как разреженные методы регуляризации 1/2 , и рассмотрим наилучшие методы оптимизации для них. Такие методы невозможно получить в стандартной постановке стохастической оптимизации. Эти знания будут полезны ML-инженерам, занимающимся рекомендательными системами. В параграфе «Введение в онлайн-обучение», которую вы читаете сейчас, вы познакомитесь с общей постановкой задачи онлайн-обучения, а также с семейством алгоритмов Follow the Regularized Leader (FTRL), которое включает в себя все методы первого порядка. Кроме того, вы узнаете, как сводить задачи стохастической оптимизации к задачам онлайн-обучения и увидите, что этот переход позволяет строить более эффективные методы стохастической оптимизации, особенно для разреженных регуляризаторов вроде L 1 L 1 . В параграфе «Адаптивный FTRL» вы узнаете, как улучшить сходимость алгоритмов стохастической оптимизации с помощью регуляризаторов и каковы гарантии сходимости для регуляризованных задач. Это позволит вывести AdaGrad как наилучший адаптивный метод для онлайн-оптимизации. В параграфе «Регуляризация в онлайн-обучении» мы снова поговорим о регуляризации, но на этот раз речь пойдёт о регуляризаторах, которые накладывают на решение определённые органичения, например, разреженность. Вы сможете с новой стороны взглянуть на разреживающие свойства L 1 L 1 -регуляризаторов. Кроме того, мы получим не достижимые с помощью обычных SGD/AdaGrad результаты для разреженных 1/2 регуляризаторов. В параграфе «Стохастическая оптимизация в Deep Learning» мы перейдём к методам оптимизации в глубоких нейросетях. Вас ждёт краткий исторический обзор и мотивация появления двух важных модификаций AdaGrad ― Adam и RMSprop. Мы покажем, что эти методы ломаются вокруг критических точек, и поговорим",
        "сложной для большинства практических задач и при этом слишком тяжёлой в плане вычислений. В первых параграфах мы будем рассматривать в основном предсказательные модели, то есть модели вида y=f(x), которые пытаются уловить зависимость между признаковым описанием x x объекта и таргетом y y. Но порой мы будем иметь дело и с моделями данных: например, «такой-то признак имеет нормальное распределение». Чаще всего предсказательные модели мы будем брать из некоторого параметрического семейства y=f w (x), где w w — параметры, которые мы будем подбирать по данным. Для примера давайте возьмём задачу предсказания цены квартиры. В качестве класса моделей выберем константные функции f(x)=c (то есть будем для всех квартир предсказывать одно и то же значение цены). Поскольку значение не зависит от x x, нам не очень важно, в каком виде получено признаковое описание: это может быть набор совершенно любых сведений о квартире. Не забудем зафиксировать метрику качества — среднее абсолютное отклонение (mean absolute error, она же MAE). min ⁡ f , MAE(f,X,y)=L(f,X,y)= N 1 i=1 ∑ N ∣f(x i )−y i ∣→ f min , где f f — это модель (та самая, f(x)=c), X=(x 1 ,…,x N ) — обучающие примеры (данные о квартирах, которые мы смогли достать), y=(y 1 ,…,y N ) — правильные ответы (то есть цены на известные нам квартиры). Чтобы найти минимум MAE, возьмём производную от выражения min ⁡ f , N 1 i=1 ∑ N ∣c−y i ∣→ f min , и приравняем её к нулю: L(f,X,y)= N 1 i=1 ∑ N sign(c−y i )=0 #{i∣y i <c}−#{i∣y i >c}=0 Нам подходят точки c c, для которых число y i y i , строго меньших c c, равно числу y i y i , строго больших c c. Таким образом, нам подходит медиана набора ,…,y f(x)=median(y). Вопрос на подумать. Давайте теперь в задаче предсказания цены квартиры рассмотрим метрику среднеквадратичное отклонение (MSE): MSE(f,X,y)= N 1 i=1 ∑ N (f(x i )−y i ) 2 Каким будет оптимальное значение параметра c c для константной модели f(x)=c? Прекрасно, значит, в классе константных функций мы можем найти оптимальную модель. Может быть, это можно сделать и в каком-нибудь более интересном классе? Этому вопросу и будет посвящена большая часть нашей книги. Классический курс ML состоит из описания классов моделей и способов работы с ними. Несмотря на то что для решения большинства практических задач на сегодня достаточно знать только два типа моделей — градиентный бустинг на решающих деревьях и нейросетевые модели — мы постараемся рассказать и про другие, чтобы развить у вас глубинное понимание предмета и дать возможность не только использовать лучшие сложившиеся практики, но и, при вашем желании, участвовать в проработке новых идей и поиске новых методов — уже в роли исследователя, а не просто инженера. Кроме выбора модели важен также выбор алгоритма обучения. Алгоритм обучения — это процедура, которая превращает обучающую выборку в обученную модель. Скажем, в примере выше для константной модели мы в качестве алгоритма обучения использовали поиск нуля градиента. Как мы увидим дальше, градиентные методы используются для обучения многих моделей, и это очень богатый класс методов оптимизации, из которого порой не",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,"
      ]
    },
    {
      "index": 14,
      "question": "Какие метрики вы будете использовать для бинарной классификации? Напишите метод",
      "ground_truth": "from sklearn.metrics import classification_report, confusion_matrix, roc_curve\r\n\r\n# Предположим, что у нас есть предсказания\r\ny_true = [0, 1, 0, 1, 0]\r\ny_pred = [0, 0, 0, 1, 1]\r\ny_prob = [0.1, 0.4, 0.2, 0.8, 0.7]\r\n\r\nprint(classification_report(y_true, y_pred))\r\nprint(f'Confusion Matrix:\\n{confusion_matrix(y_true, y_pred)}')\r\n\r\n# ROC-AUC\r\nfpr, tpr, _ = roc_curve(y_true, y_prob)\r\nroc_auc = auc(fpr, tpr)\r\nprint(f'ROC-AUC: {roc_auc:.3f}')",
      "model_answer": "На основе контекста, для бинарной классификации можно использовать следующие метрики, в зависимости от задачи и особенностей данных:\n\n1. **Accuracy (Точность)** — доля верных предсказаний среди всех объектов.  \n   `Accuracy = (TP + TN) / (TP + TN + FP + FN)`  \n   **Ограничение:** может быть неинформативна при сильном дисбалансе классов.\n\n2. **Precision (Точность-полнота, в русской терминологии — точность)** — доля верно предсказанных положительных объектов среди всех объектов, предсказанных как положительные.  \n   `Precision = TP / (TP + FP)`  \n   Полезна, когда важна минимизация ложноположительных срабатываний.\n\n3. **Recall (Полнота)** — доля верно найденных положительных объектов среди всех объектов положительного класса.  \n   `Recall = TP / (TP + FN)`  \n   Полезна, когда важна минимизация ложноотрицательных срабатываний.\n\n4. **F1-мера** — среднее гармоническое Precision и Recall.  \n   `F1 = 2 * (Precision * Recall) / (Precision + Recall)`  \n   Учитывает баланс между Precision и Recall.\n\n5. **Fβ-мера** — обобщённая версия F1, где параметр β задаёт важность Recall относительно Precision.  \n   `Fβ = (1 + β²) * (Precision * Recall) / (β² * Precision + Recall)`\n\n6. **Log-loss (логистическая функция потерь)** — используется для оценки качества предсказанных вероятностей.  \n   `Log-loss = -1/N * Σ [y_i * log(q(x_i)) + (1 - y_i) * log(1 - q(x_i))]`  \n   Применяется, когда важна калиброванность вероятностей.\n\n7. **Brier score** — квадратичная ошибка для вероятностей, также может использоваться для оценки калиброванности.\n\n**Метод выбора метрики:**\n- При сбалансированных классах и общей оценке — **Accuracy**.\n- При дисбалансе классов — **Precision, Recall, F1**.\n- Если важны вероятности (например, для последующего принятия решений) — **Log-loss** или **Brier score**.\n- Для ранжирования или поиска (например, рекомендации) — **Precision@k**, **Recall@k**.\n\nПример реализации на Python для основных метрик (кроме log-loss):\n\n```python\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\ndef evaluate_binary_classification(y_true, y_pred, y_proba=None):\n    metrics = {\n        'accuracy': accuracy_score(y_true, y_pred),\n        'precision': precision_score(y_true, y_pred),\n        'recall': recall_score(y_true, y_pred),\n        'f1': f1_score(y_true, y_pred)\n    }\n    if y_proba is not None:\n        from sklearn.metrics import log_loss, brier_score_loss\n        metrics['log_loss'] = log_loss(y_true, y_proba)\n        metrics['brier_score'] = brier_score_loss(y_true, y_proba)\n    return metrics\n```",
      "contexts": [
        "бы всегда выдающий 1 2 2 1 классификатор. Не обязательно брать квадратичную ошибку; сгодится и наш любимый log-loss: log log i=1 logq(x i )+(1−y i )log(1−q(x i ))) Это же и помогает высветить ограничения подхода, если вспомнить рассуждения о калиброванности логистической регрессии. Для достаточно гладких классификатора и датасета brier score и log-loss будут адекватными средствами оценки, но если нет — возможно всякое. Вопрос на засыпку: а как быть, если у нас классификация не бинарная, а многоклассовая? Что такое хорошо калиброванный классификатор? Как это определить численно? Как заставить произвольный классификатор предсказывать вероятности? Мы не будем про это рассказывать, но призываем читателя подумать над этим самостоятельно или, например, посмотреть туториал с ECML KDD 2020. Знак вопроса Пройдите квиз по параграфу Чтобы закрепить пройденный материал Сообщить об ошибке Предыдущий параграф 4.3. Обобщённые линейные модели Как прокачать линейную модель с помощью распределений из экспоненциального класса Следующий параграф 4.5. Генеративный подход к классификации Как использовать распределение меток классов в задаче классификации. LDA, QDA и наивный байес",
        "следующий день. Стилизация текста. Например, перевод на бюрократический язык: «Пиппина и Мерри похитили!» ↦ ↦ «Граждане Тук, Перегрин Паладинович, 2990 года рождения, и Брендибак, Мериадок Сарадокович, 2982 года рождения, были похищены неустановленными лицами». Детектирование котиков на изображении. Обучение робокота запрыгивать на стол из произвольной позы. Поиск наборов товаров, которые посетители супермаркета часто покупают вместе. Вопрос на подумать. Ранжирование — это задача с таргетом из конечного упорядоченного множества (1,…,K). Казалось бы, её запросто можно было бы рассматривать как задачу классификации на K K классов или задачу регрессии. В чём же проблема? Почему так не делают? Критерии качества По обучающей выборке мы хотим построить модель, предсказания которой достаточно хороши. Что вообще значит «достаточно хороши»? Не понимая, чего мы хотим добиться, мы не предложим хорошего решения, поэтому нужно внимательно отнестись к выбору метрик качества. Возможно, вы уже участвовали в соревнованиях по анализу данных. На таких соревнованиях метрику организатор выбирает за вас, и она, как правило, непосредственным образом связана с результатами предсказаний. Но на практике всё бывает намного сложнее. Например, мы хотим: решить, сколько коробок с бананами нужно завтра привезти в конкретный магазин, чтобы минимизировать количество товара, который не будет выкуплен, и минимизировать вероятность того, что покупатель к концу дня не найдёт желаемый продукт на полке; увеличить счастье пользователей от работы с нашим сервисом, чтобы пользователи стали лояльнее, а сервис мог получать стабильный прогнозируемый доход; решить, нужно ли направить пациента на дополнительное медицинское обследование. В каждом конкретном случае может возникать целая иерархия метрик. Самый верхний уровень – это бизнес-метрики, например, будущий доход сервиса. Их трудно измерить в моменте, они сложным образом зависят от совокупности всех наших усилий, не только связанных с машинным обучением. Онлайн (online) метрики – это характеристики работающей системы, с помощью которых мы надеемся оценить, что будет с бизнес-метриками. Например, это может быть: – Медианная длина сессии в онлайн-игре. Можно предположить, что пользователь, который долго сидит в игре – это довольный пользователь. – Среднее количество бананов на полках во всех магазинах торговой сети в конце дня. Не всегда плоды наших трудов оцениваются числами. Многое может зависеть от субъективного восприятия людей, и для того, чтобы оценить их реакцию до выпуска в продакшен, применяется оценка специально нанятыми людьми – асессорами. Например, так можно оценивать, получилось ли у нас улучшить качество машинного перевода или релевантность выдачи в поисковой системе. Офлайн (offline) метрики могут быть измерены до введения модели в эксплуатацию, например, по историческим данным. В задачах, в которых нужно предсказывать какой-то конкретный таргет, офлайн метрики обычно оценивают отклонение предсказаний модели от истинных значений таргета. Например, это может быть точность предсказания, то есть число верно угаданных значений, или среднеквадратичное отклонение. Асессорскую оценку тоже можно считать офлайн-метрикой В этой книге речь в основном пойдёт об офлайновых метриках и о функциях потерь. И прежде, чем вы начнёте знакомиться с методами решения задач обучения с учителем, полезно посмотреть, какими бывают метрики качества. Вот несколько примеров: для задачи постановки диагноза хорошими метриками могут быть, например, доля правильно поставленных диагнозов или доля больных, которым удалось поставить правильный диагноз (а вы поняли разницу?); для задачи предсказания цены квартиры метрикой качества может быть",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные"
      ]
    },
    {
      "index": 15,
      "question": "Задача: В банке система мониторинга мошеннических операций срабатывает с точностью 99% (вероятность обнаружить мошенническую операцию = 0.99). При этом вероятность ложного срабатывания (система сработала на легальную операцию) = 1%. Известно, что лишь 0.1% всех операций являются мошенническими.\r\nВопрос: Если система сработала на конкретную операцию, какова вероятность того, что операция действительно мошенническая?",
      "ground_truth": "Решение (Теорема Байеса):\r\nОбозначим:\r\nM = операция мошенническая\r\nA = система сработала (аларм)\r\n\r\nДано:\r\nP(A|M) = 0.99 (чувствительность)\r\nP(A|не M) = 0.01 (ложное срабатывание)\r\nP(M) = 0.001 (базовая распространенность)\r\nНужно найти P(M|A).\r\nПо формуле Байеса:\r\nP(M|A) = [P(A|M) * P(M)] / P(A)\r\nP(A) = P(A|M)P(M) + P(A|не M)P(не M)\r\n= (0.99 * 0.001) + (0.01 * 0.999)\r\n= 0.00099 + 0.00999 = 0.01098\r\nТогда:\r\nP(M|A) = (0.99 * 0.001) / 0.01098 ≈ 0.09016 ≈ 9.02%\r\nВывод: Несмотря на высокую точность системы, из-за низкой базовой распространенности мошенничества, лишь ~9% срабатываний являются истинно положительными. Это классический пример важности учёта априорной вероятности.",
      "model_answer": "На основе предоставленного контекста о бинарной классификации, метриках и формуле Байеса, решим задачу.\n\nЭто классическая задача на применение **формулы Байеса**. Она идеально иллюстрирует, почему при сильном дисбалансе классов (здесь 99.9% легальных операций против 0.1% мошеннических) одной высокой точности (Precision) модели недостаточно, и важно считать условную вероятность.\n\n**Дано:**\n*   `P(Сработала | Мошенническая)` = 0.99 (Истинно-положительные, TPR, Recall модели)\n*   `P(Сработала | Легальная)` = 0.01 (Ложно-положительные, FPR)\n*   `P(Мошенническая)` = 0.001 (Распространенность положительного класса)\n*   `P(Легальная)` = 1 - 0.001 = 0.999\n\n**Найти:** `P(Мошенническая | Сработала)`\n\n**Решение по формуле Байеса:**\n`P(B|A) = [P(A|B) * P(B)] / P(A)`\n\nГде:\n*   Событие **A** — система сработала.\n*   Событие **B** — операция мошенническая.\n\n1.  **Вычислим вероятность срабатывания системы вообще (`P(A)`)** по формуле полной вероятности (описана в контексте):\n    `P(Сработала) = P(Сработала | Мошенническая)*P(Мошенническая) + P(Сработала | Легальная)*P(Легальная)`\n    `P(Сработала) = (0.99 * 0.001) + (0.01 * 0.999) = 0.00099 + 0.00999 = 0.01098`\n\n2.  **Применим формулу Байеса:**\n    `P(Мошенническая | Сработала) = [P(Сработала | Мошенническая) * P(Мошенническая)] / P(Сработала)`\n    `P(Мошенническая | Сработала) = (0.99 * 0.001) / 0.01098 ≈ 0.00099 / 0.01098 ≈ 0.09016`\n\n**Ответ:** Вероятность того, что операция действительно мошенническая при срабатывании системы, составляет примерно **9.02%**.\n\n**Интерпретация в терминах контекста:**\nЭтот результат наглядно демонстрирует ключевую мысль из начала предоставленного текста: при сильном **дисбалансе классов** (0.1% мошеннических операций) даже модель с выдающимися `Recall` (99%) и низким `FPR` (1%) может иметь **низкую точность (`Precision`)** в конкретном сценарии.\n\n*   **Precision** в этой задаче — это и есть искомая вероятность `P(Мошенническая | Сработала)`.\n*   Несмотря на высокий `Recall` (99% мошеннических операций найдено), из-за огромного количества легальных операций даже небольшой `FPR` (1%) приводит к большому числу ложных срабатываний (`FP`).\n*   В результате **доля истинно-положительных срабатываний среди всех срабатываний (`TP/(TP+FP)`)** оказывается низкой (~9%).\n\nЭто классический пример, почему в задачах с дисбалансом (мошенничество, диагностика редких болезней) нельзя полагаться только на accuracy и необходимо внимательно анализировать `Precision`, `Recall` и вероятности после применения теоремы Байеса.",
      "contexts": [
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "формуле полной вероятности P(A)=P(A∣B 1 )P(B 1 )+P(A∣B 2 )P(B 2 )+P(A∣B 3 )P(B 3 )+P(A∣B 4 )P(B 4 ). Вероятности P ( B k ) P(B k ) даны в условии, оттуда же находим, что P(A∣B 1 )=1, P(A∣B 2 )=P(B 2 )+P(B P(A∣B 3 )=P(B 3 )+P(B P(A∣B 4 )=P(B 4 ). Подставляя численные значения, получаем P ( A ) = 0.337 + ( 0.375 + 0.079 ) ⋅ 0.375 + ( 0.209 + 0.079 ) ⋅ 0.209 + 0.07 9 2 = 0.573683. P(A)=0.337+(0.375+0.079)⋅0.375+(0.209+0.079)⋅0.209+0.079 2 =0.573683. Упражнение. Решите предыдущий пример, выбирая в качестве разбиения набор событий C k C k , каждое из которых заключается в том, что реципиент имеет группу k k. Формула полной вероятности легко обобщается на случай счётного числа попарно несовместных событий B k B k , а также на случай обусловливания по некоторому событию C C, например: P(A∣C)= n ∑ P(A∣B n ,C)P(B n ∣C). Формула Байеса Заметим, что вероятность P(A∩B) можно записать двумя способами P(B∣A)P(A)=P(A∩B)=P(A∣B)P(B). Оставим P(B∣A) в левой части и получим формулу Байеса. Формула Байеса. Для любых событий A A, B B c положительной вероятностью P(B∣A)= P(A) P(A∣B)P(B) . Для вычисления знаменателя в формуле Байеса часто используется формула полной вероятности. Упражнение. Среди определенной группы людей вероятность некоторой болезни 0.02. Тест, позволяющий выявить болезнь, несовершенен. На больном он дает позитивный результат в 98 случаях из 100, и, кроме того, он дает позитивный результат в 4 случаях из 100 на здоровом. Найдите вероятность того, что человек, на котором тест дал положительный результат, действительно болен. Для непрерывного случая тоже есть своя формула полной вероятности, см. раздел про условную вероятность. Независимые события События A A и B B называются независимыми, если P(A∣B)=P(A), то есть информация о реализации события B B никак не влияет на вероятность события A A. По определению условной вероятности независимость событий A A и B B эквивалентна тому, что P(A∩B)=P(A)P(B). Последнее равенство годится для определения независмости событий A A и B B даже в том случае, если P(A)=0 или P(B)=0. Пример. В полной колоде карт находится 52 52 карты: 4 4 масти от двойки до туза. Вероятность вытащить туза равна P(Ace)= 52 4 = 13 1 , карту пиковой масти — P(♠)= 52 13 = 4 1 . Эти события независимы, поскольку в пересечении этих событий лежит ровно одна карта — туз пик, вероятность появления которого равна =P(Ace)P(♠). Пусть теперь вытаскивается сразу две карты. Зависимы ли события «вытащены две карты пиковой масти» и «вытащены туз и король»? Посчитаем: P(♠♠)= 52⋅51 13⋅12 663 . P(AK)= 52⋅51 32 = 663 8 . Вероятность вытащить туза и короля пик равна 1326 ≈ 0.00075 1326 1 ≈0.00075, что отличается от 11271 ≈ 0.00071 P(♠♠)P(AK)= 11271 8 ≈0.00071. Таким образом, эти события зависимы. События ,…,A n попарно независимы, если P(A i ∩A j )=P(A i )P(A j ) при i ≠ j i  =j. Эти же события независимы в совокупности, если P(A i 1 ∩…∩A i m )= k=1 ∏ m P(A i k ) для любого набора индексов для любого набора индексов 1⩽i 1 <…<i",
        "Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные предсказания и разное качество на отложенной выборке. Так, чем ниже порог отсечения, тем больше объектов модель будет относить к положительному классу. Как в этом случае оценить качество модели? AUC Пусть мы хотим учитывать ошибки на объектах обоих классов. При уменьшении порога отсечения мы будем находить (правильно предсказывать) всё большее число положительных объектов, но также и неправильно предсказывать положительную метку на всё большем числе отрицательных объектов. Естественным кажется ввести две метрики TPR и FPR: TPR (true positive rate) — это полнота, доля положительных объектов, правильно предсказанных положительными: TPR= P TP = TP+FN TP FPR (false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными: FPR= N FP = FP+TN FP Обе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называется ROC-кривой (receiver operating characteristics curve, сокращённо ROC curve). Следующий интерактивный график поможет вам понять поведение ROC-кривой. Желтая и синяя кривые показывают распределение предсказаний классификатора на объектах положительного и отрицательного классов соответственно. То есть значения на оси X (на графике с двумя гауссианами) мы получаем из классификатора. Если классификатор идеальный, — две кривые разделимы по оси X, — то на правом графике мы получаем ROC-кривую (0,0)->(0,1)->(1,1), площадь под которой равна 1. Если классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5. Поэкспериментируйте с разными вариантами распределения предсказаний по классам и посмотрите, как меняется ROC-кривая. Чем лучше классификатор разделяет два класса, тем больше площадь (area under curve) под ROC-кривой — и мы можем использовать её в качестве метрики. Эта метрика называется AUC и она работает благодаря следующему свойству ROC-кривой: AUC равен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил, то есть предсказание классификатора на первом объекте больше: AUC AUC= i=1 ∑ N j=1 ∑ N I[y i <y j ] i=1 ∑ N j=1 ∑ N I[y i <y j ]I ′ [f(x i )<f(x 0.5 [f(x i )<f(x j )]= ⎩ ⎨ ⎧ 0, 0.5 1, f(x i )>f(x j ) f(x i )=f(x j ) f(x i )<f(x I[y i <y j ]={ Чтобы детальнее разобраться, почему это так, советуем вам обратиться к материалам А.Г.Дьяконова. В каких случаях лучше отдать предпочтение этой метрике? Рассмотрим следующую задачу: некоторый сотовый оператор хочет научиться предсказывать, будет ли клиент пользоваться его услугами через месяц. На первый взгляд кажется, что задача сводится к бинарной классификации с метками 1, если клиент останется"
      ]
    },
    {
      "index": 16,
      "question": "Задача: В A/B-тесте новая рекомендательная система (вариант B) показала конверсию 12.5% на выборке из 1000 пользователей, тогда как старая система (A) — 10% на выборке из 1200 пользователей.\r\nВопрос: Статистически значимо ли улучшение на уровне доверия 95%? Рассчитайте p-value.",
      "ground_truth": "Решение (Z-тест для долей):\r\np₁ = 0.125, n₁ = 1000\r\np₂ = 0.10, n₂ = 1200\r\nОбъединенная доля:\r\np̂ = (x₁ + x₂)/(n₁ + n₂) = (125 + 120)/(1000 + 1200) = 245/2200 ≈ 0.11136\r\nСтандартная ошибка разности:\r\nSE = √[ p̂*(1-p̂)*(1/n₁ + 1/n₂) ]\r\n= √[0.11136*0.88864*(1/1000 + 1/1200)]\r\n≈ √[0.09898 * 0.001833] ≈ √0.0001814 ≈ 0.01347\r\nZ-статистика:\r\nZ = (p₁ - p₂) / SE = (0.125 - 0.10) / 0.01347 ≈ 1.856\r\nДля двустороннего теста на уровне α=0.05, критическое значение Z ≈ 1.96.\r\nНаш Z ≈ 1.856 < 1.96 → различие не является статистически значимым на уровне 95%.\r\np-value ≈ 2 * P(Z > 1.856) ≈ 2 * 0.0317 ≈ 0.0634 (т.е. > 0.05).",
      "model_answer": "На основе предоставленного контекста, который фокусируется на проверке статистической значимости коэффициентов в регрессии, можно выделить общий принцип: для проверки гипотезы о равенстве нулю (например, разницы между коэффициентами или, в данном случае, разницы между конверсиями) используются z-тест или t-тест. Рассчитывается p-value, и если оно меньше уровня значимости (α = 0.05 для 95% доверия), то эффект считается статистически значимым.\n\nХотя в контексте напрямую не разбирается пример A/B-теста, логика проверки гипотез остается той же. Для ответа на ваш вопрос необходимо выполнить следующие шаги:\n\n1.  **Сформулировать гипотезы:**\n    *   **H₀ (нулевая гипотеза):** Конверсии в группах A и B равны (p_B - p_A = 0). Улучшения нет.\n    *   **H₁ (альтернативная гипотеза):** Конверсии различаются (p_B ≠ p_A). В контексте вашей задачи, скорее всего, предполагается односторонняя проверка (p_B > p_A), но для расчета p-value, как в вопросе, обычно используют двусторонний тест.\n\n2.  **Рассчитать статистику теста.** Для сравнения долей (конверсий) с большими выборками обычно применяется **z-тест**. Формула для z-статистики:\n    `z = (p_B - p_A) / SE`, где `SE = sqrt( p*(1-p) * (1/n_A + 1/n_B) )`, а `p` — объединенная доля (общая конверсия).\n\n3.  **Рассчитать p-value** на основе полученного z-значения, используя стандартное нормальное распределение.\n\n**Применение к вашим данным:**\n*   p_A = 0.10, n_A = 1200\n*   p_B = 0.125, n_B = 1000\n*   Объединенная доля: `p = (0.10*1200 + 0.125*1000) / (1200+1000) = (120 + 125) / 2200 ≈ 0.11136`\n*   Стандартная ошибка (SE): `SE = sqrt( 0.11136 * (1-0.11136) * (1/1200 + 1/1000) ) ≈ sqrt(0.11136*0.88864*0.001833) ≈ sqrt(0.0001813) ≈ 0.01346`\n*   z-статистика: `z = (0.125 - 0.10) / 0.01346 ≈ 1.857`\n\n4.  **Определить значимость.** Для двустороннего теста p-value = `2 * P(Z > |1.857|)`. Используя таблицу z-значений или статистический калькулятор, находим, что `P(Z > 1.857) ≈ 0.0316`. Следовательно, **p-value ≈ 2 * 0.0316 = 0.0632**.\n\n**Вывод:** Поскольку рассчитанное **p-value (≈0.063) больше уровня значимости α=0.05**, у нас **нет достаточных оснований отвергнуть нулевую гипотезу** на уровне доверия 95%. Улучшение конверсии с 10% до 12.5% **не является статистически значимым** при данных объемах выборки.\n\n*Примечание:* В контексте также упоминается, что статистические пакеты проводят такие проверки автоматически, что соответствует практике: в реальной работе вы бы использовали функцию `prop.test` в R или аналогичную в Python для получения точного p-value.",
      "contexts": [
        "Вопрос: \nОтвет: * Используются z-тест или t-тест, чтобы проверить гипотезу, что коэффициент равен нулю.\n* Рассчитывается p-value: если оно меньше уровня значимости (α), коэффициент считается значимым.\n* Статистические пакеты автоматически проводят такие проверки при оценке модели.\nПроверка статистической значимости коэффициентов в логистической регрессии – пример с расчётом стандартной ошибки (SE)",
        "Ситуация:\nВы строите модель логистической регрессии, чтобы предсказать, купит ли человек продукт (y=1) или нет (y=0). В модели есть два признака:",
        "формуле полной вероятности P(A)=P(A∣B 1 )P(B 1 )+P(A∣B 2 )P(B 2 )+P(A∣B 3 )P(B 3 )+P(A∣B 4 )P(B 4 ). Вероятности P ( B k ) P(B k ) даны в условии, оттуда же находим, что P(A∣B 1 )=1, P(A∣B 2 )=P(B 2 )+P(B P(A∣B 3 )=P(B 3 )+P(B P(A∣B 4 )=P(B 4 ). Подставляя численные значения, получаем P ( A ) = 0.337 + ( 0.375 + 0.079 ) ⋅ 0.375 + ( 0.209 + 0.079 ) ⋅ 0.209 + 0.07 9 2 = 0.573683. P(A)=0.337+(0.375+0.079)⋅0.375+(0.209+0.079)⋅0.209+0.079 2 =0.573683. Упражнение. Решите предыдущий пример, выбирая в качестве разбиения набор событий C k C k , каждое из которых заключается в том, что реципиент имеет группу k k. Формула полной вероятности легко обобщается на случай счётного числа попарно несовместных событий B k B k , а также на случай обусловливания по некоторому событию C C, например: P(A∣C)= n ∑ P(A∣B n ,C)P(B n ∣C). Формула Байеса Заметим, что вероятность P(A∩B) можно записать двумя способами P(B∣A)P(A)=P(A∩B)=P(A∣B)P(B). Оставим P(B∣A) в левой части и получим формулу Байеса. Формула Байеса. Для любых событий A A, B B c положительной вероятностью P(B∣A)= P(A) P(A∣B)P(B) . Для вычисления знаменателя в формуле Байеса часто используется формула полной вероятности. Упражнение. Среди определенной группы людей вероятность некоторой болезни 0.02. Тест, позволяющий выявить болезнь, несовершенен. На больном он дает позитивный результат в 98 случаях из 100, и, кроме того, он дает позитивный результат в 4 случаях из 100 на здоровом. Найдите вероятность того, что человек, на котором тест дал положительный результат, действительно болен. Для непрерывного случая тоже есть своя формула полной вероятности, см. раздел про условную вероятность. Независимые события События A A и B B называются независимыми, если P(A∣B)=P(A), то есть информация о реализации события B B никак не влияет на вероятность события A A. По определению условной вероятности независимость событий A A и B B эквивалентна тому, что P(A∩B)=P(A)P(B). Последнее равенство годится для определения независмости событий A A и B B даже в том случае, если P(A)=0 или P(B)=0. Пример. В полной колоде карт находится 52 52 карты: 4 4 масти от двойки до туза. Вероятность вытащить туза равна P(Ace)= 52 4 = 13 1 , карту пиковой масти — P(♠)= 52 13 = 4 1 . Эти события независимы, поскольку в пересечении этих событий лежит ровно одна карта — туз пик, вероятность появления которого равна =P(Ace)P(♠). Пусть теперь вытаскивается сразу две карты. Зависимы ли события «вытащены две карты пиковой масти» и «вытащены туз и король»? Посчитаем: P(♠♠)= 52⋅51 13⋅12 663 . P(AK)= 52⋅51 32 = 663 8 . Вероятность вытащить туза и короля пик равна 1326 ≈ 0.00075 1326 1 ≈0.00075, что отличается от 11271 ≈ 0.00071 P(♠♠)P(AK)= 11271 8 ≈0.00071. Таким образом, эти события зависимы. События ,…,A n попарно независимы, если P(A i ∩A j )=P(A i )P(A j ) при i ≠ j i  =j. Эти же события независимы в совокупности, если P(A i 1 ∩…∩A i m )= k=1 ∏ m P(A i k ) для любого набора индексов для любого набора индексов 1⩽i 1 <…<i",
        ")≈δ(w− w MAP p(y 0 ∣x 0 , w MAP )=N(y 0 x 0 w MAP ,σ 2 ) Собственно, видно, что в этом случае Пример в примере. Рассмотрим полюбившуюся уже нам задачу приближения функции многочленом степени не выше 3 3 (в которой мы строим модели с =1). Для N = 8 N=8 мы получали такую картинку: 14 Если оценить по приведённым выше формулам p(y 0 ∣x 0 ,X train ,y train ) для разных x 0 x 0 , то можно убедиться, что модель в большей степени уверена в предсказаниях для точек из областей, где было больше точек из обучающей выборки: 14 Байесовский подход и дообучение моделей До сих пор мы в основном рассуждали о моделях машинного обучения как о чём-то, что один раз обучается и дальше навсегда застывает в таком виде, но в жизни такое скорее редкость. Мы пока не будем обсуждать изменчивость истинных зависимостей во времени, но даже если истина неизменна, к нам могут поступать новые данные, которые очень хотелось бы использовать для дообучения модели. Обычные, не байесовские вероятностные модели не предоставляют таких инструментов. Оценку максимального правдоподобия придётся пересчитывать заново (хотя, конечно, можно схитрить, использовав старое значение в качестве начального приближения при итеративной оптимизации). Байесовский же подход позволяет оформить дообучения в виде простой и элегантной формулы: при добавлении новых данных N+1 ,y N+1 ),…,(x M ,y M ) имеем p(w∣(x i ,y i ) i=1 M )= p((y i ) i=N+1 M ) p((y i ) i=N+1 M ∣(x i ) i=N+1 M )p(w∣(x i ,y i ) i=1 N ) Байесовский подход к выбору модели: мотивация Нам часто приходится выбирать: дерево или случайный лес, линейная модель или метод ближайших соседей; да, собственно, и внутри наших вероятностных моделей есть параметры (скажем, дисперсия шума ), которые надо бы подбирать. Но как? В обычной ситуации мы выбираем модель, обученную на выборке train ,y train ) в зависимости от того, как она себя ведёт на валидационной выборке val ,y val ) (сравниваем правдоподобие или более сложные метрики) — или же делаем кросс-валидацию. Но как сравнивать модели, выдающие распределение? Ответим вопросом на вопрос: а как вообще сравнивать модели? Назначение любой модели — объяснять мир вокруг нас, и её качество определяется именно тем, насколько хорошо она справляется с этой задачей. Тестовая выборка — это хороший способ оценки, потому что она показывает, насколько вписываются в модель новые данные. Но могут быть и другие соображения, помогающие оценить качество модели. Пример №1 Аналитик Василий опоздал на работу. Своему руководителю он может предложить самые разные объяснения — и это будет выработанная на одном обучающем примере модель, описывающая причины опоздания и потенциально позволяющая руководителю принять решение о том, карать ли Василия. Конечно, руководитель мог бы принять изложенную Василием модель к сведению, подождать, пока появятся другие опоздавшие, и оценить её, так скажем, на тестовой выборке, но стоит ли? Давайте рассмотрим несколько конкретных примеров: Модель «Василий опоздал, потому что так получилось», то есть факт опоздания — это просто ни от чего не зависящая случайная величина. Такая модель плоха тем, что (а) не предлагает, на самом деле, никакого объяснения тому",
        "Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные предсказания и разное качество на отложенной выборке. Так, чем ниже порог отсечения, тем больше объектов модель будет относить к положительному классу. Как в этом случае оценить качество модели? AUC Пусть мы хотим учитывать ошибки на объектах обоих классов. При уменьшении порога отсечения мы будем находить (правильно предсказывать) всё большее число положительных объектов, но также и неправильно предсказывать положительную метку на всё большем числе отрицательных объектов. Естественным кажется ввести две метрики TPR и FPR: TPR (true positive rate) — это полнота, доля положительных объектов, правильно предсказанных положительными: TPR= P TP = TP+FN TP FPR (false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными: FPR= N FP = FP+TN FP Обе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называется ROC-кривой (receiver operating characteristics curve, сокращённо ROC curve). Следующий интерактивный график поможет вам понять поведение ROC-кривой. Желтая и синяя кривые показывают распределение предсказаний классификатора на объектах положительного и отрицательного классов соответственно. То есть значения на оси X (на графике с двумя гауссианами) мы получаем из классификатора. Если классификатор идеальный, — две кривые разделимы по оси X, — то на правом графике мы получаем ROC-кривую (0,0)->(0,1)->(1,1), площадь под которой равна 1. Если классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5. Поэкспериментируйте с разными вариантами распределения предсказаний по классам и посмотрите, как меняется ROC-кривая. Чем лучше классификатор разделяет два класса, тем больше площадь (area under curve) под ROC-кривой — и мы можем использовать её в качестве метрики. Эта метрика называется AUC и она работает благодаря следующему свойству ROC-кривой: AUC равен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил, то есть предсказание классификатора на первом объекте больше: AUC AUC= i=1 ∑ N j=1 ∑ N I[y i <y j ] i=1 ∑ N j=1 ∑ N I[y i <y j ]I ′ [f(x i )<f(x 0.5 [f(x i )<f(x j )]= ⎩ ⎨ ⎧ 0, 0.5 1, f(x i )>f(x j ) f(x i )=f(x j ) f(x i )<f(x I[y i <y j ]={ Чтобы детальнее разобраться, почему это так, советуем вам обратиться к материалам А.Г.Дьяконова. В каких случаях лучше отдать предпочтение этой метрике? Рассмотрим следующую задачу: некоторый сотовый оператор хочет научиться предсказывать, будет ли клиент пользоваться его услугами через месяц. На первый взгляд кажется, что задача сводится к бинарной классификации с метками 1, если клиент останется",
        "Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные предсказания и разное качество на отложенной выборке. Так, чем ниже порог отсечения, тем больше объектов модель будет относить к положительному классу. Как в этом случае оценить качество модели? AUC Пусть мы хотим учитывать ошибки на объектах обоих классов. При уменьшении порога отсечения мы будем находить (правильно предсказывать) всё большее число положительных объектов, но также и неправильно предсказывать положительную метку на всё большем числе отрицательных объектов. Естественным кажется ввести две метрики TPR и FPR: TPR (true positive rate) — это полнота, доля положительных объектов, правильно предсказанных положительными: TPR= P TP = TP+FN TP FPR (false positive rate) — это доля отрицательных объектов, неправильно предсказанных положительными: FPR= N FP = FP+TN FP Обе эти величины растут при уменьшении порога. Кривая в осях TPR/FPR, которая получается при варьировании порога, исторически называется ROC-кривой (receiver operating characteristics curve, сокращённо ROC curve). Следующий интерактивный график поможет вам понять поведение ROC-кривой. Желтая и синяя кривые показывают распределение предсказаний классификатора на объектах положительного и отрицательного классов соответственно. То есть значения на оси X (на графике с двумя гауссианами) мы получаем из классификатора. Если классификатор идеальный, — две кривые разделимы по оси X, — то на правом графике мы получаем ROC-кривую (0,0)->(0,1)->(1,1), площадь под которой равна 1. Если классификатор случайный (предсказывает одинаковые метки положительным и отрицательным объектам), то мы получаем ROC-кривую (0,0)->(1,1), площадь под которой равна 0.5. Поэкспериментируйте с разными вариантами распределения предсказаний по классам и посмотрите, как меняется ROC-кривая. Чем лучше классификатор разделяет два класса, тем больше площадь (area under curve) под ROC-кривой — и мы можем использовать её в качестве метрики. Эта метрика называется AUC и она работает благодаря следующему свойству ROC-кривой: AUC равен доле пар объектов вида (объект класса 1, объект класса 0), которые алгоритм верно упорядочил, то есть предсказание классификатора на первом объекте больше: AUC AUC= i=1 ∑ N j=1 ∑ N I[y i <y j ] i=1 ∑ N j=1 ∑ N I[y i <y j ]I ′ [f(x i )<f(x 0.5 [f(x i )<f(x j )]= ⎩ ⎨ ⎧ 0, 0.5 1, f(x i )>f(x j ) f(x i )=f(x j ) f(x i )<f(x I[y i <y j ]={ Чтобы детальнее разобраться, почему это так, советуем вам обратиться к материалам А.Г.Дьяконова. В каких случаях лучше отдать предпочтение этой метрике? Рассмотрим следующую задачу: некоторый сотовый оператор хочет научиться предсказывать, будет ли клиент пользоваться его услугами через месяц. На первый взгляд кажется, что задача сводится к бинарной классификации с метками 1, если клиент останется"
      ]
    },
    {
      "index": 17,
      "question": "Задача: В методе главных компонент (PCA) для датасета с 10 признаками мы получили следующие собственные значения ковариационной матрицы: [4.2, 2.1, 1.8, 1.1, 0.5, 0.3, 0.2, 0.1, 0.05, 0.05].\r\nВопрос: Сколько главных компонент нужно выбрать, чтобы сохранить 90% дисперсии данных?",
      "ground_truth": "Решение:\r\nОбщая дисперсия = сумма всех собственных значений = 4.2+2.1+1.8+1.1+0.5+0.3+0.2+0.1+0.05+0.05 = 10.4.\r\n\r\nНакапливаем доли:\r\n1-я компонента: 4.2/10.4 ≈ 40.38%\r\n2-я: (4.2+2.1)/10.4 ≈ 60.58%\r\n3-я: (4.2+2.1+1.8)/10.4 ≈ 77.88%\r\n4-я: +1.1 → (8.2)/10.4 ≈ 78.85% (ошибка в расчетах, пересчитаем)\r\n\r\nПравильно:\r\n1-я: 4.2/10.4 = 0.4038\r\n2-я: (4.2+2.1)/10.4 = 6.3/10.4 = 0.6058\r\n3-я: (6.3+1.8)/10.4 = 8.1/10.4 = 0.7788\r\n4-я: (8.1+1.1)/10.4 = 9.2/10.4 = 0.8846\r\n5-я: (9.2+0.5)/10.4 = 9.7/10.4 = 0.9327\r\n\r\nОтвет: Нужно 5 компонент, так как на 4-й компоненте накопленная дисперсия ≈ 88.5% (<90%), а на 5-й ≈ 93.3% (>90%).",
      "model_answer": "Чтобы сохранить 90% дисперсии данных, нужно выбрать главные компоненты, кумулятивная доля дисперсии которых достигает или превышает 0.9.\n\n**Шаги решения:**\n1. **Вычислите общую дисперсию:**  \n   Сумма всех собственных значений:  \n   4.2 + 2.1 + 1.8 + 1.1 + 0.5 + 0.3 + 0.2 + 0.1 + 0.05 + 0.05 = **10.4**.\n\n2. **Рассчитайте долю дисперсии для каждой компоненты:**\n   - PC1: 4.2 / 10.4 ≈ 0.4038 (40.38%)\n   - PC2: 2.1 / 10.4 ≈ 0.2019 (20.19%)\n   - PC3: 1.8 / 10.4 ≈ 0.1731 (17.31%)\n   - PC4: 1.1 / 10.4 ≈ 0.1058 (10.58%)\n   - PC5: 0.5 / 10.4 ≈ 0.0481 (4.81%)\n   - Остальные дают меньший вклад.\n\n3. **Вычислите кумулятивную (накопленную) дисперсию:**\n   - PC1: 0.4038\n   - PC1 + PC2: 0.4038 + 0.2019 = 0.6057 (60.57%)\n   - PC1 + PC2 + PC3: 0.6057 + 0.1731 = 0.7788 (77.88%)\n   - PC1 + PC2 + PC3 + PC4: 0.7788 + 0.1058 = **0.8846 (88.46%)**\n   - PC1 + PC2 + PC3 + PC4 + PC5: 0.8846 + 0.0481 = **0.9327 (93.27%)**\n\n4. **Определите минимальное число компонент:**  \n   Кумулятивная дисперсия достигает 90% только после добавления пятой главной компоненты (93.27% > 90%).\n\n**Ответ:** Чтобы сохранить 90% дисперсии данных, необходимо выбрать **5 главных компонент**.\n\n*Это согласуется с идеей PCA как метода понижения размерности, описанного в контексте: мы выбираем подмножество компонент, которое сохраняет основную информацию (дисперсию) данных.*",
      "contexts": [
        "Вопрос: * Преобразованные данные позволяют лучше понимать вклад каждого признака.",
        "Какие существуют методы нормализации данных?\nОтвет: ",
        "Вопрос: Как проверить наличие мультиколлинеарности в данных?\nОтвет: Используются методы:",
        "алгоритма работают на уменьшение среднего квадрата евклидова расстояния от объектов до центров их кластеров: k=1 ∑ K i=1 I[a(x i )=k] На шаге отнесения объектов к одному из кластеров мы выбираем кластер с ближайшим центроидом, то есть минимизируем каждое слагаемое в Φ 0 Φ 0 : все потенциально большие слагаемые мы зануляем, а оставляем ненулевыми только наименьшие из возможных (при условии фиксирования центров кластеров). На шаге пересчёта центров кластеров мы выбираем центр таким образом, чтобы при фиксированном наборе объектов, относящихся к кластеру, для всех k k минимизировать выражение, стоящее под суммой по i=1 I[a(x i )=k] Здесь уже становится принципиально, что мы определяем квадрат расстояния как квадрат разности векторов, так как именно отсюда при дифференцировании по μ k μ k и записи необходимого условия экстремума получается, что центры кластеров нужно пересчитывать как средние арифметические x i x i , принадлежащих кластеру. Этих соображений, конечно, недостаточно, чтобы утверждать, что мы найдём минимум Φ 0 Φ 0 . Более того, гарантии того, что мы найдём глобальный минимум, вообще говоря, нет. Однако, потратив чуть больше усилий, можно доказать, что процесс сойдётся в один из локальных минимумов. Также можно справедливо заметить, что, так как любой центр кластера — это среднее арифметическое входящих в кластер объектов x i x i , на выборке фиксированного размера есть лишь конечное множество потенциальных центров кластеров. Если предположить, что в ходе работы K-means не зацикливается, отсюда следует, что рано или поздно центры кластеров не изменятся на следующем шаге и алгоритм сойдётся. При этом фактическая сходимость, конечно же, происходит задолго до полного перебора всех возможных центров кластеров. Иерархическая агломеративная кластеризация Другой классический метод кластеризации — это иерархическая кластеризация. Иногда дополнительно уточняют: иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации на агломеративные (agglomerative) и дивизивные, или дивизионные (divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. 19 Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Расстояния в иерархической кластеризации Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное",
        "двух шагов, обоснованность применения различных метрик (расстояний между точками, а не метрик качества 😃 или функций близости связана с тем, «ломают» они какой-либо из этих шагов или нет. Первый шаг с отнесением объектов к ближайшим центрам не зависит от вида метрики. Второй шаг предполагает пересчёт центров как среднего арифметического входящих в кластер точек, и вот здесь будет подвох: к оптимальности выбора центров в среднем арифметическом приводит именно евклидова метрика (подробнее в разделе «Что оптимизирует K-means»). Однако на практике никто не мешает использовать метод и без должного обоснования, поэтому можно экспериментировать с любыми расстояниями, с той лишь оговоркой, что не будет никаких теоретических гарантий, что метод сработает. Наиболее распространённая альтернатива евклидовой метрике — это косинусная мера близости векторов (она особенно популярна в задачах анализа текстов): CosineSimilarity(μ ⋅∥x При её использовании стоит не забывать, что косинусная мера — это функция близости, а не расстояние, так что чем больше её значения, тем ближе друг к другу векторы. Mini-batch K-means Несложно заметить, что, если считать K K и размерность пространства признаков константами, оба шага алгоритма работают за O ( n ) O(n), где n — количество объектов обучающей выборки. Отсюда возникает идея ускорения работы алгоритма. В mini-batch K-means мы не считаем шаги сразу на всей выборке, а на каждой итерации выбираем случайную подвыборку (мини-батч) и работаем на ней. В случае когда исходная выборка очень велика, переход к пакетной обработке не приводит к большой потере качества, зато значительно ускоряет работу алгоритма. Понижение размерности С другой стороны, вычисление расстояний и средних делается за O ( d ) O(d), где d d — размерность пространства признаков, так что другая идея ускорения K-means — это предварительно понизить размерность пространства признаков (с помощью PCA или эмбеддингов). Особенно удачно эта идея работает в задачах кластеризации текстов, когда K-means применяют на эмбеддингах слов: получается выиграть не только в скорости работы, но и в интерпретируемости результатов кластеризации. Кстати, сам алгоритм кластеризации тоже можно использовать как метод понижения размерности. Если вы решаете задачу обучения с учителем и пространство признаков очень разнообразно (то есть обучающая выборка не даёт вам достаточно статистики при столь большом числе признаков), можно выполнить кластеризацию объектов выборки на 500 или 1000 кластеров и оперировать попаданием объектов в какой-то кластер как признаком. Такой подход называется квантизацией пространства признаков (feature space quantization) и часто помогает на практике, когда нужно огрубить признаки, добавить им интерпретируемости или же, наоборот, обезличить. Хрестоматийный пример такого использования кластеризации — метод bag of visual words, расширяющий bag of words из анализа текстов на работу с изображениями. Идея метода в том, чтобы строить признаковое описание изображений на основе входящих в него фрагментов: так, изображения с лицами будут содержать фрагменты с носом, глазами, ртом, а изображения с машинами — колёса, зеркала, двери. Но проблема здесь в том, что нарезать такие фрагменты из обучающей выборки и искать точные совпадения в новых примерах изображений, которые нужно классифицировать, — безнадёжная затея. В жизни фрагменты изображений не повторяются в других изображениях с попиксельной точностью. Решение этой проблемы оказалось возможным при помощи алгоритмов кластеризации (исторически использовался именно K-means): фрагменты изображений из обучающей выборки кластеризовали на",
        "что в процессе обучения нам потребуется слишком много оперативной памяти; Мы считаем, что в данных есть шум или что часть признаков связаны соотношением приближённой линейной зависимости — иными словами, мы уверены, что значительную часть информации можно закодировать меньшим числом признаков Мы уже обсуждали, что это можно получить, построив приближённое разложение: X⁡N×D ∼ B⁡N×T ⋅ C⁡T×D N×D X ∼ N×T B ⋅ T×D C Математика помогает. Матрица имеет ранг T T тогда и только тогда, когда она представляется в виде B⁡NtimesS ⋅ C⁡S×D NtimesS B ⋅ S×D C для S = T S=T и не представляется в таком виде для меньших S S. Доказывать это мы не будем, но подметим, что приблизить датасет линейной смесью T T признаков — это то же самое, что приблизить матрицу X X матрицей X ^ X ^ ранга T T . Качество приближения. Нам, конечно же, хочется, чтобы приближение было наилучшим — скажем, в том смысле, чтобы разность X − B C X−BC была минимальной в каком-либо смысле. Можно предложить много разных метрик; остановимся на двух: Норма Фробениуса. Представим, что матрица A=(X−BC) — это просто вектор из N × D N×D чисел, который зачем-то записали в виде прямоугольной таблицы. Тогда его норму можно записать в виде ∥A∥ fro = i,j ∑ a ij 2 = tr(A T A) Эту норму (а точнее, её квадрат) легко оптимизировать. Операторная l 2 l 2 -норма. Вычислять её тяжко, а уж оптимизировать вообще непонятно как, зато звучит круто. Идея в том, что отображения можно сравнивать в зависимости от того, как оно действует на векторы: чем больше оно умеет удлинять векторы — тем оно «больше»: ∥ A ∥ 2 = sup ∥A∥ 2 =sup{ ∣v∣ ∣Av∣ ∣v∈R D } Поскольку ∣λv∣ ∣A(λv)∣ = ∣v∣ ∣Av∣ , достаточно брать супремум только по векторам единичной длины, то есть по единичной сфере. Так как это компакт, непрерывная функция v↦∣Av∣ достигает на нём своего максимального значения, то есть мы можем переписать ∥ A ∥ 2 = sup ∥A∥ 2 =sup{∣Av∣∣v∈R D ,∣v∣=1} Смесь объектов Мы считаем, что каждый из N N объектов нашего исходного датасета — смесь (то есть линейная комбинация) R R скрытых объектов: Decomp2 Такая интерпретация может быть полезна, например, в ситуации, когда объекты — это записи с каждого из нескольких микрофонов в помещении, признаки — фреймы, а скрытые объекты — это голоса отдельных людей. Также данную модель можно интерпретировать как что-то вроде поиска типичных объектов. Отдельные представления для объектов и признаков Эту интерпретацию лучше всего пояснить на примере. Пусть объекты нашего датасета соответствуют пользователям интернет-магазина, а признаки — товарам, причём в клетке с индексом ( i , j ) (i,j) записана единица, если пользователь интересовался товаром, и ноль — если нет (или, в более общей ситуации, рейтинги, которые пользователи ставят товарам). Decomp3 При перемножении матриц B B и C C на ( i , j ) (i,j)-м месте произведении стоит скалярное произведение i i-й строки B B и j j-го столбца C C. Таким образом, степень релевантности товара пользователю моделируется скалярным произведением (напрашивается сравнение с косинусным расстоянием) вектора, представляющего i i-го"
      ]
    },
    {
      "index": 18,
      "question": "Почему в Random Forest при выборе признаков на каждом сплите используют случайное подмножество признаков?",
      "ground_truth": "Это делается для того, чтобы снизить корреляцию между деревьями в лесу и улучшить общую производительность модели. Если все деревья будут использовать одни и те же признаки, они будут более похожи друг на друга, что приведёт к менее разнообразным решениям.\r\n\r\nС точки зрения bias-variance decomposition мы хотим строить максимально разнообразные деревья и как можно больше их. То есть мы строим экспертов в своей области (по подмножеству данных и признаков), а потом их усредняем.",
      "model_answer": "На основе предоставленного контекста можно дать следующий ответ:\n\nВ Random Forest (Случайном лесе) при выборе признаков на каждом разбиении (сплите) используют случайное подмножество признаков для **уменьшения корреляции между деревьями** в ансамбле, что является ключевым для повышения его обобщающей способности.\n\nЭтот механизм напрямую связан с принципами, описанными в контексте:\n\n1.  **Снижение корреляции:** Как указано в контексте, \"Случайный выбор признаков уменьшает корреляцию между деревьями, что улучшает общую обобщающую способность ансамбля\". Если бы каждое дерево всегда выбирало для разбиения наилучший признак из всего набора, деревья становились бы очень похожими (сильно коррелированными). Их ошибки были бы схожими, и усреднение их предсказаний не давало бы значимого выигрыша в стабильности. Случайное ограничение выбора на каждом шаге заставляет деревья \"смотреть\" на данные под разными углами, делая их разнообразнее.\n\n2.  **Устойчивость и обобщение:** Разнообразие деревьев, достигнутое за счёт случайности в выборе как объектов (бутстрэп), так и признаков, делает модель более устойчивой к шуму и выбросам, а также снижает риск переобучения. Ансамбль некоррелированных моделей с низким смещением (как глубокие деревья) эффективно снижает общую дисперсию.\n\nТаким образом, использование случайного подмножества признаков на каждом сплите — это не просто техническая деталь, а фундаментальный принцип, который превращает набор решающих деревьев в мощный и устойчивый ансамблевый метод (Random Forest), компенсируя главный недостаток отдельных деревьев — высокую дисперсию.",
      "contexts": [
        "качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике является градиентный бустинг, о котором подробно рассказывается в соответствующем параграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети). Стекинг Стекинг (stacking) — алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем: он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) Обучение стекинга проходит в несколько этапов: общая выборка разделяется на тренировочную и тестовую тренировочная выборка делится на n n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются ( n − 1 ) (n−1) фолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались Автор изображения — Steven Yu. на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи Автор изображения — Steven Yu. Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве — переобучения в данном случае возникнуть не должно. Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называют блендингом (blending). Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать. Почитать по теме Лекция Евгения Соколова про bias-variance decomposition и бэггинг Блог-пост про ансамбли от Joseph Rocca Блог-пост про стекинг и блендинг от Steven Yu Знак вопроса Пройдите квиз по параграфу Чтобы закрепить пройденный материал Сообщить об ошибке Предыдущий параграф 2.3. Решающие деревья Обучение древесных моделей для классификации и регрессии. Эффективное построение решающих деревьев Следующий параграф 2.5. Градиентный бустинг Как устроено самое мощное семейство не-нейросетевых моделей: градиентный",
        "Вопрос: Почему это важно:\n         * Бутстрэппинг объектов снижает дисперсию модели за счёт усреднения предсказаний разных деревьев.\n         * Случайный выбор признаков уменьшает корреляцию между деревьями, что улучшает общую обобщающую способность ансамбля.",
        "Почему случайный лес устойчив к шуму и выбросам?\nОтвет: Случайный лес устойчив к шуму и выбросам благодаря следующим свойствам:",
        "Вопрос: * Выбирается тот признак и порог, которые дают наибольшее уменьшение хаотичности (например, снижение критерия Джини или энтропии).\n  ",
        "Итог:\nПризнак и порог разбиения выбираются так, чтобы наилучшим образом разделить данные, делая узлы максимально однородными.\n         * ",
        "Что такое жадный алгоритм построения дерева?\nОтвет: Жадный алгоритм строит дерево решений шаг за шагом, выбирая на каждом этапе лучшее разбиение по текущему критерию качества.\nЭтапы жадного алгоритма:",
        "Вопрос: Деревья\n  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "Определение порогов для категориальных и числовых признаков\nhttps://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e\n  \n  ",
        "Что такое дерево решений, и как оно работает?\nОтвет: Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.\nКаждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).\nПример:\nВ медицинской задаче:\n         * Вершина 1: \"Возраст > 40 лет?\"\n         * Да → Вершина 2: \"Курит?\"\n         * Нет → Прогноз: \"Низкий риск заболевания\".\n         * Вершина 2:\n         * Да → Прогноз: \"Высокий риск заболевания\".\n         * Нет → Прогноз: \"Средний риск заболевания\".\n  ",
        "  ",
        "Как строится дерево решений?\nВыбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:",
        "Вопрос: * Прогнозы деревьев усредняются (для регрессии) или используется голосование большинства (для классификации).\nПример:\nПри прогнозировании цен недвижимости каждое дерево может делать свои предположения о цене. Финальный прогноз будет средней ценой, предсказанной всеми деревьями.",
        "Как работают случайные выборки семплов и признаков в случайном лесе, и почему это важно для его эффективности?\nОтвет: В случайном лесе для каждого дерева случайно выбираются:"
      ]
    },
    {
      "index": 19,
      "question": "Где деревья глубже бустинг/бэггинг?",
      "ground_truth": "В бэггинге обычно деревья глубже, а бустинге с ограничением, чтобы не переобучаться.\r\nЕсли в бустинге в какой-то момент будет переобучение - вырулить из этого никак не получится.\r\nА в бэггинге даже если будет несколько переобученных деревьев, эффект от них может быть некритичным, так как мы берем несколько алгоритмов и усредняем их предсказаниях.",
      "model_answer": "Согласно контексту, глубина деревьев зависит от алгоритма:\n\n*   **В градиентном бустинге** используются деревья **небольшой глубины** (обычно 2-3 уровня). Это связано с тем, что базовые алгоритмы должны иметь высокое смещение и небольшой разброс, чтобы быстро обучаться и последовательно корректировать ошибки предыдущих моделей, приближая антиградиент функции потерь.\n\n*   **В случайном лесе (бэггинге)** используются **глубокие деревья** (часто без сильного ограничения глубины). Цель каждого дерева — максимально точно уловить закономерности в своей подвыборке данных, что требует большей глубины.\n\nТаким образом, **деревья глубже в алгоритмах бэггинга (случайный лес)**, чем в градиентном бустинге.",
      "contexts": [
        "L до первого члена в окрестности точки k−1 (x i )): L(y i ,a k−1 (x i )+b(x i ))≈L(y i ,a k−1 (x i ))+b(x i ) ∂z ∂L(y i ,z) z=a k−1 (x i ) =L(y i ,a k−1 (x i ))+b(x i )g i k−1 Избавившись от постоянных членов, мы получим следующую оптимизационную задачу: b k ≈ argminb∈B b∈B argmin i=1 ∑ N b(x i )g i k−1 Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют b ( x i ) b(x i ), пропорциональные значениям k−1 . Поэтому на каждой итерации базовые алгоритмы b k b k обучаются предсказывать значения антиградиента функции потерь по текущим предсказаниям композиции. Итак, использованная нами интуиция шага в сторону «уменьшения остатка» удивительным образом привела к оптимальным смещениям в случае квадратичной функции потерь, но для других функций потерь это не так: для них смещение происходит в сторону антиградиента. Получается, что в общем случае на каждой итерации базовые алгоритмы должны приближать значения антиградиента функции потерь. Однако есть частный случай, в котором в качестве таргета для базового алгоритма выгоднее использовать именно «остатки» — это касается функции потерь MAE. Её производная равна -1, 0 или +1. Приближая базовым алгоритмом антиградиент MAE, количество итераций до сходимости будет расти пропорционально масштабу таргета. То есть, если домножить целевое значение на 10, то потребуется в 10 раз больше итераций градиентного бустинга. Использование остатков в качестве таргета для базового алгоритма не имеет такой проблемы. Аналогичные рассуждения верны также для функции MAPE, в которой проблема с масштабом таргета может проявляться еще сильнее. Обучение базового алгоритма При построении очередного базового алгоритма b k + 1 b k+1 мы решаем задачу регрессии с таргетом, равным антиградиенту функции потерь исходной задачи на предсказании +…+b k . Теоретически можно воспользоваться любым методом построения регрессионного дерева. Важно выбрать оценочную функцию S S, которая будет показывать, насколько текущая структура дерева хорошо приближает антиградиент. Её нужно будет использовать для построения критерия ветвления: max ⁡ , ∣R∣⋅S(R)−∣R right ∣⋅S(R right )−∣R left ∣⋅S(R left )→max, где S ( R ) S(R) — значение функции S S в вершине S(R left ),S(R right ) — значения в левом и правом сыновьях R R после добавления предиката, ∣ ⋅ ∣ ∣⋅∣ — количество элементов, пришедших в вершину. Например, можно использовать следующие оценочные функции: (g,p)= i=1 Cosine(g,p)=− i=1 i=1 ∑ N g i 2 i=1 где p i p i — предсказание дерева на объекте — антиградиент, на который учится дерево, p=p i i=1 g=g i N . Функция L 2 L 2 представляет собой среднеквадратичную ошибку, а функция Cosine определяет близость через косинусное расстояние между векторами предсказаний и антиградиентов. В итоге обучение базового алгоритма проходит в два шага: по функции потерь вычисляется целевая переменная для обучения следующего базового алгоритма: ∂L(y i ,z) z=a k (x i ) строится регрессионное дерево на обучающей выборке ,−g i k ), минимизирующее выбранную оценочную функцию. На практике Поскольку для построения градиентного бустинга достаточно уметь считать градиент функции потерь по предсказаниям, с его помощью можно решать широкий спектр задач. В библиотеках градиентного",
        "качестве базовых алгоритмов часто выбирают алгоритмы с высоким смещением и небольшим разбросом. Например, если в качестве базовых классификаторов выступают деревья, то их глубина должна быть небольшой — обычно не больше 2-3 уровней. Ещё одной важной причиной для выбора моделей с высоким смещением в качестве базовых является то, что такие модели, как правило, быстрее учатся. Это важно для их последовательного обучения, которое может стать очень дорогим по времени, если на каждой итерации будет учиться сложная модель. На текущий момент основным видом бустинга с точки зрения применения на практике является градиентный бустинг, о котором подробно рассказывается в соответствующем параграфе. Хотя случайный лес — мощный и достаточно простой для понимания и реализации алгоритм, на практике он чаще всего уступает градиентному бустингу. Поэтому градиентный бустинг сейчас — основное продакшн-решение, если работа происходит с табличными данными (в работе с однородными данными — картинками, текстами — доминируют нейросети). Стекинг Стекинг (stacking) — алгоритм ансамблирования, основные отличия которого от предыдущих состоят в следующем: он может использовать алгоритмы разного типа, а не только из какого-то фиксированного семейства. Например, в качестве базовых алгоритмов могут выступать метод ближайших соседей и линейная регрессия результаты базовых алгоритмов объединяются в один с помощью обучаемой мета-модели, а не с помощью какого-либо обычного способа агрегации (суммирования или усреднения) Обучение стекинга проходит в несколько этапов: общая выборка разделяется на тренировочную и тестовую тренировочная выборка делится на n n фолдов. Затем эти фолды перебираются тем же способом, что используется при кросс-валидации: на каждом шаге фиксируются ( n − 1 ) (n−1) фолдов для обучения базовых алгоритмов и один — для их предсказаний (вычисления мета-факторов). Такой подход нужен для того, чтобы можно было использовать всё тренировочное множество, и при этом базовые алгоритмы не переобучались Автор изображения — Steven Yu. на полученных мета-факторах обучается мета-модель. Кроме мета-факторов, она может принимать на вход и фичи из исходного датасета. Выбор зависит от решаемой задачи Автор изображения — Steven Yu. Для получения мета-факторов на тестовом множестве базовые алгоритмы можно обучить на всём тренировочном множестве — переобучения в данном случае возникнуть не должно. Если данных достаточно много, то можно просто разделить обучающие данные на две непересекающиеся части: ту, на которой учатся базовые алгоритмы, и ту, на которой они делают свои предсказания и обучается мета-модель. Использование такого простого разбиения вместо кросс-валидации на тренировочных данных иногда называют блендингом (blending). Если данных совсем много, то тестовое множество тоже можно разделить на две части: тестовую и валидационную, и использовать последнюю для подбора гиперпараметров моделей-участников. С точки зрения смещения и разброса стекинг не имеет прямой интерпретации, так как не минимизирует напрямую ни ту, ни другую компоненту ошибки. Удачно работающий стекинг просто уменьшает ошибку, и, как следствие, её компоненты тоже будут убывать. Почитать по теме Лекция Евгения Соколова про bias-variance decomposition и бэггинг Блог-пост про ансамбли от Joseph Rocca Блог-пост про стекинг и блендинг от Steven Yu Знак вопроса Пройдите квиз по параграфу Чтобы закрепить пройденный материал Сообщить об ошибке Предыдущий параграф 2.3. Решающие деревья Обучение древесных моделей для классификации и регрессии. Эффективное построение решающих деревьев Следующий параграф 2.5. Градиентный бустинг Как устроено самое мощное семейство не-нейросетевых моделей: градиентный",
        "Вопрос: Почему в градиентном бустинге используют деревья небольшой глубины?\nОтвет: В градиентном бустинге обычно применяются деревья небольшой глубины (3–6 уровней), чтобы:",
        "Вопрос: Какой глубины деревья используются в случайном лесе и градиентном бустинге?\nОтвет: * Случайный лес:\nИспользуются глубокие деревья (большая глубина, часто без ограничения), чтобы максимально улавливать закономерности в данных.\n            * Градиентный бустинг:\nИспользуются неглубокие деревья (3-6 уровней), чтобы каждое дерево выполняло небольшую корректировку и предотвращалось переобучение.",
        "Может ли градиентный бустинг переобучиться с увеличением количества деревьев?",
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа"
      ]
    },
    {
      "index": 20,
      "question": "Как работает k-nn?",
      "ground_truth": "1. Обучение:\r\nОбучения как такового нет.\r\nМодель просто запоминает все обучающие объекты и их метки классов (или значения, если это регрессия). \r\nЧтобы классифицировать новый объект, модель ищет k ближайших объектов в обучающей выборке и голосует по их меткам.\r\nДля регрессии — берется среднее значение у k ближайших соседей.\r\n\r\n2. Предсказание:\r\nКогда приходит новый объект, происходит следующее:\r\nВычисляется расстояние до всех объектов из обучающей выборки\r\n— обычно Евклидово, но может быть любое (манхэттенское, косинусное и т.п.)\r\nВыбираются k ближайших соседей\r\nКлассификация:\r\nКласс — тот, за который проголосовало большинство соседей (majority vote)\r\nМожно взвешивать по расстоянию: ближние — весомее\r\n\r\nРегрессия:\r\nПредсказывается среднее значение по соседям\r\nИли взвешенное среднее (опять же — ближние весомее)",
      "model_answer": "На основе предоставленного контекста, метод k-ближайших соседей (k-NN) работает следующим образом:\n\n### Основная идея\nЭто метрический алгоритм, основанный на принципе «Скажи мне, кто твой друг, и я скажу, кто ты». Он не строит глобальную модель в процессе обучения, а просто запоминает всю обучающую выборку (такой подход называется *lazy learning*). Предсказание для нового объекта делается на основе его локального окружения — то есть объектов из обучающей выборки, которые наиболее на него похожи.\n\n### Формальное описание алгоритма (для классификации)\n1.  **Дано:**\n    *   Обучающая выборка: `X = (x_i, y_i), i=1...N`, где `x_i` — объект, а `y_i` — его метка класса из множества `Y = {1, ..., C}`.\n    *   Функция расстояния `ρ: X × X → [0, +∞)`, симметричная по своим аргументам.\n    *   Новый объект `u`, который нужно классифицировать.\n    *   Параметр `k` — количество ближайших соседей.\n\n2.  **Шаг предсказания:**\n    *   Найти `k` объектов из обучающей выборки, наиболее близких к `u` в смысле расстояния `ρ`. Это множество обозначается `X_k(u) = {x_u(1), ..., x_u(k)}`. Для всех объектов в этом множестве расстояние до `u` не больше, чем для объектов вне его.\n    *   Определить метки класса для каждого из этих `k` соседей.\n\n3.  **Принятие решения:**\n    *   Класс нового объекта `u` определяется как наиболее часто встречающийся класс среди его `k` ближайших соседей. Формально:\n        `a(u) = argmax_(y ∈ Y) ∑_(i=1)^k I[y_u(i) = y]`,\n        где `I` — индикаторная функция (равна 1, если метка соседа равна `y`, и 0 иначе).\n    *   Алгоритм также позволяет эвристически оценить вероятность класса `y` для объекта `u` как долю соседей этого класса: `P(u ~ y) = (∑_(i=1)^k I[y_u(i) = y]) / k`.\n\n### Ключевые особенности и замечания из контекста\n*   **Отсутствие фазы обучения:** Алгоритм просто хранит данные. Вся «работа» происходит на этапе предсказания при поиске соседей.\n*   **Риск переобучения:** При малом `k` (например, 1 или 2) границы между классами становятся очень сложными, и алгоритм может подстроиться под шум в данных. Это происходит потому, что вся обучающая выборка по сути является параметром модели.\n*   **Важность выбора метрики:** Качество работы сильно зависит от выбора функции расстояния `ρ`.\n    *   **Евклидово расстояние** — хороший выбор по умолчанию.\n    *   **Манхэттенское расстояние** — более устойчиво к выбросам в пространствах высокой размерности.\n    *   **Метрика Минковского** — обобщение евклидовой и манхэттенской.\n    *   **Косинусное расстояние** — полезно, когда важна направленность векторов, а не их длина (например, в задачах анализа текстов).\n\n### Преимущества и недостатки (из контекста)\n*   **Плюсы:** Простота, интерпретируемость, хорошая точность на многих задачах. Не делает сильных предположений о глобальной структуре данных.\n*   **Минусы:**\n    *   **Вычислительная сложность:** На этапе предсказания для каждого нового объекта требуется найти расстояние до всех объектов обучающей выборки, что может быть неприемлемо при больших объемах данных.\n    *   **Необходимость быстрого поиска соседей:** Для практического применения критически важны эффективные алгоритмы поиска ближайших соседей (например, k-d-деревья), которые лишь упомянуты в контексте.\n\nТаким образом, k-NN — это интуитивно понятный, непараметрический алгоритм, который классифицирует объекты на основе голосования их ближайших соседей в пространстве признаков, используя заданную метрику.",
      "contexts": [
        "классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто встречающийся класс среди объектов из (u): a ( u ) = argmax⁡y∈Y (2) a(u)= y∈Y argmax i=1 ∑ k I[y u (i) =y](2) Формула может показаться страшной, но на самом деле всё довольно просто: для каждой метки класса y ∈ Y y∈Y количество соседей u u с такой меткой можно посчитать, просто просуммировав по всем соседям индикаторы событий, соответствующих тому, что метка соседа равна y y. Легко заметить, что этот алгоритм позволяет также оценивать вероятности классов. Для этого достаточно просто посчитать частоты классов соседей: P(u∼y)= k ∑ i=1 k I[y u (i) =y] Стоит, однако, понимать, что, хоть такая функция и удовлетворяет свойствам вероятности (она неотрицательна, аддитивна и ограничена единицей), это не более чем эвристика. Несмотря на то что формально фаза обучения отсутствует, алгоритм может легко переобучиться. Вы можете убедиться в этом сами, использовав маленькое количество соседей (например, одного или двух), — границы классов оказываются довольно сложными. Происходит это из-за того, что параметрами алгоритма можно считать всю обучающую выборку, довольно большую по размеру. Из-за этого алгоритму легко подстроиться под конкретные данные. По ссылке вы можете увидеть интерактивный пример работы алгоритма. Автор примера - Анастасия Чирикова. Выбор метрики Может возникнуть закономерный вопрос, как же правильно выбрать функцию расстояния ρ ρ. В подавляющем большинстве случаев обычное евклидово расстояние ρ(x,y)= будет хорошим выбором. Однако в некоторых случаях другие функции будут подходить лучше, поэтому давайте разберём ещё несколько функций, наиболее используемых на практике. 2 Манхэттенская метрика ρ(x,y)= Часто используется в высокоразмерных пространствах из-за лучшей устойчивости к выбросам. Представим, что два объекта в 1000-размерном пространстве почти идентичны, но сильно отличаются по одному из признаков. Это почти наверняка свидетельствует о выбросе в этом признаке, и объекты, скорее всего, очень близки. Однако евклидово расстояние усилит различие в единственном признаке и сделает их более далёкими друг от друга. Этого недостатка лишена манхэттенская метрика — в ней вместо квадрата используется модуль. Метрика Минковского ρ(x,y)=( 1/p Является обобщением евклидовой ( p = 2 p=2) и манхэттенской ( p = 1 p=1) метрик. Косинусное расстояние cos ρ(x,y)=1−cosθ=1− ∥x∥∥y∥ x⋅y Эта метрика хороша тем, что не зависит от норм векторов. Такое поведение бывает полезно в некоторых задачах, например при поиске похожих документов. В качестве признаков там часто используются количества слов. При этом интуитивно кажется, что если в тексте использовать каждое слово в два раза больше, то тема этого текста поменяться не должна. Поэтому как раз в этом случае нам не важна норма вектор-признака, и в задачах, связанных с текстами, часто применяется именно",
        "Смысл метрических методов очень хорошо раскрывает фраза «Скажи мне, кто твой друг, и я скажу, кто ты». Алгоритмы этого класса почти не имеют фазы обучения. Вместо этого они просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут объекты, похожие на целевой. Такой процесс называют lazy learning, потому что никакого обучения, по сути, не происходит. Также метрические модели являются непараметрическими, потому что они не делают явных допущений о глобальных законах, которым подчиняются данные. Так, линейная регрессия основывается на предположении о том, что изучаемая закономерность линейная (с неизвестными коэффициентами, которые восстанавливаются по выборке), а линейная бинарная классификация — что существует гиперплоскость, неплохо разделяющая классы. Метрические методы же локальны: они исходят из допущения, что свойства объекта можно узнать, имея представление о его соседях. Указанные выше свойства могут быть полезными, особенно в случае сложно устроенных данных, для которых мы не можем придумать глобальную модель. Однако с другой стороны, из-за lazy learning алгоритм становится абсолютно неприменимым при большом количестве данных. Несмотря на то, что эти алгоритмы очень просты для понимания, они довольно точны и хорошо интерпретируемы — и часто используются как минимум в качестве бейзлайнов в разных задачах. В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методе k-ближайших соседей (k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах. Например, у алгоритмов поиска ближайших соседей, — неотъемлемой часть метода, — намного более широкая область применения. Плюс ко всему KNN — очень простой и легко интерпретируемый алгоритм, поэтому изучить его всё равно полезно. Мы обсудим подробнее его преимущества, недостатки, область его применения, а также возможные обобщения. Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей. Метод k-ближайших соседей (KNN) Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): 2 Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто",
        "алгоритма работают на уменьшение среднего квадрата евклидова расстояния от объектов до центров их кластеров: k=1 ∑ K i=1 I[a(x i )=k] На шаге отнесения объектов к одному из кластеров мы выбираем кластер с ближайшим центроидом, то есть минимизируем каждое слагаемое в Φ 0 Φ 0 : все потенциально большие слагаемые мы зануляем, а оставляем ненулевыми только наименьшие из возможных (при условии фиксирования центров кластеров). На шаге пересчёта центров кластеров мы выбираем центр таким образом, чтобы при фиксированном наборе объектов, относящихся к кластеру, для всех k k минимизировать выражение, стоящее под суммой по i=1 I[a(x i )=k] Здесь уже становится принципиально, что мы определяем квадрат расстояния как квадрат разности векторов, так как именно отсюда при дифференцировании по μ k μ k и записи необходимого условия экстремума получается, что центры кластеров нужно пересчитывать как средние арифметические x i x i , принадлежащих кластеру. Этих соображений, конечно, недостаточно, чтобы утверждать, что мы найдём минимум Φ 0 Φ 0 . Более того, гарантии того, что мы найдём глобальный минимум, вообще говоря, нет. Однако, потратив чуть больше усилий, можно доказать, что процесс сойдётся в один из локальных минимумов. Также можно справедливо заметить, что, так как любой центр кластера — это среднее арифметическое входящих в кластер объектов x i x i , на выборке фиксированного размера есть лишь конечное множество потенциальных центров кластеров. Если предположить, что в ходе работы K-means не зацикливается, отсюда следует, что рано или поздно центры кластеров не изменятся на следующем шаге и алгоритм сойдётся. При этом фактическая сходимость, конечно же, происходит задолго до полного перебора всех возможных центров кластеров. Иерархическая агломеративная кластеризация Другой классический метод кластеризации — это иерархическая кластеризация. Иногда дополнительно уточняют: иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации на агломеративные (agglomerative) и дивизивные, или дивизионные (divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. 19 Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Расстояния в иерархической кластеризации Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное",
        "в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба». Поиск ближайших соседей: точные методы Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие эвристики хоть и могут давать некоторый выигрыш по времени, но не улучшат асимптотическую сложность. Второй — k-d-деревья, о которых стоит поговорить подробнее. K-d-деревья Представим на секунду, что у нас есть всего лишь один признак, то есть объекты выражаются вещественными числами, а не векторами. В этом случае для поиска ближайшего соседа напрашивается всем вам известное бинарное дерево поиска, которое позволяет находить элементы за логарифмическое время. Оказывается, существует аналог данной структуры в многомерном пространстве, который называется k-d-дерево (k-d tree, сокращение от k-dimensional tree). Как и в обычном дереве поиска, в k-d-дереве каждый узел является объектом обучающей выборки, который особым образом делит пространство на два полупространства. Таким образом, всё пространство оказывается поделено на множество малых областей, и такое деление оказывается очень полезным при поиске ближайших соседей. Рассмотрим подробнее, как строится такое дерево. Трудность в применении обычного дерева поиска состоит в том, что мы не можем напрямую сравнить два вектора так же, как два вещественных числа. Чтобы эту проблему преодолеть, узлы дерева будут делить пространство лишь по одной оси. При движении вниз по дереву оси, по которым точки делят пространство, циклически сменяют друг друга. Например, в двумерном пространстве корень будет отвечать за деление по x-координате, его сыновья — за деление по y-координате, а внуки — снова за x-координату, и т. д. Посмотрим, как это работает на примере: Источник На картинке выше корень ( 30 , 40 ) (30,40) делит все точки по оси х: слева оказываются точки, у которых x < 30 x<30, а справа — те, у которых x ⩾ 30 x⩾30. Аналогично левый сын корня ( 5 , 25 ) (5,25) делит своё поддерево по оси y: слева оказываются точки, у которых y < 25 y<25, а справа — те, у которых y ⩾ 25 y⩾25. Остаётся вопрос — как выбирать точки, которые будут делить пространство пополам? Чтобы дерево было сбалансированным, нужно находить точку с медианой, соответствующей уровню поддерева координаты. На практике часто ограничиваются выбором случайной точки или любой эвристикой по приближённому поиску медианы (например, медиана некоторого подмножества точек). Это позволяет ускорить построение дерева, но убирает все гарантии на его сбалансированность. Добавлять новые точки можно так же, как и в одномерном дереве поиска. Спускаясь по дереву, можно однозначно определить лист, к которому нужно подвесить новую точку, чтобы не нарушить все свойства дерева. При добавлении большого количества точек, однако, дерево может перестать быть сбалансированным, и нужно проводить ребалансировку. Также существуют варианты k-d-деревьев, которые сохраняют сбалансированность при добавлении / удалении точек. Поговорим теперь про",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,"
      ]
    },
    {
      "index": 21,
      "question": "Как ускорить K-NN для большого датасета?",
      "ground_truth": "Понижение размерности перед k-NN\r\nИспользуй PCA, UMAP, TSNE, TruncatedSVD и т.п.\r\nУменьшаешь размерность данных → быстрее считается расстояние\r\nГлавное — сохранить \"структуру близости\" между точками\r\nМожно использовать Approximate Nearest Neighbors. Annoy, HNSW (Approximate Nearest Neighbors)\r\nДля приближенного поиска ближайших — быстрее, но с небольшой потерей точности\r\nНапример, Annoy: Можем представить обучающую выборку в виде дерева и считаем уже не по всей области, а по части выборки. Другие методы используют другие методы ограничения выборки для подсчета.\r\nОчень хорошо работают для больших объемов данных",
      "model_answer": "На основе предоставленного контекста можно выделить несколько основных стратегий для ускорения метода k-ближайших соседей (KNN) при работе с большими датасетами. Проблема в том, что наивный поиск перебором имеет сложность O(ND), где N — размер выборки, а D — размерность признаков, что становится неприемлемо на этапе предсказания.\n\n**Основные подходы к ускорению KNN:**\n\n### 1. Точные методы (Exact Methods)\n\nЭти методы находят точных k ближайших соседей, но стремятся сделать это эффективнее полного перебора.\n\n*   **K-d деревья (k-dimensional trees):** Это основная точная структура данных, упомянутая в контексте. Идея аналогична бинарному дереву поиска, но для многомерного пространства. Пространство рекурсивно делится гиперплоскостями, что позволяет быстро отбрасывать целые регионы при поиске, не проверяя все точки. Однако:\n    *   Их эффективность падает с ростом размерности D (проклятие размерности).\n    *   Требуется время на построение дерева, но это делается один раз на этапе \"обучения\" (хотя формального обучения в KNN нет).\n    *   Для поддержания эффективности может потребоваться ребалансировка.\n\n### 2. Приближённые методы (Approximate Methods)\n\nЭти методы жертвуют точностью в пользу скорости, находя не абсолютно ближайших, а достаточно близких соседей. В контексте прямо указано, что такие методы существуют, хотя их детали не раскрыты. Общая идея — ускорить поиск за счёт вероятностных или эвристических подходов.\n\n### 3. Эвристики для полного перебора\n\nДаже при использовании полного перебора можно применить оптимизации:\n*   **Использование подмножества признаков для оценки:** Можно быстро вычислить расстояние по части признаков. Если эта оценка снизу уже превышает текущее наилучшее расстояние до кандидата, объект можно отбросить, не вычисляя полное расстояние.\n*   **Векторизация операций:** Использование эффективных библиотек (например, NumPy) для пакетного вычисления расстояний.\n*   **Нормализация данных:** Предварительный расчёт норм векторов (для евклидовой или косинусной метрики) может ускорить вычисления.\n\n### 4. Общие рекомендации из контекста:\n\n*   **Выбор метрики:** Правильный выбор функции расстояния `ρ` может не только улучшить качество, но и повлиять на вычислительную сложность. Например, манхэттенское расстояние (L1) считается быстрее евклидова (L2), так как не требует операции возведения в квадрат и извлечения корня.\n*   **Уменьшение размерности:** В контексте упоминается, что объекты в исходном пространстве могут быть \"очень далеки друг от друга\", и для решения этой проблемы часто предварительно обучают *представления* (embeddings). Использование методов снижения размерности (PCA, t-SNE, autoencoders) может значительно уменьшить D, что ускорит любой метод поиска.\n*   **Индексирование:** Для промышленного применения (как в поисковых системах Google или YouTube, которые упомянуты как пример) используются сложные системы индексирования, построенные на идеях поиска ближайших соседей. Эти системы являются развитием идей k-d деревьев и других методов.\n\n**Итоговый совет:** Для больших датасетов наивный перебор неприменим. Следует рассмотреть:\n1.  **K-d деревья** для данных умеренной размерности (D < 20-30) как точный метод.\n2.  **Приближённые методы поиска ближайших соседей (Approximate Nearest Neighbors, ANN)**, такие как Locality-Sensitive Hashing (LSH), Annoy, или HNSW, которые специально разработаны для работы с большими и высокоразмерными данными.\n3.  **Уменьшение размерности признакового пространства** как обязательный подготовительный этап.\n4.  **Оптимизацию вычисления выбранной метрики** (например, переход на L1 или косинусное расстояние, если это уместно для задачи).",
      "contexts": [
        "классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто встречающийся класс среди объектов из (u): a ( u ) = argmax⁡y∈Y (2) a(u)= y∈Y argmax i=1 ∑ k I[y u (i) =y](2) Формула может показаться страшной, но на самом деле всё довольно просто: для каждой метки класса y ∈ Y y∈Y количество соседей u u с такой меткой можно посчитать, просто просуммировав по всем соседям индикаторы событий, соответствующих тому, что метка соседа равна y y. Легко заметить, что этот алгоритм позволяет также оценивать вероятности классов. Для этого достаточно просто посчитать частоты классов соседей: P(u∼y)= k ∑ i=1 k I[y u (i) =y] Стоит, однако, понимать, что, хоть такая функция и удовлетворяет свойствам вероятности (она неотрицательна, аддитивна и ограничена единицей), это не более чем эвристика. Несмотря на то что формально фаза обучения отсутствует, алгоритм может легко переобучиться. Вы можете убедиться в этом сами, использовав маленькое количество соседей (например, одного или двух), — границы классов оказываются довольно сложными. Происходит это из-за того, что параметрами алгоритма можно считать всю обучающую выборку, довольно большую по размеру. Из-за этого алгоритму легко подстроиться под конкретные данные. По ссылке вы можете увидеть интерактивный пример работы алгоритма. Автор примера - Анастасия Чирикова. Выбор метрики Может возникнуть закономерный вопрос, как же правильно выбрать функцию расстояния ρ ρ. В подавляющем большинстве случаев обычное евклидово расстояние ρ(x,y)= будет хорошим выбором. Однако в некоторых случаях другие функции будут подходить лучше, поэтому давайте разберём ещё несколько функций, наиболее используемых на практике. 2 Манхэттенская метрика ρ(x,y)= Часто используется в высокоразмерных пространствах из-за лучшей устойчивости к выбросам. Представим, что два объекта в 1000-размерном пространстве почти идентичны, но сильно отличаются по одному из признаков. Это почти наверняка свидетельствует о выбросе в этом признаке, и объекты, скорее всего, очень близки. Однако евклидово расстояние усилит различие в единственном признаке и сделает их более далёкими друг от друга. Этого недостатка лишена манхэттенская метрика — в ней вместо квадрата используется модуль. Метрика Минковского ρ(x,y)=( 1/p Является обобщением евклидовой ( p = 2 p=2) и манхэттенской ( p = 1 p=1) метрик. Косинусное расстояние cos ρ(x,y)=1−cosθ=1− ∥x∥∥y∥ x⋅y Эта метрика хороша тем, что не зависит от норм векторов. Такое поведение бывает полезно в некоторых задачах, например при поиске похожих документов. В качестве признаков там часто используются количества слов. При этом интуитивно кажется, что если в тексте использовать каждое слово в два раза больше, то тема этого текста поменяться не должна. Поэтому как раз в этом случае нам не важна норма вектор-признака, и в задачах, связанных с текстами, часто применяется именно",
        "в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба». Поиск ближайших соседей: точные методы Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие эвристики хоть и могут давать некоторый выигрыш по времени, но не улучшат асимптотическую сложность. Второй — k-d-деревья, о которых стоит поговорить подробнее. K-d-деревья Представим на секунду, что у нас есть всего лишь один признак, то есть объекты выражаются вещественными числами, а не векторами. В этом случае для поиска ближайшего соседа напрашивается всем вам известное бинарное дерево поиска, которое позволяет находить элементы за логарифмическое время. Оказывается, существует аналог данной структуры в многомерном пространстве, который называется k-d-дерево (k-d tree, сокращение от k-dimensional tree). Как и в обычном дереве поиска, в k-d-дереве каждый узел является объектом обучающей выборки, который особым образом делит пространство на два полупространства. Таким образом, всё пространство оказывается поделено на множество малых областей, и такое деление оказывается очень полезным при поиске ближайших соседей. Рассмотрим подробнее, как строится такое дерево. Трудность в применении обычного дерева поиска состоит в том, что мы не можем напрямую сравнить два вектора так же, как два вещественных числа. Чтобы эту проблему преодолеть, узлы дерева будут делить пространство лишь по одной оси. При движении вниз по дереву оси, по которым точки делят пространство, циклически сменяют друг друга. Например, в двумерном пространстве корень будет отвечать за деление по x-координате, его сыновья — за деление по y-координате, а внуки — снова за x-координату, и т. д. Посмотрим, как это работает на примере: Источник На картинке выше корень ( 30 , 40 ) (30,40) делит все точки по оси х: слева оказываются точки, у которых x < 30 x<30, а справа — те, у которых x ⩾ 30 x⩾30. Аналогично левый сын корня ( 5 , 25 ) (5,25) делит своё поддерево по оси y: слева оказываются точки, у которых y < 25 y<25, а справа — те, у которых y ⩾ 25 y⩾25. Остаётся вопрос — как выбирать точки, которые будут делить пространство пополам? Чтобы дерево было сбалансированным, нужно находить точку с медианой, соответствующей уровню поддерева координаты. На практике часто ограничиваются выбором случайной точки или любой эвристикой по приближённому поиску медианы (например, медиана некоторого подмножества точек). Это позволяет ускорить построение дерева, но убирает все гарантии на его сбалансированность. Добавлять новые точки можно так же, как и в одномерном дереве поиска. Спускаясь по дереву, можно однозначно определить лист, к которому нужно подвесить новую точку, чтобы не нарушить все свойства дерева. При добавлении большого количества точек, однако, дерево может перестать быть сбалансированным, и нужно проводить ребалансировку. Также существуют варианты k-d-деревьев, которые сохраняют сбалансированность при добавлении / удалении точек. Поговорим теперь про",
        "Смысл метрических методов очень хорошо раскрывает фраза «Скажи мне, кто твой друг, и я скажу, кто ты». Алгоритмы этого класса почти не имеют фазы обучения. Вместо этого они просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут объекты, похожие на целевой. Такой процесс называют lazy learning, потому что никакого обучения, по сути, не происходит. Также метрические модели являются непараметрическими, потому что они не делают явных допущений о глобальных законах, которым подчиняются данные. Так, линейная регрессия основывается на предположении о том, что изучаемая закономерность линейная (с неизвестными коэффициентами, которые восстанавливаются по выборке), а линейная бинарная классификация — что существует гиперплоскость, неплохо разделяющая классы. Метрические методы же локальны: они исходят из допущения, что свойства объекта можно узнать, имея представление о его соседях. Указанные выше свойства могут быть полезными, особенно в случае сложно устроенных данных, для которых мы не можем придумать глобальную модель. Однако с другой стороны, из-за lazy learning алгоритм становится абсолютно неприменимым при большом количестве данных. Несмотря на то, что эти алгоритмы очень просты для понимания, они довольно точны и хорошо интерпретируемы — и часто используются как минимум в качестве бейзлайнов в разных задачах. В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методе k-ближайших соседей (k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах. Например, у алгоритмов поиска ближайших соседей, — неотъемлемой часть метода, — намного более широкая область применения. Плюс ко всему KNN — очень простой и легко интерпретируемый алгоритм, поэтому изучить его всё равно полезно. Мы обсудим подробнее его преимущества, недостатки, область его применения, а также возможные обобщения. Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей. Метод k-ближайших соседей (KNN) Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): 2 Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто",
        "могут быть очень далеки друг от друга. Зачастую для решения этой проблемы вначале обучают представления. Применение Из-за своих недостатков алгоритм очень неэффективен в задачах с большим количеством данных. Однако у него всё равно есть много применений в реальном мире. Приведём лишь некоторые из них: Рекомендательные системы. Если посмотреть на саму формулировку задачи «предложить пользователю что-то похожее на то, что он любит», то KNN прямо напрашивается в качестве решения. Несмотря на то что сейчас часто используются более совершенные алгоритмы, метод ближайших соседей всё равно применяется в качестве хорошего бейзлайна. Поиск семантически похожих документов. Если векторные представления близки друг к другу, то темы документов схожи. Поиск аномалий и выбросов. Из-за того что алгоритм запоминает обучающую выборку полностью, ему легко посмотреть, насколько целевой объект похож на все данные, которые он видел. Задача кредитного скоринга. Рейтинги двух людей, у которых примерно одинаковая зарплата, схожие должности и кредитные истории, не должны сильно отличаться, поэтому KNN отлично подходит для решения такой задачи. Вопрос сложности алгоритма неочевиден и требует детального анализа, который будет частично проведён в следующем разделе. Поиск ближайших соседей Для того чтобы применять метод ближайших соседей, нужно уметь как-то находить этих самых соседей. С первого взгляда может показаться, что никакой проблемы нет: действительно, можно ведь просто перебрать все объекты из обучающей выборки X=(x i ,y i ) i=1 N , посчитать для каждого из них расстояние до тестового объекта и затем найти минимум. Однако несмотря на то что сложность такого поиска линейная по N N, она также зависит и от размерности пространства признаков. Если x ∈ R D x∈R D , то сложность такого алгоритма поиска O ( N D ) O(ND). Если вспомнить, что в типичной задаче машинного обучения количество признаков D D может быть порядка 100 100, а размер выборки и вовсе может исчисляться десятками и сотнями тысяч объектов, то становится ясно, что такая сложность никуда не годится. Проблема осложняется ещё и тем, что данный поиск необходимо выполнять на этапе применения модели, который должен быть быстрым. Всё это означает, что возникает необходимость в более быстрых методах поиска ближайших соседей, чем простой перебор. Все такие методы можно поделить на две основные группы: точные и приближённые. Последние, как следует из их названия, находят соседей лишь приближённо, то есть найденные объекты хоть и будут действительно близки, но не обязательно будут самыми близкими. В этом разделе мы подробнее рассмотрим методы из каждой группы. Перед началом обзора стоит сказать, что хоть мы и рассматриваем алгоритмы поиска соседей именно в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба». Поиск ближайших соседей: точные методы Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,"
      ]
    },
    {
      "index": 22,
      "question": "Напиши скрипт на SQL. В таблице sales есть колонки order_id, user_id, amount, order_date. Напишите запрос, который покажет для каждого пользователя: общую сумму покупок, количество заказов и средний чек, но только для заказов за последние 30 дней.",
      "ground_truth": "SELECT \r\n    user_id,\r\n    SUM(amount) as total_amount_last_30d,\r\n    COUNT(order_id) as orders_count_last_30d,\r\n    AVG(amount) as avg_check_last_30d\r\nFROM sales\r\nWHERE order_date >= CURRENT_DATE - INTERVAL '30 days'\r\nGROUP BY user_id\r\nORDER BY total_amount_last_30d DESC;",
      "model_answer": "Хотя в контексте обсуждаются метрики регрессии и анализ временных рядов, SQL-запрос к данным о продажах напрямую не относится к этим темам. Однако, можно отметить, что вычисление общей суммы, количества заказов и среднего чека — это пример агрегации данных, аналогичный расчёту статистик, обсуждаемых в контексте (например, как MSE или MAE агрегируют ошибки). Фильтрация по последним 30 дням связана с анализом временных рядов, где важны временные интервалы и лаги.\n\nВот скрипт на SQL, который решает задачу:\n\n```sql\nSELECT \n    user_id,\n    SUM(amount) AS total_amount,\n    COUNT(order_id) AS order_count,\n    AVG(amount) AS avg_order_value\nFROM sales\nWHERE order_date >= DATE_SUB(CURDATE(), INTERVAL 30 DAY)\nGROUP BY user_id;\n```\n\nПояснение:\n- `SUM(amount)` рассчитывает общую сумму покупок пользователя за период — аналогично тому, как в метриках регрессии суммируются ошибки.\n- `COUNT(order_id)` подсчитывает количество заказов.\n- `AVG(amount)` вычисляет средний чек.\n- Фильтр `WHERE` ограничивает данные последними 30 днями, что важно для анализа актуальных трендов, как в задачах с временными рядами.\n- `GROUP BY user_id` обеспечивает расчёт показателей для каждого пользователя отдельно.",
      "contexts": [
        "метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. MSE(y true ,y pred )= N 1 i=1 ∑ N (y i −f(x i )) 2 Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток y ˉ y ˉ . При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки: =1− ∑ i=1 i=1 N (y i −f(x i )) 2 . У идеального решающего правила R 2 R 2 равен 1 1, у наилучшего константного предсказания он равен 0 0 на обучающей выборке. Можно заметить, что R 2 R 2 показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. MAE Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике MAE (mean absolute error): MAE(y true ,y pred )= N 1 i=1 ∑ N ∣y i −f(x i )∣ Метрики, учитывающие относительные ошибки И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на",
        "метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. MSE(y true ,y pred )= N 1 i=1 ∑ N (y i −f(x i )) 2 Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток y ˉ y ˉ . При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки: =1− ∑ i=1 i=1 N (y i −f(x i )) 2 . У идеального решающего правила R 2 R 2 равен 1 1, у наилучшего константного предсказания он равен 0 0 на обучающей выборке. Можно заметить, что R 2 R 2 показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. MAE Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике MAE (mean absolute error): MAE(y true ,y pred )= N 1 i=1 ∑ N ∣y i −f(x i )∣ Метрики, учитывающие относительные ошибки И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на",
        "метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. MSE(y true ,y pred )= N 1 i=1 ∑ N (y i −f(x i )) 2 Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток y ˉ y ˉ . При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки: =1− ∑ i=1 i=1 N (y i −f(x i )) 2 . У идеального решающего правила R 2 R 2 равен 1 1, у наилучшего константного предсказания он равен 0 0 на обучающей выборке. Можно заметить, что R 2 R 2 показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. MAE Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике MAE (mean absolute error): MAE(y true ,y pred )= N 1 i=1 ∑ N ∣y i −f(x i )∣ Метрики, учитывающие относительные ошибки И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на",
        "Временной ряд – зависимые между собой наблюдения. Например, температура воздуха сегодня достаточно сильно зависит от вчерашнего показателя температуры. Эту зависимость хотелось бы описать численно. Для этого часто используют разные виды коэффициентов корреляции, например, корреляции Пирсона, Спирмена и Кендалла. Каждый из этих коэффициентов корреляции вычисляется по двум выборкам, корреляцию между которыми требуется посчитать. В данном случае мы имеем один временной ряд, и наша задача – оценить корреляцию между разными наблюдениями ряда, считая, что она не меняется со временем. В качестве оценки корреляции значений t+τ для любых t t рассмотрим коэффициент корреляции Пирсона ряда с самим собой со сдвигом на τ τ. Тем самым мы получим численную оценку степени влияния значения y t y t на значение y t + τ y t+τ corr (y t ,y t+τ )= t=1 t=1 ∑ T−τ (y t − y )(y t+τ − y ) , где τ τ – лаг автокорреляции, а среднее вычисляется по всему ряду t=1 ∑ T y t . Например, если мы хотим оценить степень влияния сегодняшней температуры на завтрашнюю, то посчитаем коэффициент корреляции исходного ряда и им же, сдвинутым на 1 день. Замечание. Формула содержит некоторые упрощения при оценке ковариации и дисперсий. Свойства коэффициента корреляции: ∣⩽1; =0 – отсутствие автокорреляции, при этом значения могут быть зависимыми (см. подробнее про разницу между независимостью и некоррелированностью); >0 – положительная корреляция, то есть чем больше было значение вчера, тем оно будет больше сегодня; <0 – отрицательная корреляция, то есть чем больше было значение вчера, тем оно будет меньше сегодня; ∣=1 означает строгую линейную зависимость. Посмотреть простые примеры и потренировать свою интуицию вы можете в игре Guess The Correlation. Пусть мы посчитали значение автокорреляции. А как понять, значение 0.1 – это много или мало? На этот вопрос может ответить статистический критерий Льюнга-Бокса (Ljung–Box), который проверяет значимость отклонения r τ r τ от нуля. Основное правило, которое нужно здесь понять – если значение p-value критерия не превосходит 0.05 0.05 (или другого заранее фиксированного порога значимости), то автокорреляция с лагом τ τ значима. Это число вычисляется с помощью стандартных статистических пакетов (например, statsmodels в Питоне). Рассмотрим временной ряд дорожно-транспортных происшествий за 14 лет с дискретностью 1 месяц, то есть с 12 измерениями в год. На графике мы видим явную сезонность. На нижнем графике изображена коррелограмма – график, визуализирующий автокорреляционную функцию. Точками на графике показаны значения автокорреляционной функции. Ее значение в нуле всегда равно 1, так как это автокорреляция ряда с собой же. Также мы видим, что значение r 12 r 12 является локальным максимумом, что означает высокую положительную корреляцию значения ряда за текущий месяц с аналогичным значением год назад. Иными словами, ряд со сдвигом на год ведёт себя «похожим образом», и это подкрепляет наше наблюдение про наличие годичной сезонности. Наоборот, значение r 6 r 6 минимально в своей окрестности, что означает высокую отрицательную корреляцию значения ряда со значением полгода назад. Закрашенная область визуализирует границу незначимой автокорреляции, то есть тех значений автокорреляции, для которых не выявлена статистически значимое отличие от 0 (иначе говоря, доверительный интервал пересекает 0). Так мы видим, что последняя значимая сезонная автокорреляция это",
        "Q: Каким будет результат следующего выражения?\nA: ```python\n>>> -30 % 10\n```\nРезультатом выражения \"-30 % 10\" будет - 0. Это происходит потому, что оператор % возвращает остаток от деления первого числа на второе, и в данном случае -30 можно\nразбить на целое количество десяток и остаток 0. Поэтому -30 % 10 равно 0."
      ]
    },
    {
      "index": 23,
      "question": "Напишите скрипт на SQL. Найдите 3 последних заказа для каждого пользователя из таблицы orders с колонками order_id, user_id, order_date, amount.",
      "ground_truth": "WITH ranked_orders AS (\r\n    SELECT \r\n        order_id,\r\n        user_id,\r\n        order_date,\r\n        amount,\r\n        ROW_NUMBER() OVER (\r\n            PARTITION BY user_id \r\n            ORDER BY order_date DESC\r\n        ) as rn\r\n    FROM orders\r\n)\r\nSELECT *\r\nFROM ranked_orders\r\nWHERE rn <= 3;",
      "model_answer": "На основе контекста, где обсуждается работа с базами данных через Python и извлечение элементов (например, `list1[-1]` для последнего элемента), я подготовлю SQL-скрипт. Контекст также подчеркивает важность обработки последовательностей (как в трансформерах для рекомендаций), что соотносится с задачей поиска последних заказов для каждого пользователя.\n\nВот SQL-скрипт, использующий оконную функцию `ROW_NUMBER()` для нумерации заказов каждого пользователя по убыванию даты и последующего выбора трёх последних:\n\n```sql\nWITH ranked_orders AS (\n    SELECT \n        order_id,\n        user_id,\n        order_date,\n        amount,\n        ROW_NUMBER() OVER (\n            PARTITION BY user_id \n            ORDER BY order_date DESC\n        ) AS order_rank\n    FROM orders\n)\nSELECT \n    order_id,\n    user_id,\n    order_date,\n    amount\nFROM ranked_orders\nWHERE order_rank <= 3\nORDER BY user_id, order_date DESC;\n```\n\n**Пояснение:**\n1. **CTE `ranked_orders`**: Создаём временный результат, где для каждого пользователя (`PARTITION BY user_id`) заказы нумеруются по убыванию даты (`ORDER BY order_date DESC`). Последний заказ получает `order_rank = 1`.\n2. **Основной запрос**: Выбираем заказы с рангом 1, 2 или 3, что соответствует трём последним заказам для каждого пользователя.\n3. **Сортировка**: Результат упорядочен по `user_id` и дате заказа (по убыванию) для наглядности.\n\n**Альтернативный вариант с `RANK()` или `DENSE_RANK()`**:  \nЕсли в данных возможны заказы с одинаковой датой, используйте `RANK()` или `DENSE_RANK()` вместо `ROW_NUMBER()`, чтобы корректно обработать совпадения. Например:\n```sql\nRANK() OVER (PARTITION BY user_id ORDER BY order_date DESC) AS order_rank\n```\n\nЭтот подход эффективен и соответствует современным стандартам SQL. Он аналогичен идее извлечения последних элементов из последовательности (как `list1[-1]` в Python), применённой к данным в реляционной базе.",
      "contexts": [
        "Q: Предположим, что list1 равен [2, 33, 222, 14, 25]. Что такое list1[-1]?\nA: list1[-1] относится к последнему элементу списка, который в данном случае равен 25. Таким образом, -1 относится к последнему элементу, -2 относится к предпоследнему\nэлементу и так далее.",
        "Q: Выполнение команд DML через программы Python?\nA: Можно выполнять команды DML (Data Manipulation Language) в программе, используя различные библиотеки, такие как Psycopg2 для баз данных PostgreSQL или sqlite3\nдля баз данных SQLite. Эти библиотеки обеспечивают соединение с базой данных и методы для выполнения запросов к ней, включая запросы SELECT, INSERT, UPDATE\nи DELETE. Вот пример использования Psycopg2 для выполнения запроса INSERT в базу данных PostgreSQL:\nimport psycopg2\nconn = psycopg2.connect(\"dbname=mydatabase user=myuser\")\ncur = conn.cursor()\ncur.execute(\"INSERT INTO mytable (column1, column2, column3) VALUES (%s, %s, %s)\", (value1, value2, value3))\nconn.commit()\nА вот пример использования sqlite3 для выполнения запроса SELECT в базе данных SQLite:\nimport sqlite3\nconn = sqlite3.connect('example.db')\ncur = conn.cursor()\ncur.execute('SELECT * FROM mytable')\nresults = cur.fetchall()\nОбратите внимание, что необходимо заменить mydatabase, myuser, mytable и т.д. на соответствующие значения для вашей базы данных.",
        "подобранные для запроса q q негативные примеры. Генерировать их можно по-разному; на практике чаще всего используют одну из следующих стратегий: Равновероятно выбирать подмножество документов из некликнутых. В оригинальной статье предлагают брать позитивные и негативные в соотношении 4 : 1 4:1. С большей вероятностью выбирать те из некликнутых документов, популярность которых выше. На каждой эпохе обучения выбирать некликнутые документы, получившие максимальный скор для этого запроса на предыдущей эпохе. Другие функции потерь Pairwise loss Задачу построения рекомендаций можно решать, как задачу ранжирования. Например, это можно делать с помощью попарного лосса. А именно, рассмотрим пару объектов, в которой i 1 i 1 – релевантный, а i 2 i 2 не релевантный для пользователя u u. Тогда мы можем использовать один из двух вариантов функции потерь: CrossEntropy ( 1.0 L(R(u,i 1 ),R(u,i 2 ))=CrossEntropy(1.0,σ(R(u,i 1 )−R(u,i 2 ))). Тем самым модель будет учиться ранжировать положительные примеры выше отрицательных. max L(R(u,i 1 ),R(u,i 2 ))=max(0,α−R(u,i 1 )+R(u,i 2 )) (triplet loss). При этом модель обучается так, чтобы положительный и отрицательный примеры как можно больше отличались. Эта функция потерь довольно популярна не только в DSSM сетках, но и в целом в задачах, где нужно обучить парные представления ) объектов ( q , d ) (q,d) из разных доменов так, чтобы для релевантных друг другу q q и d d эмбеддинги оказывались близкими, а для не релевантных далёкими. Full Product Softmax loss Рассмотрим батч ),…,(u M ,i M ,r M ) размера M M, где u t u t – пользователь, i t i t – пользователю, а r t r t – таргет, степень релевантности объекта пользователю. Построим по ним: матрицу эмбеддингов пользователей U∈R M×D ; матрицу эмбеддингов объектов W∈R M×D ; вектор таргетов r ∈ R M r∈R M . Рассмотрим матрицу softmax softmax(αUW T +β),UW T ∈R M×M , где softmax берётся по строкам DSSM Рассмотрим функцию потерь вид log ⁡ ( diag ( softmax L=−I{r>0} T ⋅log(diag(softmax(αUW T +β))) Эта функция потерь старается сделать так, чтобы для релевантных друг другу (с r > 0 r>0) пар ( u , i ) (u,i) скалярное произведение эмбеддингов ⟩ было максимальным. Трансформеры для рекомендаций В 2018 году появилась архитектура трансформеров на основе механизма внимания. Модели на основе трансформеров показали state-of-the-art результаты на большом числе NLP задач, а впоследствии оказалось, что они отлично подходят и для задач компьютерного зрения. С их помощью можно решать и задачи рекомендаций. Аналогия заключается в следующем: если в NLP трансформеры работают с последовательностями токенов, то в рекомендациях в качестве последовательности можно взять историю событий пользователя. Каждый элемент последовательности – это взаимодействие пользователя с объектом, например, клик на объект. Классические модели рекомендаций часто игнорируют тот факт, что история пользователя – это направленная последовательность, в которой порядок событий имеет значение. Трансформеры позволяют учитывать как порядок событий, так и сложные паттерны в поведении и интересах пользователя. Например, исследователи из Alibaba представили модель, которую назвали Behaviour Sequence Transformer. Авторы заявляют, что модель используется в продакшене. Модель решает задачу Click Through Rate (CTR) prediction – предсказание вероятности клика по объекту. transformer На вход модели подается история кликов",
        "Q: Каким будет результат следующего выражения?\nA: ```python\n>>> -30 % 10\n```\nРезультатом выражения \"-30 % 10\" будет - 0. Это происходит потому, что оператор % возвращает остаток от деления первого числа на второе, и в данном случае -30 можно\nразбить на целое количество десяток и остаток 0. Поэтому -30 % 10 равно 0.",
        "вариант — пойти в направлении ), как делалось ранее; второй — пойти в направлении антиградиента. Также показаны линии уровня значений функции потерь. Функция потерь в этом примере устроена таким образом, что , из-за чего шаг по антиградиенту оказывается более выгодным. Движение в сторону антиградиента более выгодно с точки зрения минимизации функции потерь — плюс оно также позволяет справляться с ситуациями, когда явно посчитать остаток (разницу между целевым значением и предсказанием) не представляется возможным. Один из таких примеров — задача ранжирования. В задаче ранжирования объекты в датасете разбиты на группы и требуется построить модель, по предсказаниям которой можно было бы «правильно» упорядочить документы в каждой группе (обычно по убыванию предсказания модели). Что значит упорядочить «правильно»? Это значит, что полученная по предсказаниям модели перестановка объектов в группе должна быть близка к идеальной по некоторой метрике. Как задается идеальная перестановка? Есть два способа: Первый способ — проставить каждому объекту число y y, по которому можно отсортировать объекты для получения идеальной перестановки. Это число можно рассматривать как таргет и обучать модель регрессии — в некоторых случаях это даже будет работать хорошо. Второй способ — задать набор пар объектов, которые обозначают их порядок относительно друг друга в идеальной перестановке. То есть пара ( i , j ) (i,j) означает, что объект с номером i i должен стоять раньше в перестановке, чем объект с номером j j. Во втором способе таргетов у объектов нет, но дифференцируемая функция потерь есть — в библиотеке CatBoost она называется PairLogit и вычисляется по формуле: PairLogit= ∣Pairs∣ − p,n∈Pairs ∑ (log( 1+e −(a где — это предсказания модели на объектах p p и n n соответственно. Градиент такой функции потерь посчитать можно, а разницу между предсказанием и истинным значением — нет. Математическое обоснование Попробуем записать наши интуитивные соображения более формально. Пусть L L – дифференцируемая функция потерь, а наш алгоритм a ( x ) a(x) представляет собой композицию базовых алгоритмов: a(x)=a k (x)=b 1 (x)+…+b k (x) Мы строим нашу композицию «жадно»: (x)=a k−1 (x)+b k (x), где вновь добавляемый базовый алгоритм b k b k обучается так, чтобы улучшить предсказания текущей композиции: b k = argminb∈B b∈B argmin i=1 ∑ N L(y i ,a k−1 (x i )+b(x i )) Модель b 0 b 0 выбирается так, чтобы минимизировать потери на обучающей выборке: b 0 = argminb∈B b∈B argmin i=1 ∑ N L(y i ,b(x i )) Для построения базовых алгоритмов на следующих шагах рассмотрим разложение Тейлора функции потерь L L до первого члена в окрестности точки k−1 (x i )): L(y i ,a k−1 (x i )+b(x i ))≈L(y i ,a k−1 (x i ))+b(x i ) ∂z ∂L(y i ,z) z=a k−1 (x i ) =L(y i ,a k−1 (x i ))+b(x i )g i k−1 Избавившись от постоянных членов, мы получим следующую оптимизационную задачу: b k ≈ argminb∈B b∈B argmin i=1 ∑ N b(x i )g i k−1 Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют b ( x i ) b(x i ), пропорциональные значениям k−1 . Поэтому на каждой итерации базовые"
      ]
    },
    {
      "index": 24,
      "question": "Напишите скрипт на SQL.В таблице users есть дублирующиеся email (колонки id, email, created_at). Найдите все дубликаты и оставьте только самую раннюю запись для каждого email.",
      "ground_truth": "SELECT \r\n    email,\r\n    COUNT(*) as duplicate_count,\r\n    MIN(created_at) as first_created,\r\n    MAX(created_at) as last_created\r\nFROM users\r\nGROUP BY email\r\nHAVING COUNT(*) > 1;",
      "model_answer": "На основе предоставленного контекста о работе с данными и SQL, вот скрипт для решения вашей задачи:\n\n```sql\n-- Находим дублирующиеся email и оставляем только самую раннюю запись\n-- Сначала идентифицируем дубликаты\nSELECT \n    email,\n    COUNT(*) as duplicate_count,\n    MIN(created_at) as earliest_date,\n    MIN(id) as earliest_id\nFROM users\nGROUP BY email\nHAVING COUNT(*) > 1;\n\n-- Удаляем дубликаты, оставляя только самую раннюю запись для каждого email\nDELETE FROM users\nWHERE id NOT IN (\n    SELECT MIN(id)\n    FROM users\n    GROUP BY email\n);\n```\n\n**Объяснение решения:**\n\n1. **Первая часть запроса** показывает все дублирующиеся email с информацией:\n   - Сам email\n   - Количество дубликатов\n   - Самую раннюю дату создания\n   - ID самой ранней записи\n\n2. **Вторая часть (DELETE запрос)** удаляет все дублирующиеся записи, оставляя только одну самую раннюю запись для каждого уникального email. Логика:\n   - Подзапрос находит минимальный ID для каждого email (самая ранняя запись)\n   - Основной запрос удаляет все записи, чьи ID не входят в этот список\n\n**Важное примечание:** Перед выполнением DELETE запроса рекомендуется:\n- Сделать резервную копию таблицы\n- Протестировать запрос на тестовых данных\n- Выполнить SELECT часть сначала, чтобы убедиться в корректности идентификации дубликатов\n\nЭто решение соответствует принципам работы с данными, описанным в контексте, где упоминается выполнение DML команд и манипуляция данными в таблицах.",
      "contexts": [
        "алгоритма работают на уменьшение среднего квадрата евклидова расстояния от объектов до центров их кластеров: k=1 ∑ K i=1 I[a(x i )=k] На шаге отнесения объектов к одному из кластеров мы выбираем кластер с ближайшим центроидом, то есть минимизируем каждое слагаемое в Φ 0 Φ 0 : все потенциально большие слагаемые мы зануляем, а оставляем ненулевыми только наименьшие из возможных (при условии фиксирования центров кластеров). На шаге пересчёта центров кластеров мы выбираем центр таким образом, чтобы при фиксированном наборе объектов, относящихся к кластеру, для всех k k минимизировать выражение, стоящее под суммой по i=1 I[a(x i )=k] Здесь уже становится принципиально, что мы определяем квадрат расстояния как квадрат разности векторов, так как именно отсюда при дифференцировании по μ k μ k и записи необходимого условия экстремума получается, что центры кластеров нужно пересчитывать как средние арифметические x i x i , принадлежащих кластеру. Этих соображений, конечно, недостаточно, чтобы утверждать, что мы найдём минимум Φ 0 Φ 0 . Более того, гарантии того, что мы найдём глобальный минимум, вообще говоря, нет. Однако, потратив чуть больше усилий, можно доказать, что процесс сойдётся в один из локальных минимумов. Также можно справедливо заметить, что, так как любой центр кластера — это среднее арифметическое входящих в кластер объектов x i x i , на выборке фиксированного размера есть лишь конечное множество потенциальных центров кластеров. Если предположить, что в ходе работы K-means не зацикливается, отсюда следует, что рано или поздно центры кластеров не изменятся на следующем шаге и алгоритм сойдётся. При этом фактическая сходимость, конечно же, происходит задолго до полного перебора всех возможных центров кластеров. Иерархическая агломеративная кластеризация Другой классический метод кластеризации — это иерархическая кластеризация. Иногда дополнительно уточняют: иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации на агломеративные (agglomerative) и дивизивные, или дивизионные (divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. 19 Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Расстояния в иерархической кластеризации Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное",
        "Q: Напишите регулярное выражение, которое будет принимать идентификатор электронной почты.\nA: Используйте модуль re.\nДля написания регулярного выражения, которое будет принимать идентификатор электронной почты, вы можете использовать следующий код в Python, используя модуль\nre:\nimport re\nemail_regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\ndef is_valid_email(email):\nif re.match(email_regex, email):\nreturn True\nelse:\nreturn False\nВ этом коде мы создаем регулярное выражение email_regex, которое проверяет, соответствует ли переданный идентификатор электронной почты заданному формату.\nЗатем мы используем функцию re.match() для сравнения переданного идентификатора электронной почты с регулярным выражением. Если совпадение найдено, мы\nвозвращаем True, в противном случае False.\nНапример, вызов is_valid_email('example@mail.com') вернет True, а вызов is_valid_email('not_valid_email') вернет False.",
        "могут быть очень далеки друг от друга. Зачастую для решения этой проблемы вначале обучают представления. Применение Из-за своих недостатков алгоритм очень неэффективен в задачах с большим количеством данных. Однако у него всё равно есть много применений в реальном мире. Приведём лишь некоторые из них: Рекомендательные системы. Если посмотреть на саму формулировку задачи «предложить пользователю что-то похожее на то, что он любит», то KNN прямо напрашивается в качестве решения. Несмотря на то что сейчас часто используются более совершенные алгоритмы, метод ближайших соседей всё равно применяется в качестве хорошего бейзлайна. Поиск семантически похожих документов. Если векторные представления близки друг к другу, то темы документов схожи. Поиск аномалий и выбросов. Из-за того что алгоритм запоминает обучающую выборку полностью, ему легко посмотреть, насколько целевой объект похож на все данные, которые он видел. Задача кредитного скоринга. Рейтинги двух людей, у которых примерно одинаковая зарплата, схожие должности и кредитные истории, не должны сильно отличаться, поэтому KNN отлично подходит для решения такой задачи. Вопрос сложности алгоритма неочевиден и требует детального анализа, который будет частично проведён в следующем разделе. Поиск ближайших соседей Для того чтобы применять метод ближайших соседей, нужно уметь как-то находить этих самых соседей. С первого взгляда может показаться, что никакой проблемы нет: действительно, можно ведь просто перебрать все объекты из обучающей выборки X=(x i ,y i ) i=1 N , посчитать для каждого из них расстояние до тестового объекта и затем найти минимум. Однако несмотря на то что сложность такого поиска линейная по N N, она также зависит и от размерности пространства признаков. Если x ∈ R D x∈R D , то сложность такого алгоритма поиска O ( N D ) O(ND). Если вспомнить, что в типичной задаче машинного обучения количество признаков D D может быть порядка 100 100, а размер выборки и вовсе может исчисляться десятками и сотнями тысяч объектов, то становится ясно, что такая сложность никуда не годится. Проблема осложняется ещё и тем, что данный поиск необходимо выполнять на этапе применения модели, который должен быть быстрым. Всё это означает, что возникает необходимость в более быстрых методах поиска ближайших соседей, чем простой перебор. Все такие методы можно поделить на две основные группы: точные и приближённые. Последние, как следует из их названия, находят соседей лишь приближённо, то есть найденные объекты хоть и будут действительно близки, но не обязательно будут самыми близкими. В этом разделе мы подробнее рассмотрим методы из каждой группы. Перед началом обзора стоит сказать, что хоть мы и рассматриваем алгоритмы поиска соседей именно в контексте их использования в KNN, область их применения значительно шире, и она не ограничивается исключительно машинным обучением. Например, на их основе работает любая информационно-поисковая система, от поиска в «Гугле» или «Яндексе» до всем известных алгоритмов «Ютьюба». Поиск ближайших соседей: точные методы Точных методов существует довольно мало. Можно сказать, что их, по сути, два. Первый — полный перебор с различными эвристиками. Например, можно выбрать подмножество признаков и считать расстояние только по ним. Оно будет оценкой снизу на реальное расстояние, поэтому если оно уже больше, чем до текущего ближайшего объекта, то можно сразу отбросить этот объект и переходить к следующему. Такие",
        "Q: Выполнение команд DML через программы Python?\nA: Можно выполнять команды DML (Data Manipulation Language) в программе, используя различные библиотеки, такие как Psycopg2 для баз данных PostgreSQL или sqlite3\nдля баз данных SQLite. Эти библиотеки обеспечивают соединение с базой данных и методы для выполнения запросов к ней, включая запросы SELECT, INSERT, UPDATE\nи DELETE. Вот пример использования Psycopg2 для выполнения запроса INSERT в базу данных PostgreSQL:\nimport psycopg2\nconn = psycopg2.connect(\"dbname=mydatabase user=myuser\")\ncur = conn.cursor()\ncur.execute(\"INSERT INTO mytable (column1, column2, column3) VALUES (%s, %s, %s)\", (value1, value2, value3))\nconn.commit()\nА вот пример использования sqlite3 для выполнения запроса SELECT в базе данных SQLite:\nimport sqlite3\nconn = sqlite3.connect('example.db')\ncur = conn.cursor()\ncur.execute('SELECT * FROM mytable')\nresults = cur.fetchall()\nОбратите внимание, что необходимо заменить mydatabase, myuser, mytable и т.д. на соответствующие значения для вашей базы данных.",
        "Q: Как отправить почту из скрипта Python?\nA: Для отправки электронной почты из скрипта Python можно использовать библиотеку smtplib. Вот простейший пример кода, отправляющий email с текстом:\nimport smtplib\nsender_email = \"your_email@example.com\"\nreceiver_email = \"recipient_email@example.com\"\nmessage = \"Привет от Питона!\"\nsmtp_server = smtplib.SMTP(\"smtp.gmail.com\", 587)\nsmtp_server.starttls()\nsmtp_server.login(sender_email, \"your_password\")\nsmtp_server.sendmail(sender_email, receiver_email, message)\nsmtp_server.quit()\nЗамените \"your_email@example.com\" на свой электронный адрес отправителя, \"recipient_email@example.com\" на адрес получателя и \"your_password\" на пароль для входа\nв вашу учетную запись электронной почты. Также вы можете изменить содержимое переменной message. Обратите внимание, что для отправки почты через Gmail\nпридется разрешить отправку писем из ненадежных приложений в настройках вашей учетной записи Google."
      ]
    },
    {
      "index": 25,
      "question": "Напишите скрипт на SQL. Найдите продукты, цена которых выше средней цены в их категории (таблица products с колонками product_id, category_id, price).",
      "ground_truth": "SELECT \r\n    product_id,\r\n    category_id,\r\n    price,\r\n    category_avg_price\r\nFROM (\r\n    SELECT \r\n        product_id,\r\n        category_id,\r\n        price,\r\n        AVG(price) OVER (PARTITION BY category_id) as category_avg_price\r\n    FROM products\r\n) t\r\nWHERE price > category_avg_price;",
      "model_answer": "В предоставленном контексте о деревьях решений и методах кластеризации нет информации, необходимой для ответа на ваш вопрос о написании SQL-запроса. Однако, основываясь на общих знаниях SQL, могу предложить решение.\n\nДля нахождения продуктов, цена которых выше средней по их категории, можно использовать подзапрос или оконную функцию. Вот два варианта:\n\n### Вариант 1: С использованием подзапроса в `JOIN`\n```sql\nSELECT p.product_id, p.category_id, p.price\nFROM products p\nJOIN (\n    SELECT category_id, AVG(price) as avg_price\n    FROM products\n    GROUP BY category_id\n) cat_avg ON p.category_id = cat_avg.category_id\nWHERE p.price > cat_avg.avg_price;\n```\n\n### Вариант 2: С использованием оконной функции (более эффективно)\n```sql\nSELECT product_id, category_id, price\nFROM (\n    SELECT *,\n           AVG(price) OVER (PARTITION BY category_id) as avg_category_price\n    FROM products\n) subquery\nWHERE price > avg_category_price;\n```\n\nОба запроса выполняют одну задачу:\n1. Вычисляют среднюю цену для каждой категории\n2. Сравнивают цену каждого продукта со средней ценой в его категории\n3. Выбирают только те продукты, где цена превышает среднюю\n\nВторой вариант с оконной функцией обычно предпочтительнее для больших таблиц, так как требует только одного прохода по данным.",
      "contexts": [
        "строго. Подставляя вектор c=(p 1 ,…,p K ) в выражение выше, мы в качестве информативности получим энтропию распределения классов: log ⁡ p k H(X m )=− k=1 ∑ K p k logp k Информативность в задаче классификации: критерий Джини Пусть предсказание модели — это распределение вероятностей классов ,…,c k ). Вместо логарифма правдоподобия в качестве критерия можно выбрать, например, метрику Бриера (за которой стоит всего лишь идея посчитать MSE от вероятностей). Тогда информативность получится равной min H(X min )∈X m ∑ k=1 ∑ K (c k −I[y i =k]) 2 Можно показать, что оптимальное значение этой метрики, как и в случае энтропии, достигается на векторе c c, состоящем из выборочных оценок частот классов ,…,p I[y i =k]. Если подставить ,…,p k ) в выражение выше и упростить его, получится критерий Джини: H(X m )= k=1 ∑ K p k (1−p k ) Критерий Джини допускает и следующую интерпретацию: H ( X m ) H(X m ) равно математическому ожиданию числа неправильно классифицированных объектов в случае, если мы будем приписывать им случайные метки из дискретного распределения, заданного вероятностями ,…,p k ). Неоптимальность полученных критериев Казалось бы, мы вывели критерии информативности для всех популярных задач, и они довольно логично следуют из их постановок, но получилось ли у нас обмануть NP-полноту и научиться строить оптимальные деревья легко и быстро? Конечно, нет. Простейший пример — решение задачи XOR с помощью жадного алгоритма и любого критерия, который мы построили выше: Источник Вне зависимости от того, что вы оптимизируете, жадный алгоритм не даст оптимального решения задачи XOR. Но этим примером проблемы не исчерпываются. Скажем, бывают ситуации, когда оптимальное с точки зрения выбранной метрики дерево вы получите с критерием ветвления, построенным по другой метрике (например, MSE-критерий для MAE-задачи или Джини для misclassification error). Особенности данных Категориальные признаки На первый взгляд, деревья прекрасно могут работать с категориальными переменными. А именно, если признак x i x i принимает значения из множества C=c 1 ,…,c M , то при очередном разбиении мы можем рассматривать по этому признаку произвольные сплиты вида C=C l ⊔C r (предикат будет иметь вид ]). Это очень логично и естественно, но проблема в том, что при больших M M у нас будет M−1 −1 сплитов, и перебирать их будет слишком долго. Было бы здорово уметь каким-то образом упорядочивать значения c m c m , чтобы работать с ними так же, как с обычными числами: разделяя на значения, «не превосходящие» и «большие» определённого порога. Оказывается, что для некоторых задач такое упорядочение можно построить вполне естественным образом. Так, для задачи бинарной классификации значения c m c m можно упорядочить по неубыванию доли объектов класса 1 с , после чего работать с ними, как со значениями вещественного признака. Показано, что в случае, если мы выбираем таким образом сплит, оптимальный с точки зрения энтропийного критерия или критерия Джини, то он будет оптимальным среди всех M−1 −1 сплитов. Для задачи регрессии с функцией потерь MSE значения c m c m можно упорядочивать по среднему значению таргета на подмножестве X∣x i =c m . Полученный таким образом сплит тоже будет оптимальным. Работа",
        "алгоритма работают на уменьшение среднего квадрата евклидова расстояния от объектов до центров их кластеров: k=1 ∑ K i=1 I[a(x i )=k] На шаге отнесения объектов к одному из кластеров мы выбираем кластер с ближайшим центроидом, то есть минимизируем каждое слагаемое в Φ 0 Φ 0 : все потенциально большие слагаемые мы зануляем, а оставляем ненулевыми только наименьшие из возможных (при условии фиксирования центров кластеров). На шаге пересчёта центров кластеров мы выбираем центр таким образом, чтобы при фиксированном наборе объектов, относящихся к кластеру, для всех k k минимизировать выражение, стоящее под суммой по i=1 I[a(x i )=k] Здесь уже становится принципиально, что мы определяем квадрат расстояния как квадрат разности векторов, так как именно отсюда при дифференцировании по μ k μ k и записи необходимого условия экстремума получается, что центры кластеров нужно пересчитывать как средние арифметические x i x i , принадлежащих кластеру. Этих соображений, конечно, недостаточно, чтобы утверждать, что мы найдём минимум Φ 0 Φ 0 . Более того, гарантии того, что мы найдём глобальный минимум, вообще говоря, нет. Однако, потратив чуть больше усилий, можно доказать, что процесс сойдётся в один из локальных минимумов. Также можно справедливо заметить, что, так как любой центр кластера — это среднее арифметическое входящих в кластер объектов x i x i , на выборке фиксированного размера есть лишь конечное множество потенциальных центров кластеров. Если предположить, что в ходе работы K-means не зацикливается, отсюда следует, что рано или поздно центры кластеров не изменятся на следующем шаге и алгоритм сойдётся. При этом фактическая сходимость, конечно же, происходит задолго до полного перебора всех возможных центров кластеров. Иерархическая агломеративная кластеризация Другой классический метод кластеризации — это иерархическая кластеризация. Иногда дополнительно уточняют: иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации на агломеративные (agglomerative) и дивизивные, или дивизионные (divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. 19 Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Расстояния в иерархической кластеризации Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное",
        "сложной для большинства практических задач и при этом слишком тяжёлой в плане вычислений. В первых параграфах мы будем рассматривать в основном предсказательные модели, то есть модели вида y=f(x), которые пытаются уловить зависимость между признаковым описанием x x объекта и таргетом y y. Но порой мы будем иметь дело и с моделями данных: например, «такой-то признак имеет нормальное распределение». Чаще всего предсказательные модели мы будем брать из некоторого параметрического семейства y=f w (x), где w w — параметры, которые мы будем подбирать по данным. Для примера давайте возьмём задачу предсказания цены квартиры. В качестве класса моделей выберем константные функции f(x)=c (то есть будем для всех квартир предсказывать одно и то же значение цены). Поскольку значение не зависит от x x, нам не очень важно, в каком виде получено признаковое описание: это может быть набор совершенно любых сведений о квартире. Не забудем зафиксировать метрику качества — среднее абсолютное отклонение (mean absolute error, она же MAE). min ⁡ f , MAE(f,X,y)=L(f,X,y)= N 1 i=1 ∑ N ∣f(x i )−y i ∣→ f min , где f f — это модель (та самая, f(x)=c), X=(x 1 ,…,x N ) — обучающие примеры (данные о квартирах, которые мы смогли достать), y=(y 1 ,…,y N ) — правильные ответы (то есть цены на известные нам квартиры). Чтобы найти минимум MAE, возьмём производную от выражения min ⁡ f , N 1 i=1 ∑ N ∣c−y i ∣→ f min , и приравняем её к нулю: L(f,X,y)= N 1 i=1 ∑ N sign(c−y i )=0 #{i∣y i <c}−#{i∣y i >c}=0 Нам подходят точки c c, для которых число y i y i , строго меньших c c, равно числу y i y i , строго больших c c. Таким образом, нам подходит медиана набора ,…,y f(x)=median(y). Вопрос на подумать. Давайте теперь в задаче предсказания цены квартиры рассмотрим метрику среднеквадратичное отклонение (MSE): MSE(f,X,y)= N 1 i=1 ∑ N (f(x i )−y i ) 2 Каким будет оптимальное значение параметра c c для константной модели f(x)=c? Прекрасно, значит, в классе константных функций мы можем найти оптимальную модель. Может быть, это можно сделать и в каком-нибудь более интересном классе? Этому вопросу и будет посвящена большая часть нашей книги. Классический курс ML состоит из описания классов моделей и способов работы с ними. Несмотря на то что для решения большинства практических задач на сегодня достаточно знать только два типа моделей — градиентный бустинг на решающих деревьях и нейросетевые модели — мы постараемся рассказать и про другие, чтобы развить у вас глубинное понимание предмета и дать возможность не только использовать лучшие сложившиеся практики, но и, при вашем желании, участвовать в проработке новых идей и поиске новых методов — уже в роли исследователя, а не просто инженера. Кроме выбора модели важен также выбор алгоритма обучения. Алгоритм обучения — это процедура, которая превращает обучающую выборку в обученную модель. Скажем, в примере выше для константной модели мы в качестве алгоритма обучения использовали поиск нуля градиента. Как мы увидим дальше, градиентные методы используются для обучения многих моделей, и это очень богатый класс методов оптимизации, из которого порой не",
        "Вопрос: Деревья\n  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "Определение порогов для категориальных и числовых признаков\nhttps://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e\n  \n  ",
        "Что такое дерево решений, и как оно работает?\nОтвет: Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.\nКаждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).\nПример:\nВ медицинской задаче:\n         * Вершина 1: \"Возраст > 40 лет?\"\n         * Да → Вершина 2: \"Курит?\"\n         * Нет → Прогноз: \"Низкий риск заболевания\".\n         * Вершина 2:\n         * Да → Прогноз: \"Высокий риск заболевания\".\n         * Нет → Прогноз: \"Средний риск заболевания\".\n  ",
        "  ",
        "Как строится дерево решений?\nВыбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:",
        "j ] i=1 ∑ N j=1 ∑ N I[y i <y j ]I ′ [f(x i )<f(x 0.5 [f(x i )<f(x j )]= ⎩ ⎨ ⎧ 0, 0.5 1, f(x i )>f(x j ) f(x i )=f(x j ) f(x i )<f(x I[y i <y j ]={ Чтобы детальнее разобраться, почему это так, советуем вам обратиться к материалам А.Г.Дьяконова. В каких случаях лучше отдать предпочтение этой метрике? Рассмотрим следующую задачу: некоторый сотовый оператор хочет научиться предсказывать, будет ли клиент пользоваться его услугами через месяц. На первый взгляд кажется, что задача сводится к бинарной классификации с метками 1, если клиент останется с компанией и 0 0 — иначе. Однако если копнуть глубже в процессы компании, то окажется, что такие метки практически бесполезны. Компании скорее интересно упорядочить клиентов по вероятности прекращения обслуживания и в зависимости от этого применять разные варианты удержания: кому-то прислать скидочный купон от партнёра, кому-то предложить скидку на следующий месяц, а кому-то и новый тариф на особых условиях. Таким образом, в любой задаче, где нам важна не метка сама по себе, а правильный порядок на объектах, имеет смысл применять AUC. Утверждение выше может вызывать у вас желание использовать AUC в качестве метрики в задачах ранжирования, но мы призываем вас быть аккуратными. Average Precision Будем постепенно уменьшать порог бинаризации. При этом полнота будет расти от 0 0 до 1 1, так как будет увеличиваться количество объектов, которым мы приписываем положительный класс (а количество объектов, на самом деле относящихся к положительному классу, очевидно, меняться не будет). Про точность же нельзя сказать ничего определённого, но мы понимаем, что скорее всего она будет выше при более высоком пороге отсечения (мы оставим только объекты, в которых модель «уверена» больше всего). Варьируя порог и пересчитывая значения Precision и Recall на каждом пороге, мы получим некоторую кривую примерно следующего вида: Источник Рассмотрим среднее значение точности (оно равно площади под кривой точность-полнота): AP =∫ 0 1 p(r)dr Получим показатель эффективности, который называется average precision. Как в случае матрицы ошибок мы переходили к скалярным показателям эффективности, так и в случае с кривой точность-полнота мы охарактеризовали ее в виде числа. Многоклассовая классификация Если классов становится больше двух, расчёт метрик усложняется. Если задача классификации на K K классов ставится как K K задач об отделении класса i i от остальных ( i=1,…,K), то для каждой из них можно посчитать свою матрицу ошибок. Затем есть два варианта получения итогового значения метрики из K K матриц ошибок: Усредняем элементы матрицы ошибок (TP, FP, TN, FN) между бинарными классификаторами, например TP= K 1 ∑ i=1 K TP i . Затем по одной усреднённой матрице ошибок считаем Precision, Recall, F-меру. Это называют микроусреднением. Считаем Precision, Recall для каждого классификатора отдельно, а потом усредняем. Это называют макроусреднением. Порядок усреднения влияет на результат в случае дисбаланса классов. Показатели TP, FP, FN — это счётчики объектов. Пусть некоторый класс обладает маленькой мощностью (обозначим её M M). Тогда значения TP и FN при классификации этого класса против остальных будут не больше M M, то есть тоже маленькие. Про FP мы ничего уверенно сказать не можем, но скорее всего"
      ]
    },
    {
      "index": 26,
      "question": "Реализуйте кастомную метрику для задачи регрессии: Symmetric Mean Absolute Percentage Error (SMAPE)",
      "ground_truth": "import numpy as np\r\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\r\nfrom scipy import stats\r\n\r\ndef smape(y_true, y_pred):\r\n    \"\"\"\r\n    Symmetric Mean Absolute Percentage Error\r\n    SMAPE = 100% * Σ(|y_true - y_pred| / (|y_true| + |y_pred|)) / n\r\n    \"\"\"\r\n    # Защита от деления на 0\r\n    denominator = np.abs(y_true) + np.abs(y_pred)\r\n    # Для случая, когда и истинное значение, и предсказание равны 0\r\n    denominator = np.where(denominator == 0, 1, denominator)\r\n    \r\n    smape_val = 100 * np.mean(2 * np.abs(y_pred - y_true) / denominator)\r\n    return smape_val\r\n\r\ndef mape(y_true, y_pred):\r\n    \"\"\"Mean Absolute Percentage Error\"\"\"\r\n    # Защита от нулей в y_true\r\n    mask = y_true != 0\r\n    if not np.any(mask):\r\n        return np.nan\r\n    return 100 * np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask]))\r\n\r\n# Пример использования с обработкой edge cases\r\ny_true = np.array([100, 200, 300, 0, 500])\r\ny_pred = np.array([110, 190, 320, 10, 480])\r\n\r\nprint(f\"SMAPE: {smape(y_true, y_pred):.2f}%\")\r\nprint(f\"MAPE: {mape(y_true, y_pred):.2f}%\")\r\nprint(f\"MAE: {mean_absolute_error(y_true, y_pred):.2f}\")\r\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_true, y_pred)):.2f}\")\r\n\r\n# Дополнительно: реализация weighted RMSE\r\ndef weighted_rmse(y_true, y_pred, weights=None):\r\n    \"\"\"RMSE с весами для наблюдений\"\"\"\r\n    if weights is None:\r\n        weights = np.ones_like(y_true)\r\n    \r\n    # Нормализуем веса\r\n    weights = weights / np.sum(weights) * len(weights)\r\n    \r\n    mse_weighted = np.mean(weights * (y_true - y_pred) ** 2)\r\n    return np.sqrt(mse_weighted)\r\n\r\n# Пример с весами\r\nweights = np.array([1.0, 0.5, 2.0, 0.1, 1.5])\r\nprint(f\"Weighted RMSE: {weighted_rmse(y_true, y_pred, weights):.2f}\")",
      "model_answer": "На основе предоставленного контекста, вот реализация кастомной метрики SMAPE (Symmetric Mean Absolute Percentage Error) для задачи регрессии.\n\nКонтекст объясняет, что метрики вроде MSE и MAE работают с абсолютными ошибками и могут не учитывать бизнес-требования, когда важнее минимизировать относительную, а не абсолютную ошибку (как в примере с прогнозированием спроса на товары с разным уровнем продаж). SMAPE — одна из метрик, которая учитывает относительные ошибки, симметрично наказывая за завышение и занижение прогноза. Она особенно полезна, когда масштаб целевой переменной вариативен.\n\n```python\nimport numpy as np\nfrom sklearn.metrics import make_scorer\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\ndef smape(y_true, y_pred):\n    \"\"\"\n    Вычисляет Symmetric Mean Absolute Percentage Error (SMAPE).\n\n    SMAPE = (100%/n) * Σ(|y_true - y_pred| / ((|y_true| + |y_pred|)/2))\n\n    Параметры:\n    y_true : array-like, истинные значения.\n    y_pred : array-like, предсказанные значения.\n\n    Возвращает:\n    score : float, значение SMAPE (в процентах, обычно от 0% до 200%).\n    \"\"\"\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n\n    # Для избежания деления на ноль, добавляем небольшое эпсилон.\n    # Также используем знаменатель как среднее абсолютных значений.\n    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2 + 1e-8 # +1e-8 для численной стабильности\n    smape_value = np.mean(np.abs(y_true - y_pred) / denominator) * 100\n\n    return smape_value\n\n# Пример использования с make_scorer для интеграции в sklearn (например, в GridSearchCV)\nsmape_scorer = make_scorer(smape, greater_is_better=False)  # Чем меньше SMAPE, тем лучше\n```\n\n**Объяснение и связь с контекстом:**\n\n1.  **Проблема абсолютных ошибок:** Контекст подчеркивает, что MAE и MSE суммируют абсолютные ошибки. В примере с товарами A (100 шт.) и B (10 шт.) ошибка в 2 единицы для товара B (относительная ошибка 20%) так же важна для MAE, как и ошибка в 2 единицы для товара A (относительная ошибка 2%). SMAPE решает эту проблему, рассматривая ошибку относительно масштаба значений.\n\n2.  **Относительные ошибки:** Контекст говорит: *\"Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку\"*. SMAPE — это метрика, основанная на относительной ошибке. Она вычисляет процент ошибки, нормированный на среднее от истинного и предсказанного значений, что делает её симметричной.\n\n3.  **Интерпретация:** Как и R² (упомянутый в контексте как нормализованная метрика), SMAPE позволяет легче понять качество модели. Идеальная модель даст SMAPE, близкий к 0%. Метрика ограничена сверху (примерно 200%), что облегчает интерпретацию по сравнению с неограниченной MSE.\n\n4.  **Чувствительность к выбросам:** В отличие от MSE, которая квадратично штрафует выбросы и может исказить сравнение моделей (как указано в контексте), SMAPE менее чувствительна к ним из-за нормировки. Однако стоит быть осторожным, если в данных есть значения, близкие к нулю, так как знаменатель формулы может стать очень маленьким.\n\n**Использование в конвейере scikit-learn:**\nВы можете использовать `smape_scorer` в качестве метрики для кросс-валидации или подбора гиперпараметров.\n\n```python\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Предположим, X_train, y_train - ваши данные\nmodel = RandomForestRegressor()\nscores = cross_val_score(model, X_train, y_train, cv=5, scoring=smape_scorer)\nprint(f\"Средний SMAPE: {scores.mean():.2f}%\")\n```\n\nЭта реализация напрямую следует логике, изложенной в контексте: когда бизнес-требования делают относительную точность прогноза более важной, чем абсолютную, такие метрики, как SMAPE, становятся предпочтительным инструментом для оценки и сравнения моделей регрессии.",
      "contexts": [
        "метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. MSE(y true ,y pred )= N 1 i=1 ∑ N (y i −f(x i )) 2 Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток y ˉ y ˉ . При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки: =1− ∑ i=1 i=1 N (y i −f(x i )) 2 . У идеального решающего правила R 2 R 2 равен 1 1, у наилучшего константного предсказания он равен 0 0 на обучающей выборке. Можно заметить, что R 2 R 2 показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. MAE Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике MAE (mean absolute error): MAE(y true ,y pred )= N 1 i=1 ∑ N ∣y i −f(x i )∣ Метрики, учитывающие относительные ошибки И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на",
        "метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. MSE(y true ,y pred )= N 1 i=1 ∑ N (y i −f(x i )) 2 Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток y ˉ y ˉ . При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки: =1− ∑ i=1 i=1 N (y i −f(x i )) 2 . У идеального решающего правила R 2 R 2 равен 1 1, у наилучшего константного предсказания он равен 0 0 на обучающей выборке. Можно заметить, что R 2 R 2 показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. MAE Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике MAE (mean absolute error): MAE(y true ,y pred )= N 1 i=1 ∑ N ∣y i −f(x i )∣ Метрики, учитывающие относительные ошибки И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на",
        "метрик в задаче регрессии. Она уже знакома вам, так как применяется в качестве функции потерь (или входит в ее состав) во многих ранее рассмотренных методах. MSE(y true ,y pred )= N 1 i=1 ∑ N (y i −f(x i )) 2 Иногда для того, чтобы показатель эффективности MSE имел размерность исходных данных, из него извлекают квадратный корень и получают показатель эффективности RMSE. MSE неограничен сверху, и может быть нелегко понять, насколько «хорошим» или «плохим» является то или иное его значение. Чтобы появились какие-то ориентиры, делают следующее: Берут наилучшее константное предсказание с точки зрения MSE — среднее арифметическое меток y ˉ y ˉ . При этом чтобы не было подглядывания в test, среднее нужно вычислять по обучающей выборке Рассматривают в качестве показателя ошибки: =1− ∑ i=1 i=1 N (y i −f(x i )) 2 . У идеального решающего правила R 2 R 2 равен 1 1, у наилучшего константного предсказания он равен 0 0 на обучающей выборке. Можно заметить, что R 2 R 2 показывает, какая доля дисперсии таргетов (знаменатель) объяснена моделью. MSE квадратично штрафует за большие ошибки на объектах. Мы уже видели проявление этого при обучении моделей методом минимизации квадратичных ошибок — там это проявлялось в том, что модель старалась хорошо подстроиться под выбросы. Пусть теперь мы хотим использовать MSE для оценки наших регрессионных моделей. Если большие ошибки для нас действительно неприемлемы, то квадратичный штраф за них — очень полезное свойство (и его даже можно усиливать, повышая степень, в которую мы возводим ошибку на объекте). Однако если в наших тестовых данных присутствуют выбросы, то нам будет сложно объективно сравнить модели между собой: ошибки на выбросах будет маскировать различия в ошибках на основном множестве объектов. Таким образом, если мы будем сравнивать две модели при помощи MSE, у нас будет выигрывать та модель, у которой меньше ошибка на объектах-выбросах, а это, скорее всего, не то, чего требует от нас наша бизнес-задача. MAE Использовать RMSE для сравнения моделей на выборках с большим количеством выбросов может быть неудобно. В таких случаях прибегают к также знакомой вам в качестве функции потери метрике MAE (mean absolute error): MAE(y true ,y pred )= N 1 i=1 ∑ N ∣y i −f(x i )∣ Метрики, учитывающие относительные ошибки И MSE и MAE считаются как сумма абсолютных ошибок на объектах. Рассмотрим следующую задачу: мы хотим спрогнозировать спрос товаров на следующий месяц. Пусть у нас есть два продукта: продукт A продаётся в количестве 100 штук, а продукт В в количестве 10 штук. И пусть базовая модель предсказывает количество продаж продукта A как 98 штук, а продукта B как 8 штук. Ошибки на этих объектах добавляют 4 штрафных единицы в MAE. И есть 2 модели-кандидата на улучшение. Первая предсказывает товар А 99 штук, а товар B 8 штук. Вторая предсказывает товар А 98 штук, а товар B 9 штук. Обе модели улучшают MAE базовой модели на 1 единицу. Однако, с точки зрения бизнес-заказчика вторая модель может оказаться предпочтительнее, так как предсказание продажи редких товаров может быть приоритетнее. Один из способов учесть такое требование — рассматривать не абсолютную, а относительную ошибку на",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные",
        "Благодаря большому дисбалансу, Accuracy dummy-классификатора, объявляющего все документы нерелевантными, будет близка к единице. Напомним, что Accuracy Accuracy= TP+TN+FP+FN TP+TN , и в нашем случае высокое значение метрики будет обеспечено членом TN, в то время для пользователей более важен высокий TP. Поэтому в случае ассиметрии классов, можно использовать метрики, которые не учитывают TN и ориентируются на TP. Если мы рассмотрим долю правильно предсказанных положительных объектов среди всех объектов, предсказанных положительным классом, то мы получим метрику, которая называется точностью (precision) Precision Precision= TP+FP TP Интуитивно метрика показывает долю релевантных документов среди всех найденных классификатором. Чем меньше ложноположительных срабатываний будет допускать модель, тем больше будет её Precision. Если же мы рассмотрим долю правильно найденных положительных объектов среди всех объектов положительного класса, то мы получим метрику, которая называется полнотой (recall) Recall Recall= TP+FN TP Интуитивно метрика показывает долю найденных документов из всех релевантных. Чем меньше ложно отрицательных срабатываний, тем выше recall модели. Например, в задаче предсказания злокачественности опухоли точность показывает, сколько из определённых нами как злокачественные опухолей действительно злокачественные, а полнота — какую долю злокачественных опухолей нам удалось выявить. Хорошее понимание происходящего даёт следующая картинка: Источник Recall@k, Precision@k Метрики Recall и Precision хорошо подходят для задачи поиска «документ d релевантен запросу q», когда из списка рекомендованных алгоритмом документов нас интересует только первый. Но не всегда алгоритм машинного обучения вынужден работать в таких жестких условиях. Может быть такое, что вполне достаточно, что релевантный документ попал в первые k рекомендованных. Например, в интерфейсе выдачи первые три подсказки видны всегда одновременно и вообще не очень понятно, какой у них порядок. Тогда более честной оценкой качества алгоритма будет «в выдаче D размера k по запросу q нашлись релевантные документы». Для расчёта метрики по всей выборке объединим все выдачи и рассчитаем precision, recall как обычно подокументно. F1-мера Как мы уже отмечали ранее, модели очень удобно сравнивать, когда их качество выражено одним числом. В случае пары Precision-Recall существует популярный способ скомпоновать их в одну метрику - взять их среднее гармоническое. Данный показатель эффективности исторически носит название F1-меры (F1-measure). Recall 1 + Precision Recall+Precision Recall⋅Precision = TP+ 2 FP+FN TP Стоит иметь в виду, что F1-мера предполагает одинаковую важность Precision и Recall, если одна из этих метрик для вас приоритетнее, то можно воспользоваться F β F β мерой: =(β 2 +1) Recall+β 2 Precision Recall⋅Precision Бинарная классификация: вероятности классов Многие модели бинарной классификации устроены так, что класс объекта получается бинаризацией выхода классификатора по некоторому фиксированному порогу: f(x;w,w 0 )=I[g(x,w)>w 0 ]. Например, модель логистической регрессии возвращает оценку вероятности принадлежности примера к положительному классу. Другие модели бинарной классификации обычно возвращают произвольные вещественные значения, но существуют техники, называемые калибровкой классификатора, которые позволяют преобразовать предсказания в более или менее корректную оценку вероятности принадлежности к положительному классу. Как оценить качество предсказываемых вероятностей, если именно они являются нашей конечной целью? Общепринятой мерой является логистическая функция потерь, которую мы изучали раньше, когда говорили об устройстве некоторых методов классификации (например уже упоминавшейся логистической регрессии). Если же нашей целью является построение прогноза в терминах метки класса, то нам нужно учесть, что в зависимости от порога мы будем получать разные"
      ]
    },
    {
      "index": 27,
      "question": "Что такое иерархическая агломеративная кластеризация, чем отличается от дивизионных алгоритмов?\r\n",
      "ground_truth": "Это тип кластеризации, при котором мы постепенно объединяем объекты в кластеры, начиная с того, что каждая точка — отдельный кластер, и в итоге объединяем всё в один.\r\nАлгоритм:\r\nСтарт: каждая точка — это свой кластер.\r\nВычисляется расстояние между всеми кластерами.\r\nНаходим два ближайших кластера и объединяем их.\r\nОбновляем матрицу расстояний.\r\nПовторяем шаги 2–4, пока не останется один кластер (или не достигнут критерий остановки).",
      "model_answer": "**Ответ на основе предоставленного контекста:**\n\n**Иерархическая агломеративная кластеризация** — это метод кластеризации, который строит древовидную (иерархическую) структуру кластеров, последовательно объединяя (агломерируя) более мелкие кластеры в более крупные.\n\n**Принцип работы алгоритма (как описано в контексте):**\n1.  **Инициализация:** Каждый объект выборки помещается в свой собственный кластер. То есть изначально создаётся столько кластеров, сколько объектов.\n2.  **Итеративное слияние:** На каждой итерации находится пара двух **ближайших** кластеров и объединяется в один новый кластер.\n3.  **Критерий останова:** Процесс повторяется, пока не будет выполнено условие остановки (например, не останется заданное количество кластеров или не будет достигнуто некоторое пороговое расстояние между кластерами). В результате последовательности объединений формируется **дендрограмма** — древовидная схема, показывающая вложенность кластеров.\n\n**Ключевое отличие от дивизионных (дивизивных) алгоритмов:**\n\n*   **Агломеративная кластеризация** — это подход **снизу-вверх (bottom-up)**. Алгоритм начинает с множества элементарных кластеров (каждый объект сам по себе) и последовательно объединяет их, уменьшая общее количество кластеров.\n*   **Дивизионная (дивизивная) кластеризация** — это подход **сверху-вниз (top-down)**. Алгоритм начинает с одного большого кластера, содержащего все объекты, и последовательно разделяет его на всё более мелкие кластеры.\n\nТаким образом, оба метода относятся к **иерархической кластеризации** (поскольку оба формируют древовидную структуру вложенных кластеров), но используют противоположные стратегии её построения. В предоставленном контексте подчёркивается, что агломеративные алгоритмы более классические и распространены.",
      "contexts": [
        "классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто встречающийся класс среди объектов из (u): a ( u ) = argmax⁡y∈Y (2) a(u)= y∈Y argmax i=1 ∑ k I[y u (i) =y](2) Формула может показаться страшной, но на самом деле всё довольно просто: для каждой метки класса y ∈ Y y∈Y количество соседей u u с такой меткой можно посчитать, просто просуммировав по всем соседям индикаторы событий, соответствующих тому, что метка соседа равна y y. Легко заметить, что этот алгоритм позволяет также оценивать вероятности классов. Для этого достаточно просто посчитать частоты классов соседей: P(u∼y)= k ∑ i=1 k I[y u (i) =y] Стоит, однако, понимать, что, хоть такая функция и удовлетворяет свойствам вероятности (она неотрицательна, аддитивна и ограничена единицей), это не более чем эвристика. Несмотря на то что формально фаза обучения отсутствует, алгоритм может легко переобучиться. Вы можете убедиться в этом сами, использовав маленькое количество соседей (например, одного или двух), — границы классов оказываются довольно сложными. Происходит это из-за того, что параметрами алгоритма можно считать всю обучающую выборку, довольно большую по размеру. Из-за этого алгоритму легко подстроиться под конкретные данные. По ссылке вы можете увидеть интерактивный пример работы алгоритма. Автор примера - Анастасия Чирикова. Выбор метрики Может возникнуть закономерный вопрос, как же правильно выбрать функцию расстояния ρ ρ. В подавляющем большинстве случаев обычное евклидово расстояние ρ(x,y)= будет хорошим выбором. Однако в некоторых случаях другие функции будут подходить лучше, поэтому давайте разберём ещё несколько функций, наиболее используемых на практике. 2 Манхэттенская метрика ρ(x,y)= Часто используется в высокоразмерных пространствах из-за лучшей устойчивости к выбросам. Представим, что два объекта в 1000-размерном пространстве почти идентичны, но сильно отличаются по одному из признаков. Это почти наверняка свидетельствует о выбросе в этом признаке, и объекты, скорее всего, очень близки. Однако евклидово расстояние усилит различие в единственном признаке и сделает их более далёкими друг от друга. Этого недостатка лишена манхэттенская метрика — в ней вместо квадрата используется модуль. Метрика Минковского ρ(x,y)=( 1/p Является обобщением евклидовой ( p = 2 p=2) и манхэттенской ( p = 1 p=1) метрик. Косинусное расстояние cos ρ(x,y)=1−cosθ=1− ∥x∥∥y∥ x⋅y Эта метрика хороша тем, что не зависит от норм векторов. Такое поведение бывает полезно в некоторых задачах, например при поиске похожих документов. В качестве признаков там часто используются количества слов. При этом интуитивно кажется, что если в тексте использовать каждое слово в два раза больше, то тема этого текста поменяться не должна. Поэтому как раз в этом случае нам не важна норма вектор-признака, и в задачах, связанных с текстами, часто применяется именно",
        "двух шагов, обоснованность применения различных метрик (расстояний между точками, а не метрик качества 😃 или функций близости связана с тем, «ломают» они какой-либо из этих шагов или нет. Первый шаг с отнесением объектов к ближайшим центрам не зависит от вида метрики. Второй шаг предполагает пересчёт центров как среднего арифметического входящих в кластер точек, и вот здесь будет подвох: к оптимальности выбора центров в среднем арифметическом приводит именно евклидова метрика (подробнее в разделе «Что оптимизирует K-means»). Однако на практике никто не мешает использовать метод и без должного обоснования, поэтому можно экспериментировать с любыми расстояниями, с той лишь оговоркой, что не будет никаких теоретических гарантий, что метод сработает. Наиболее распространённая альтернатива евклидовой метрике — это косинусная мера близости векторов (она особенно популярна в задачах анализа текстов): CosineSimilarity(μ ⋅∥x При её использовании стоит не забывать, что косинусная мера — это функция близости, а не расстояние, так что чем больше её значения, тем ближе друг к другу векторы. Mini-batch K-means Несложно заметить, что, если считать K K и размерность пространства признаков константами, оба шага алгоритма работают за O ( n ) O(n), где n — количество объектов обучающей выборки. Отсюда возникает идея ускорения работы алгоритма. В mini-batch K-means мы не считаем шаги сразу на всей выборке, а на каждой итерации выбираем случайную подвыборку (мини-батч) и работаем на ней. В случае когда исходная выборка очень велика, переход к пакетной обработке не приводит к большой потере качества, зато значительно ускоряет работу алгоритма. Понижение размерности С другой стороны, вычисление расстояний и средних делается за O ( d ) O(d), где d d — размерность пространства признаков, так что другая идея ускорения K-means — это предварительно понизить размерность пространства признаков (с помощью PCA или эмбеддингов). Особенно удачно эта идея работает в задачах кластеризации текстов, когда K-means применяют на эмбеддингах слов: получается выиграть не только в скорости работы, но и в интерпретируемости результатов кластеризации. Кстати, сам алгоритм кластеризации тоже можно использовать как метод понижения размерности. Если вы решаете задачу обучения с учителем и пространство признаков очень разнообразно (то есть обучающая выборка не даёт вам достаточно статистики при столь большом числе признаков), можно выполнить кластеризацию объектов выборки на 500 или 1000 кластеров и оперировать попаданием объектов в какой-то кластер как признаком. Такой подход называется квантизацией пространства признаков (feature space quantization) и часто помогает на практике, когда нужно огрубить признаки, добавить им интерпретируемости или же, наоборот, обезличить. Хрестоматийный пример такого использования кластеризации — метод bag of visual words, расширяющий bag of words из анализа текстов на работу с изображениями. Идея метода в том, чтобы строить признаковое описание изображений на основе входящих в него фрагментов: так, изображения с лицами будут содержать фрагменты с носом, глазами, ртом, а изображения с машинами — колёса, зеркала, двери. Но проблема здесь в том, что нарезать такие фрагменты из обучающей выборки и искать точные совпадения в новых примерах изображений, которые нужно классифицировать, — безнадёжная затея. В жизни фрагменты изображений не повторяются в других изображениях с попиксельной точностью. Решение этой проблемы оказалось возможным при помощи алгоритмов кластеризации (исторически использовался именно K-means): фрагменты изображений из обучающей выборки кластеризовали на",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,",
        "алгоритма работают на уменьшение среднего квадрата евклидова расстояния от объектов до центров их кластеров: k=1 ∑ K i=1 I[a(x i )=k] На шаге отнесения объектов к одному из кластеров мы выбираем кластер с ближайшим центроидом, то есть минимизируем каждое слагаемое в Φ 0 Φ 0 : все потенциально большие слагаемые мы зануляем, а оставляем ненулевыми только наименьшие из возможных (при условии фиксирования центров кластеров). На шаге пересчёта центров кластеров мы выбираем центр таким образом, чтобы при фиксированном наборе объектов, относящихся к кластеру, для всех k k минимизировать выражение, стоящее под суммой по i=1 I[a(x i )=k] Здесь уже становится принципиально, что мы определяем квадрат расстояния как квадрат разности векторов, так как именно отсюда при дифференцировании по μ k μ k и записи необходимого условия экстремума получается, что центры кластеров нужно пересчитывать как средние арифметические x i x i , принадлежащих кластеру. Этих соображений, конечно, недостаточно, чтобы утверждать, что мы найдём минимум Φ 0 Φ 0 . Более того, гарантии того, что мы найдём глобальный минимум, вообще говоря, нет. Однако, потратив чуть больше усилий, можно доказать, что процесс сойдётся в один из локальных минимумов. Также можно справедливо заметить, что, так как любой центр кластера — это среднее арифметическое входящих в кластер объектов x i x i , на выборке фиксированного размера есть лишь конечное множество потенциальных центров кластеров. Если предположить, что в ходе работы K-means не зацикливается, отсюда следует, что рано или поздно центры кластеров не изменятся на следующем шаге и алгоритм сойдётся. При этом фактическая сходимость, конечно же, происходит задолго до полного перебора всех возможных центров кластеров. Иерархическая агломеративная кластеризация Другой классический метод кластеризации — это иерархическая кластеризация. Иногда дополнительно уточняют: иерархическая агломеративная кластеризация. Название указывает сразу на два обстоятельства. Во-первых, есть деление алгоритмов кластеризации на агломеративные (agglomerative) и дивизивные, или дивизионные (divisive). Агломеративные алгоритмы начинают с небольших кластеров (обычно с кластеров, состоящих из одного объекта) и постепенно объединяют их в кластеры побольше. Дивизивные начинают с больших кластеров (обычно – с одного единственного кластера) и постепенно делят на кластеры поменьше. 19 Во-вторых, кластеризация бывает, по аналогии с оргструктурой в организациях, плоской (когда все кластеры равноправны и находятся на одном уровне кластеризации) и иерархической (когда кластеры бывают вложены друг в друга и образуют древовидную структуру). В случае иерархической агломеративной кластеризации мы действительно будем начинать с кластеров из одного объекта, постепенно объединяя их, а уже последовательность этих объединений даст структуру вложенности кластеров. Даже если в итоге мы будем использовать кластеры с одного уровня, не углубляясь ни в какую вложенность, кластеризация всё равно называется иерархической, так как иерархия естественным образом возникает в процессе работы алгоритма. Сам алгоритм выглядит предельно просто: Создаём столько кластеров, сколько у нас объектов в выборке, каждый объект — в своём отдельном кластере. Повторяем итеративно слияние двух ближайших кластеров, пока не выполнится критерий останова. Расстояния в иерархической кластеризации Как измерить расстояние между кластерами из одного объекта? Нужно просто взять расстояние между этими объектами. Остаётся вопрос, как обобщить расстояние между объектами до расстояния между кластерами (если в них более одного объекта). Традиционные решения — брать среднее расстояние между объектами кластеров, минимальное",
        "Смысл метрических методов очень хорошо раскрывает фраза «Скажи мне, кто твой друг, и я скажу, кто ты». Алгоритмы этого класса почти не имеют фазы обучения. Вместо этого они просто запоминают всю обучающую выборку, а на этапе предсказания просто ищут объекты, похожие на целевой. Такой процесс называют lazy learning, потому что никакого обучения, по сути, не происходит. Также метрические модели являются непараметрическими, потому что они не делают явных допущений о глобальных законах, которым подчиняются данные. Так, линейная регрессия основывается на предположении о том, что изучаемая закономерность линейная (с неизвестными коэффициентами, которые восстанавливаются по выборке), а линейная бинарная классификация — что существует гиперплоскость, неплохо разделяющая классы. Метрические методы же локальны: они исходят из допущения, что свойства объекта можно узнать, имея представление о его соседях. Указанные выше свойства могут быть полезными, особенно в случае сложно устроенных данных, для которых мы не можем придумать глобальную модель. Однако с другой стороны, из-за lazy learning алгоритм становится абсолютно неприменимым при большом количестве данных. Несмотря на то, что эти алгоритмы очень просты для понимания, они довольно точны и хорошо интерпретируемы — и часто используются как минимум в качестве бейзлайнов в разных задачах. В первой части параграфа мы расскажем об одном из самых известных метрических алгоритмов — методе k-ближайших соседей (k-nearest neighbors, KNN). Этот подход в основном чисто инженерный из-за отсутствия фазы обучения — в настоящее время уже почти нигде не применяется. Однако многие техники, на которых основан алгоритм, используются и в других методах. Например, у алгоритмов поиска ближайших соседей, — неотъемлемой часть метода, — намного более широкая область применения. Плюс ко всему KNN — очень простой и легко интерпретируемый алгоритм, поэтому изучить его всё равно полезно. Мы обсудим подробнее его преимущества, недостатки, область его применения, а также возможные обобщения. Для метрических методов очень важно уметь эффективно находить ближайшие объекты, поэтому задача их поиска неизбежно возникает при применении любого такого алгоритма. Поэтому во второй части параграфа мы рассмотрим возможные подходы к быстрому поиску ближайших соседей. Метод k-ближайших соседей (KNN) Представим, что мы проводим классификацию объектов на два класса — красный или жёлтый. Нам дана некоторая обучающая выборка и целевой объект (серый): 2 Мы хотим определить, к какому классу относится серый объект. Интуитивно очевидно, что он должен быть жёлтым, потому что все его соседи жёлтые. Эта интуиция и отражает суть метода KNN — классифицировать целевой объект, исходя из того, какие классы у объектов, которые максимально похожи на него. Перейдём теперь к более формальному описанию алгоритма. Рассмотрим сначала задачу многоклассовой классификации, а регрессией займёмся позже. Пусть дана обучающая выборка X=(x i ,y i ) i=1 N , где ∈X, y i ∈Y= 1,…,C. Пусть также задана некоторая симметричная по своим аргументам функция расстояния ρ:X×X→[0,+∞). Предположим, что требуется классифицировать новый объект u u. Для этого найдём k k наиболее близких к u u в смысле расстояния ρ ρ объектов обучающей выборки (u)= x u (1) ,…,x u (k) (1) ∀x in ∈X k (u) ∀x out ∈X∖X k (u)ρ(u,x in )⩽ρ(u,x out ).(1) Метку класса объекта (i) будем обозначать (i) . Класс нового объекта тогда естественным образом определим как наиболее часто"
      ]
    },
    {
      "index": 28,
      "question": "Почему AUC-ROC не всегда подходит для многоклассовых задач без модификаций?",
      "ground_truth": "Потому что ROC определен только для бинарной классификации",
      "model_answer": "Отличный вопрос! Он затрагивает ключевое различие между бинарной и многоклассовой классификацией.\n\n**Короткий ответ:** AUC-ROC в своей стандартной форме — это метрика, изначально разработанная для **бинарной** классификации. Она оценивает способность модели разделять два класса. В многоклассовой задаче (N > 2 классов) нет единого, общепринятого способа напрямую вычислить \"один\" ROC-AUC, так как концепция \"истинно положительных\" и \"ложно положительных\" ставок становится неоднозначной.\n\nДавайте разберем подробнее, почему это так и какие есть модификации.\n\n### 1. Проблемы прямого применения стандартного AUC-ROC\n\n1.  **Отсутствие единого порога для всех классов.** В бинарном случае ROC-кривая строится, варьируя порог решения для одного класса (например, \"положительного\"). В многоклассовой задаче модель обычно выдает вероятности принадлежности к каждому из N классов. Какой порог и для какого класса мы будем менять? Нет единого скалярного выхода, который можно было бы пороговить.\n\n2.  **Многозначность понятий TP, FP, TN, FN.** Основа ROC-кривой — это вычисление True Positive Rate (TPR) и False Positive Rate (FPR) для разных порогов. В случае N классов:\n    *   **TP (Истинно положительные)** для класса i — это объекты, правильно отнесенные к классу i.\n    *   **FP (Ложно положительные)** для класса i — это объекты **всех других классов**, ошибочно отнесенные к классу i.\n    *   **TN (Истинно отрицательные)** для класса i — это объекты **всех других классов**, правильно не отнесенные к классу i (т.е. отнесенные к любому другому классу).\n    *   **FN (Ложно отрицательные)** для класса i — это объекты класса i, ошибочно отнесенные к **любому другому** классу.\n\n    Проблема в том, что количество TN растет квадратично с увеличением числа классов (O(N²)), что может делать метрику слишком оптимистичной и нечувствительной к ошибкам между конкретными классами.\n\n### 2. Основные стратегии модификации (адаптации) AUC-ROC для многоклассовых задач\n\nЧтобы обойти эти проблемы, используют следующие подходы:\n\n#### **A. \"One-vs-Rest\" (OvR) или \"One-vs-All\" (OvA)**\n*   **Идея:** Каждый класс по очереди рассматривается как \"положительный\", а все остальные классы объединяются в один \"отрицательный\" класс.\n*   **Расчет:** Для каждого из N классов строится своя бинарная ROC-кривая и вычисляется AUC-ROCᵢ.\n*   **Итоговая метрика:** Затем результаты агрегируются. Самые распространенные варианты:\n    *   **Macro-average AUC:** `AUC_macro = (1/N) * Σ AUC-ROCᵢ`. Усредняет метрики всех классов, давая равный вес каждому классу. Хорош для несбалансированных данных, так как маленькие классы учитываются наравне с большими.\n    *   **Weighted-average AUC:** `AUC_weighted = Σ (wᵢ * AUC-ROCᵢ)`, где `wᵢ` — доля объектов класса i в выборке. Учитывает дисбаланс классов.\n    *   **Micro-average AUC:** Более сложный метод. Объединяет все бинарные прогнозы (для всех классов в схеме OvR) в один глобальный набор и строит одну общую ROC-кривую. На практике используется реже, чем macro-average.\n\n#### **B. \"One-vs-One\" (OvO)**\n*   **Идея:** Строится ROC-кривая для каждой **пары** классов (C(N, 2) кривых). Оценивается, насколько хорошо модель отделяет класс i от класса j.\n*   **Расчет:** Для каждой пары (i, j) временно рассматривается только подвыборка из этих двух классов, строится бинарный AUC-ROCᵢⱼ.\n*   **Итоговая метрика:** Обычно также усредняется (macro) по всем парам классов. Этот метод может быть более точным, но требует построения O(N²) кривых и вычислительно дорог для большого числа классов.\n\n#### **C. Обобщенный (Multiclass) AUC-ROC (Hand & Till, 2001)**\n*   **Идея:** Прямое обобщение AUC без приведения к бинарным подзадачам. Интерпретируется как вероятность того, что случайно выбранный объект из класса i будет иметь более высокую оценку (вероятность) для своего класса i, чем случайно выбранный объект из класса j для класса i.\n*   **Расчет:** `M_AUC = (2 / (N*(N-1))) * Σ AUC(i, j)`, где сумма берется по всем парам i < j, а `AUC(i, j)` — это вероятность из определения выше (фактически, AUC для пары классов в OvO схеме).\n*   **Преимущество:** Теоретически более обоснованная метрика, специально разработанная для многоклассового случая. Реализована, например, в библиотеке `scikit-learn` как `roc_auc_score` с параметром `multi_class='ovo'` или `'ovr'`.\n\n### 3. Когда (и какая модификация) может быть полезна, а когда нет?\n\n*   **Полезна (Macro-average AUC):**\n    *   При **несбалансированных классах**, когда важно оценить качество предсказания для каждого класса, а не только для большинства.\n    *   Когда стоимость ошибки **одинакова для всех классов**.\n    *   Для сравнения моделей на одном и том же наборе данных.\n\n*   **Может быть менее информативной или вводить в заблуждение:**\n    *   Если классы **сильно пересекаются** по признакам, высокий AUC может быть недостижим, и сама метрика теряет смысл.\n    *   Когда важна **интерпретируемость конкретных ошибок** (какие классы путает модель). В этом случае лучше смотреть на **нормированную матрицу ошибок (confusion matrix)**.\n    *   Для задач с **очень большим числом классов** (например, 1000) вычисление OvO или даже OvR AUC становится громоздким, а итоговое усредненное число может быть сложно интерпретировать.\n\n### Вывод\n\n**AUC-ROC не подходит для многоклассовых задач \"как есть\"**, потому что он бинарный по своей природе. Однако с помощью **модификаций** — прежде всего, стратегий **OvR (macro-average)** и **OvO** — его можно успешно адаптировать. **Macro-average AUC-ROC** часто является отличным выбором для многоклассовой несбалансированной классификации, так как дает агрегированную оценку, устойчивую к дисбалансу. Но всегда важно понимать, как именно вычислена метрика, и дополнять ее анализом матрицы ошибок.",
      "contexts": []
    },
    {
      "index": 29,
      "question": "Что такое векторизация TF/IDF?",
      "ground_truth": "TF/IDF (Term Frequency/Inverse Document Frequency) – это метод векторизации текстовых данных, который используется для оценки важности слов в документе или коллекции документов. Он основывается на двух понятиях: частоте терма (TF) и обратной частоте документа (IDF).\r\nЧастота терма (TF) – это мера того, насколько часто определенное слово встречается в документе. Чем чаще слово встречается, тем больше его вес в документе.\r\nОбратная частота документа (IDF) – это мера того, насколько уникально слово является в коллекции документов. Слова, которые встречаются редко в коллекции, имеют более высокий IDF и, следовательно, более высокую важность.\r\nВекторизация TF/IDF преобразует текстовые документы в числовые векторы, где каждое слово представлено весом, основанным на его TF и IDF. Это позволяет использовать текстовые данные в алгоритмах машинного обучения, которые требуют числовых входных данных.",
      "model_answer": "На основе предоставленного контекста можно дать следующее объяснение:\n\n**TF-IDF (Term Frequency-Inverse Document Frequency)** — это статистический подход к векторизации текстов, который следует парадигме «мешка слов» (Bag of Words). В этом подходе весь текст рассматривается как неупорядоченный набор токенов (обычно слов), и ему сопоставляется один вектор.\n\n**Ключевые особенности, упомянутые в контексте:**\n1.  **Векторизация целиком:** TF-IDF — это пример метода, который «векторизует текст целиком, превращая его в один вектор».\n2.  **«Мешок токенов»:** Метод рассматривает текст как неупорядоченный набор («мешок») токенов. Это означает, что теряется информация о порядке слов (предложения «Я не люблю ML» и «Я люблю не ML» получат одинаковые векторизации).\n3.  **Один из базовых подходов:** Векторизация TF-IDF упоминается как один из простых подходов наряду с `word2vec`, которые можно использовать перед применением более сложных архитектур нейронных сетей.\n4.  **Контекст применения:** Такие методы, как TF-IDF, исторически использовались в задачах, подобных `bag of visual words` для изображений, где фрагменты изображений кластеризуются (например, с помощью K-means), а затем изображение описывается гистограммой встречаемости этих кластеров-«слов».\n\nТаким образом, TF-IDF — это классический метод представления текста в виде числового вектора на основе частоты терминов в документе и их редкости во всей коллекции документов, но без учёта порядка слов и их семантических связей.",
      "contexts": [
        "меньшие. Обычно размер выходного слоя выбирают, балансируя между качеством и ресурсами, необходимыми на расчёт и хранение выхода сети. Этот подход был назван Deep Structured Semantic Models и описан в статье от Microsoft. Идею можно применять в целом в любой задаче ранжирования для своих типов «документов». Посмотреть, как она была воплощена в Web поиске для поиска по смыслу, можно в блоге Яндекса. Если вкратце, у модели следующие особенности: На входе у модели не все тексты, а только заголовок документа и запрос; Для уменьшения размера входа текст разбит на буквенные триграммы, вектор на входе - это Bag Of Trigrams; Архитектура обработки запроса и документа разная; Особый способ генерации негативных примеров. Схематически архитектура модели показана на рисунке ниже: Artboard Конечно, чтобы заставить простую архитектуру давать хорошее качество, нужно экспериментировать с методами сбора данных и улучшения качества, которые описаны в других главах учебника. Однако при наличии соответствующих мощностей можно улучшать качество, изменяя архитектуру обработки текста. В частности, модели на основе трансформеров (например, BERT) улучшают качество. Это же касается и косинуса, то есть соединительной части. Вполне можно вместо него использовать полносвязную сеть или даже трансформерную архитектуру. Трансформеры, которые по-отдельности обрабатывают сущности запроса и документа, в Яндексе названы split-моделями и более подробно описаны в том же блоге на Хабре. Метафичи В предыдущем пункте мы уже ввели фактор для модели, который сам является значением модели. Мы улучшили качество с помощью стекинга DSSM и итоговой модели. Аналогичным образом можно использовать предсказания моделей, обученных на разные таргеты и разными способами: их можно добавить к другим фичам для итоговой модели. К сожалению, если факторов-моделей (метафичей) много, такая модель не будет удовлетворять требованиям по времени работы. В этом случае можно прибегнуть к дистилляции знаний большой модели в более компактную. Фичи, зависящие от времени Известно, что модель машинного обучения работает хорошо (а точнее, ожидаемо) только в случае, когда при её применении распределения данных и факторов похожи на те, которые использовались при обучении. Но в продакшн-системах постоянное выполнение этого свойства невозможно обеспечить. Поэтому главный совет: настраивайте мониторинги качества ваших ML-систем для того, чтобы не пропускать моменты поломки. Качество может снизиться как из-за изменений в логике других сервисов, на которые вы полагаетесь при вычислении факторов, так и из-за появления новых трендов. Например, это происходит при появлении новых тем, о которых раньше не было запросов. Показательный случай — пандемия вируса COVID-19, который стал резко появляться среди запросов пользователей. Но бывают факторы, которые зависят от времени сами по себе. Так, для ранжирования новых документов может быть полезно знать возраст документа. Со временем распределение этого фактора сдвигается вправо, поскольку многие старые документы не удаляются из базы. Получается, фактор старого документа меняется, а релевантность нет. Появление фичей вне ожидаемых значений может привести к непредсказуемому поведению модели. Так что их нужно применять с осторожностью, лучше в тех моделях, которые можно быстро обучить и обновить в продакшне. Ещё лучшим решением будет преобразовать или отнормировать фичи таким образом, чтобы их распределение не менялось так кардинально. Наш фактор с возрастом документа можно преобразовать в индикатор того, что возраст документа меньше одного дня. Тогда только один раз за историю документа этот фактор будет",
        "В этом разделе вы познакомитесь с нейросетями для работы с данными, имеющими вид последовательностей некоторых токенов. Это может быть музыка или видео, временные ряды или траектория движения робота, последовательности аминокислот в белке или много чего ещё, но одним из самых богатых источников таких данных является Natural Language Processing (NLP). Как следует из названия, Natural Language Processing (обработка естественного языка) — это область data science, посвященная анализу текстов, написанных на естественных (человеческих) языках. С задачами обработки текста мы встречаемся каждый день, например, когда просим Siri или Алису включить любимую песню или добавить напоминание в календарь, когда используем автодополнение при вводе поискового запроса или проверяем орфографию и пунктуацию с помощью специальных программ. Вот ещё несколько примеров задач, относящихся к обработке естественного языка: классификация документов (по темам, рубрикам, жанрам и так далее); определение спама; определение частей речи; исправление орфографических ошибок и опечаток; поиск ключевых слов, синонимов / антонимов в тексте; распознавание именованных сущностей (имен, названий географических объектов, дат, номеров телефонов, адресов); определение эмоциональной окраски текста (sentiment analysis); поиск релевантных документов по запросу, а также их ранжирование; задача суммаризации (автоматическое составление краткого пересказа текста); автоматический перевод с одного языка на другой (машинный перевод); диалоговые системы и чат-боты; вопросно-ответные системы (выбор ответа из нескольких предложенных вариантов или вопросы с открытым ответом); кроме того, к NLP также относят задачу распознавания речи (Automated Speech Recognition, ASR). Для работы с такими данными есть несколько возможных режимов: Many-to-one. На вход подается последовательность объектов, на выходе один объект. Пример 2: классификация текстов или видео. Пример 2: тематическая классификация. По предложению нефиксированной длины генерируем вектор вероятностей упоминания заранее фиксированных тем во входном предложении. Размерность выходного вектора постоянна и равна количеству тем. One-to-many. На вход подается один объект, на выходе последовательность объектов. Пример: генерация заголовка к изображению (image captioning). Many-to-many. На входе и выходе последовательности нефиксированной длины. Примеры: машинный перевод, суммаризация текста, генерация заголовка к статье. Синхронизированный вариант many-to-many. На входе и выходе последовательности одинаковой длины, токены входной явно сопоставлены соответствующим токенам выходной. Пример: генерация покадровых субтитров к видео, PoS-tagging (part of speech tagging, для каждого слова в предложении предсказываем, что это за часть речи). sec Мы начнём с архитектур, в которых размер выхода предсказуемым образом зависит от размера входа: many-to-one и синхронизованном варианте many-to-many — но в итоге доберёмся и до остальных. Word Embeddings Перед тем, как рассказать об архитектурах, которые часто используются для работы с текстами, надо разобраться, каким образом можно кодировать текстовые данные: ведь нужно их превратить во что-то векторное, прежде чем подавать на вход нейросети. К векторизации текстов есть два базовых подхода: векторизовать текст целиком, превращая его в один вектор; векторизовать отдельные структурные единицы, превращая текст в последовательность векторов. Первые, статистические подходы к векторизации следовали первому подходу и рассматривали текст как неупорядоченный набор («мешок») токенов (обычно токенами являются слова). Тем самым, тексты «Я не люблю ML» и «Я люблю не ML» получали одинаковые векторизации, то есть по ходу терялась существенная информация. Поэтому мы лишь коротко упомянем о них. Обратимся теперь к другому подходу и подумаем, как сопоставить векторы (эмбеддинги) словам. Допустим, что у нас одно и то же",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,",
        "и value векторов для каждого токена, настакаем эмбеддинги входных токенов в матрицу X X и посчитаем матрицы Q=W Q ∗X, K=W K ∗X и V=W V ∗X. Затем происходит повторение описанных в предыдущем абзаце шагов, только для матриц. Посчитаем итоговую матрицу Z Z, подав матрицы Q, K и V в формулу: norm const ) V ˙ Z=softmax( norm const В оригинальной статье Vaswani et al., 2017 в качестве нормализующей константы выбрали число 8 (квадратный корень размерности key-векторов). Нормализация приводила к более стабильным градиентам в процессе обучения. Интересно, что обычно используют параллельно несколько self-attention блоков. Такая схема называется multi-head self-attention. Вычисление self-attention происходит несколько раз с разными матрицами весов, затем полученные матрицы конкатенируются и умножаются на еще одну матрицу весов W O W O (см. схему). Это позволяет разным self-attention головам фокусироваться на разных взаимосвязях, например, одна голова может отвечать за признаковые описания, другая за действия, третья за отношения «объект-субъект». Разные головы могут вычисляться параллельно, при этом входная матрица эмбеддингов отображается в разные подпространства представлений, что значительно обогащает возможности внутреннего внимания моделировать взаимосвязи между словами. В виде формулы вычисление multihead self-attention можно представить так: MultiHead(Q,K,V)=Concat(head 1 ,head 2 ,...,head где norm const ) V ˙ head i (Q,K,V)=softmax( norm const Схема вычисления multi-head self-attention. Источник Есть много реализаций self-attention (PyTorch, TensorFlow). Также советуем ознакомиться с jupyter-ноутбуком от Гарвардской NLP-группы, в котором представлена реализация архитектуры «трансформер» с подробными объяснениями. Еще один отличный источник, позволяющий подробнее разобраться с self-attention и трансформером, - это статья Jay Alammar под названием «Illustrated Transformer». Особенности работы с текстами Предобработка текстов Перед тем, как применять описанные выше архитектуры (или даже использовать простые подходы, вроде TF-IDF или word2vec), нужно разобраться, как делать предобработку текстов. Первым делом надо научиться представлять связный текст в виде последовательности. Для начала имеет смысл разбить текст на предложения, а дальше уже на слова или символьные n-граммы. Этот процесс называется токенизацией. Можно делать токенизацию вручную, например, с помощью регулярных выражений, или воспользоваться готовыми методами из библиотеки NLTK. Представим, что мы получили упорядоченный список слов, из которых состоит текст. Но это еще не все. Обычно тексты содержат разные грамматические формы одного и того же слова. Привести все словоформы к начальной форме можно с помощью лемматизации. Лемматизация - это алгоритм приведения слова к его начальной форме с использованием морфологическего анализа и знаний об особенностях конкретного языка. Пример работы лемматизатора: «собаки, собака, с собакой, собаками -> собака» Другой способ приведения всех словоформ к одной форме - это стемминг. Стемминг — это более грубый процесс на основе эвристик, который действует без знания контекста, словарей и морфологии. Стеммер не поймет, что слова с чередованием имеют один и тот же корень (только если прописать в явном виде такую эвристику) или что слова «есть», «буду» и «был» - это формы глагола «быть». Стемминг - менее аккуратный процесс по сравнению с лемматизацией, зато гораздо более быстрый. Еще один важный этап предобработки текстов - это удаление стоп-слов. Стоп-словами называют междометия, союзы, предлоги, артикли, в общем все слова, которые будут вносить шум в работу алгоритма машинного обучения. Иногда дополнительно убирают слова общей лексики, оставляя только специфические",
        "двух шагов, обоснованность применения различных метрик (расстояний между точками, а не метрик качества 😃 или функций близости связана с тем, «ломают» они какой-либо из этих шагов или нет. Первый шаг с отнесением объектов к ближайшим центрам не зависит от вида метрики. Второй шаг предполагает пересчёт центров как среднего арифметического входящих в кластер точек, и вот здесь будет подвох: к оптимальности выбора центров в среднем арифметическом приводит именно евклидова метрика (подробнее в разделе «Что оптимизирует K-means»). Однако на практике никто не мешает использовать метод и без должного обоснования, поэтому можно экспериментировать с любыми расстояниями, с той лишь оговоркой, что не будет никаких теоретических гарантий, что метод сработает. Наиболее распространённая альтернатива евклидовой метрике — это косинусная мера близости векторов (она особенно популярна в задачах анализа текстов): CosineSimilarity(μ ⋅∥x При её использовании стоит не забывать, что косинусная мера — это функция близости, а не расстояние, так что чем больше её значения, тем ближе друг к другу векторы. Mini-batch K-means Несложно заметить, что, если считать K K и размерность пространства признаков константами, оба шага алгоритма работают за O ( n ) O(n), где n — количество объектов обучающей выборки. Отсюда возникает идея ускорения работы алгоритма. В mini-batch K-means мы не считаем шаги сразу на всей выборке, а на каждой итерации выбираем случайную подвыборку (мини-батч) и работаем на ней. В случае когда исходная выборка очень велика, переход к пакетной обработке не приводит к большой потере качества, зато значительно ускоряет работу алгоритма. Понижение размерности С другой стороны, вычисление расстояний и средних делается за O ( d ) O(d), где d d — размерность пространства признаков, так что другая идея ускорения K-means — это предварительно понизить размерность пространства признаков (с помощью PCA или эмбеддингов). Особенно удачно эта идея работает в задачах кластеризации текстов, когда K-means применяют на эмбеддингах слов: получается выиграть не только в скорости работы, но и в интерпретируемости результатов кластеризации. Кстати, сам алгоритм кластеризации тоже можно использовать как метод понижения размерности. Если вы решаете задачу обучения с учителем и пространство признаков очень разнообразно (то есть обучающая выборка не даёт вам достаточно статистики при столь большом числе признаков), можно выполнить кластеризацию объектов выборки на 500 или 1000 кластеров и оперировать попаданием объектов в какой-то кластер как признаком. Такой подход называется квантизацией пространства признаков (feature space quantization) и часто помогает на практике, когда нужно огрубить признаки, добавить им интерпретируемости или же, наоборот, обезличить. Хрестоматийный пример такого использования кластеризации — метод bag of visual words, расширяющий bag of words из анализа текстов на работу с изображениями. Идея метода в том, чтобы строить признаковое описание изображений на основе входящих в него фрагментов: так, изображения с лицами будут содержать фрагменты с носом, глазами, ртом, а изображения с машинами — колёса, зеркала, двери. Но проблема здесь в том, что нарезать такие фрагменты из обучающей выборки и искать точные совпадения в новых примерах изображений, которые нужно классифицировать, — безнадёжная затея. В жизни фрагменты изображений не повторяются в других изображениях с попиксельной точностью. Решение этой проблемы оказалось возможным при помощи алгоритмов кластеризации (исторически использовался именно K-means): фрагменты изображений из обучающей выборки кластеризовали на"
      ]
    },
    {
      "index": 30,
      "question": "Вам дали набор данных твитов, задача – предсказать их тональность (положительная или отрицательная). Как бы вы проводили предобработку?",
      "ground_truth": "Поскольку твиты наполнены хэштегами, которые могут представлять важную информацию, и, возможно, создать набор признаков, закодированных унитарным кодом (one-hot encoding), в котором ‘1’ будет означать наличие хэштега, а ‘0’ – его отсутствие. То же самое можно сделать с символами ‘@’ (может быть важно, какому аккаунту адресован твит). В твитах особенно часто встречаются сокращения (поскольку есть лимит количества символов), так что в текстах наверняка будет много намеренно неправильно записанных слов, которые придется восстанавливать. Возможно, само количество неправильно написанных слов также представляет полезную информацию: разозленные люди обычно пишут больше неправильных слов.\r\n\r\nУдаление пунктуации, хоть оно и является стандартным для NLP, в данном случае можно пропустить, поскольку восклицательные знаки, вопросы, точки и пр. могут нести важную информацию, в сочетании с текстом, в котором они применяются. Можно создать три или большее количество столбцов, в которых будет указано количество восклицательных знаков, вопросительных знаков и точек. Однако перед передачей данных в модель пунктуацию следует убрать из текста.\r\n\r\nЗатем нужно провести лемматизацию и токенизацию текста. В модель следует передать не только чистый текст, но и информацию о хэштегах, ‘@’, неправильно написанных словах и пунктуации. Все это, вероятно, повысит точность предсказаний.",
      "model_answer": "На основе предоставленного контекста, вот как можно подойти к предобработке набора данных твитов для задачи классификации тональности:\n\n1.  **Токенизация:** Первым шагом необходимо разбить текст на отдельные единицы (токены). Как указано в контексте, \"связный текст\" нужно представить \"в виде последовательности\". Для твитов это означает разбиение на слова или символьные n-граммы. Можно использовать готовые методы из библиотек, например, NLTK.\n\n2.  **Приведение к нормальной форме:** Чтобы уменьшить размерность признакового пространства и объединить разные формы одного слова, следует привести слова к начальной форме. Контекст предлагает два основных подхода:\n    *   **Лемматизация:** Более точный метод, использующий морфологический анализ (например, \"собаки\", \"собакой\" -> \"собака\"). Рекомендуется для задач, где важна точность.\n    *   **Стемминг:** Более быстрый, но грубый метод на основе эвристик (например, \"running\", \"ran\" -> \"run\"). Может быть полезен, если скорость обработки критична.\n\n3.  **Удаление стоп-слов:** Как отмечено в контексте, важно убрать слова, которые не несут смысловой нагрузки для задачи (междометия, союзы, предлоги и т.д.), так как они \"будут вносить шум в работу алгоритма\". Для твитов этот шаг особенно важен, так как они часто содержат служебные слова и междометия.\n\n4.  **Векторизация текста (создание признаков):** После предобработки текст нужно превратить в векторное представление, которое сможет воспринять модель машинного обучения. Контекст упоминает два подхода:\n    *   **Векторизация отдельных единиц (слов):** Превращение текста в последовательность векторов (например, с помощью word2vec или эмбеддингов, как в разделе про NLP).\n    *   **Векторизация текста целиком:** Рассмотрение текста как \"неупорядоченного набора («мешка») токенов\" (например, TF-IDF). Однако контекст отмечает, что этот подход теряет информацию о порядке слов, что может быть критично для понимания тональности.\n\n**Дополнительные рекомендации (с учетом специфики твитов):**\n*   Очистка от специальных символов, упоминаний пользователей (@username), хештегов (можно оставить как отдельный признак или удалить символ #) и URL-ссылок.\n*   Обработка смайликов и эмодзи, которые часто несут сильную эмоциональную окраску. Их можно либо удалить, либо заменить на текстовые метки (например, `:)` -> `SMILEY_POS`).\n*   Исправление частых опечаток и сокращений, характерных для социальных сетей.\n\n**Архитектура модели:**\nУчитывая, что задача является **бинарной классификацией** (положительная/отрицательная), и данные представляют собой последовательности, можно использовать архитектуры, описанные в контексте для работы с текстами, например:\n*   **Many-to-one:** На вход подается последовательность слов (токенов) твита, на выходе — один объект (вероятность положительной тональности). Это подходит для рекуррентных (RNN) или трансформерных архитектур.\n*   Также можно использовать более простые модели (например, линейную регрессию или решающие деревья), если применить к предобработанному тексту методы векторизации вроде TF-IDF, но тогда будет потеряна информация о последовательности слов.\n\nТаким образом, пайплайн предобработки будет включать: токенизацию, очистку, приведение слов к нормальной форме (лемматизация/стемминг), удаление стоп-слов и последующую векторизацию для подачи в модель классификации.",
      "contexts": [
        "вызвана тем, что люди обычно больше потребляют электричество днем, чем ночью. Недельная сезонность вызвана более высоким потреблением электричества по будням. Если бы мы посмотрели данные за несколько лет, то увидели бы еще одну сезонность – годовую, например, вызванную тем, что в теплое время года работает больше кондиционеров. ex Почему бы нам не построить прогноз простыми методами, например, линейной регрессией по времени? Общий тренд так можно уловить. Но в остатках (то есть в разности между истинными значениями и прогнозом) этой модели будет достаточно много информации, которую хотелось бы как-то учесть. ex Можно также добавить квадрат значения времени. Тогда можно уловить квадратичный тренд, но не более. ex Прогнозирование с помощью сведения к задаче регрессии Давайте для начала поймем, что мы вообще хотим сделать. Посмотрим на этот график, на котором показаны продажи одного из товаров в магазине за разные года. ts Мы знаем значения ряда (зеленые) до момента времени t t, в данном случае за 4 года с 2013 по 2016 включительно. Предположим также, что в данный момент мы отмечаем Новый год 2017. В этот момент мы хотели бы предсказать (синее) будущие значения ряда (оранжевое) за весь 2017 год на основе четырехлетней истории продаж. Основная идея – подадим известные (зеленые) значения ряда в какую-то регрессионную функцию, получив тем самым предсказания. При этом можем брать не все известные значения ряда, а только p p последних значений. Иначе говоря, модель имеет вид =f(y t−1 ,…,y t−p ), где f f – произвольная функция. Ее можно построить некоторым известным методом машинного обучения, например, линейной регрессией, решающими деревьями, бустингами, нейронными сетями (как сверточными, так и рекуррентными). Разберёмся, какие признаки мы подадим на вход регрессии. Признаки Общий принцип На практике при генерации идей о том, какие признаки можно создавать для построения модели, рекомендуется строить следующий график. На нем нужно отметить момент времени t t и мысленно поставить себя в этот момент времени. Затем нужно подумать, какие данные нам при этом доступны. В модель можно брать любые признаки, которые доступны к моменту времени t t. Если все данные поступают сразу, то можно брать все признаки, которые зависят только от значений до момента времени t t. В реальности часть данных может поступать с задержкой. Например, если данные загружаются в базу данных раз в сутки в полночь, то в полдень нам не доступны данные за последние 12 часов. 1 Также нужно помнить о том, на сколько времени вперед нужно сделать прогноз. Например, пусть у нас задача состоит в том, чтобы построить прогнозы продаж в магазине с целью планирования новых поставок. После того, как на основе прогноза мы примем решение о составе товаров в новой поставке, необходимо сначала собрать данные товары на складе, потом отправить машину в магазин, и затем еще разложить товар на полки в магазине. На эту процедуру может уходить от нескольких часов до нескольких дней. Тем самым еще до момента начала формирования новой поставки модель прогнозирования продаж должна построить прогноз спроса на товар к тому моменту, когда его выложат на полки. Даты Посмотрим на то, какие признаки можно извлечь Пусть дана какая-то дата: 13.04.2021 09:00. Отсюда можно получить следующие",
        "В этом разделе вы познакомитесь с нейросетями для работы с данными, имеющими вид последовательностей некоторых токенов. Это может быть музыка или видео, временные ряды или траектория движения робота, последовательности аминокислот в белке или много чего ещё, но одним из самых богатых источников таких данных является Natural Language Processing (NLP). Как следует из названия, Natural Language Processing (обработка естественного языка) — это область data science, посвященная анализу текстов, написанных на естественных (человеческих) языках. С задачами обработки текста мы встречаемся каждый день, например, когда просим Siri или Алису включить любимую песню или добавить напоминание в календарь, когда используем автодополнение при вводе поискового запроса или проверяем орфографию и пунктуацию с помощью специальных программ. Вот ещё несколько примеров задач, относящихся к обработке естественного языка: классификация документов (по темам, рубрикам, жанрам и так далее); определение спама; определение частей речи; исправление орфографических ошибок и опечаток; поиск ключевых слов, синонимов / антонимов в тексте; распознавание именованных сущностей (имен, названий географических объектов, дат, номеров телефонов, адресов); определение эмоциональной окраски текста (sentiment analysis); поиск релевантных документов по запросу, а также их ранжирование; задача суммаризации (автоматическое составление краткого пересказа текста); автоматический перевод с одного языка на другой (машинный перевод); диалоговые системы и чат-боты; вопросно-ответные системы (выбор ответа из нескольких предложенных вариантов или вопросы с открытым ответом); кроме того, к NLP также относят задачу распознавания речи (Automated Speech Recognition, ASR). Для работы с такими данными есть несколько возможных режимов: Many-to-one. На вход подается последовательность объектов, на выходе один объект. Пример 2: классификация текстов или видео. Пример 2: тематическая классификация. По предложению нефиксированной длины генерируем вектор вероятностей упоминания заранее фиксированных тем во входном предложении. Размерность выходного вектора постоянна и равна количеству тем. One-to-many. На вход подается один объект, на выходе последовательность объектов. Пример: генерация заголовка к изображению (image captioning). Many-to-many. На входе и выходе последовательности нефиксированной длины. Примеры: машинный перевод, суммаризация текста, генерация заголовка к статье. Синхронизированный вариант many-to-many. На входе и выходе последовательности одинаковой длины, токены входной явно сопоставлены соответствующим токенам выходной. Пример: генерация покадровых субтитров к видео, PoS-tagging (part of speech tagging, для каждого слова в предложении предсказываем, что это за часть речи). sec Мы начнём с архитектур, в которых размер выхода предсказуемым образом зависит от размера входа: many-to-one и синхронизованном варианте many-to-many — но в итоге доберёмся и до остальных. Word Embeddings Перед тем, как рассказать об архитектурах, которые часто используются для работы с текстами, надо разобраться, каким образом можно кодировать текстовые данные: ведь нужно их превратить во что-то векторное, прежде чем подавать на вход нейросети. К векторизации текстов есть два базовых подхода: векторизовать текст целиком, превращая его в один вектор; векторизовать отдельные структурные единицы, превращая текст в последовательность векторов. Первые, статистические подходы к векторизации следовали первому подходу и рассматривали текст как неупорядоченный набор («мешок») токенов (обычно токенами являются слова). Тем самым, тексты «Я не люблю ML» и «Я люблю не ML» получали одинаковые векторизации, то есть по ходу терялась существенная информация. Поэтому мы лишь коротко упомянем о них. Обратимся теперь к другому подходу и подумаем, как сопоставить векторы (эмбеддинги) словам. Допустим, что у нас одно и то же",
        "какую-либо категорию пользователей. Например, если двум людям с одинаковой и достаточно длинной историей просмотров онлайн-кинотеатр рекомендует разные фильмы только из-за того, что у них разный пол, то это не здорово. Данные Машинное обучение начинается с данных. Важно, чтобы их было достаточно много и чтобы они были достаточно качественными. Некоторые проекты приходится откладывать на неопределённый срок из-за того, что просто невозможно собрать данные. Чем сложнее задача, тем больше данных нужно, чтобы её решить. Например, существенные успехи в задачах распознавания изображений были достигнуты лишь с появлением очень больших датасетов (и, стоит добавить, вычислительных мощностей). Вычислительные ресурсы продолжают совершенствовать, но во многих ситуациях размеченных данных (то есть объектов, которым кто-то сопоставил ответ) было бы по-прежнему слишком мало: например, для решения задачи аннотирования изображений (image captioning) потребовалось бы огромное количество пар (изображение, описание). В некоторых случаях можно воспользоваться открытыми датасетами. Сейчас их доступно довольно много и некоторые весьма велики, но чаще всего они создаются для довольно простых задач, например, для задачи классификации изображений. Иногда датасет можно купить. Но для каких-то задач вы нигде не найдёте данных. Скажем, авторам неизвестно больших и качественных корпусов телефонных разговоров с расшифровками – в том числе и по причинам конфиденциальности таких данных. Бороться с проблемой нехватки данных можно двумя способами. Первый – использование краудсорсинга, то есть привлечение людей, готовых разметить много данных. Во многих ситуациях (например, когда речь заходит об оценке поисковой выдачи) без дополнительной разметки никак не обойтись. Мы расскажем про краудсорсинг подробнее в соответствующем параграфе. Некоторые проекты, в первую очередь научные и социальные, используют также citizen science – разметку данных волонтёрами без какого-либо вознаграждения, просто за чувство причастности к доброму делу исследования животных Африки или формы галактик. Второй же способ состоит в использовании неразмеченных данных. К примеру, в задаче аннотирования изображений у нас есть огромное количество никак не связанных друг с другом изображений и текстов. Однако, мы можем использовать их для того, чтобы помочь компьютеру понять, какие слова в принципе могут стоять рядом в предложении. Подходы, связанные с использованием неразмеченных данных для решения задач обучения с учителем, объединяются термином self-supervised learning и очень активно используются сейчас. Важной составляющей является обучение представлений (representation learning) — задача построения компактных векторов небольшой размерности из сложных по структуре данных, например, изображений, звука, текстов, графов, так, чтобы близкие по структуре или семантике данные получали метрически близкие представления. Делать это можно разными способами — например, используя фрагменты моделей, обученных для решения какой-либо другой задачи, или строя модель, предсказывающую скрытую часть объекта по оставшейся его части — например, пропущенное слово в предложении. Этому будет посвящен отдельный параграф нашего учебника. Но кроме количества данных важно ещё и то, насколько они хороши и удобны для анализа. Давайте разберёмся, что это значит и какие с этим бывают проблемы. Для работы с объектом модель должна опираться на какие-то его свойства, например, доход человека, цвет левого верхнего пикселя на изображении или частоту встречаемости слова «интеграл» в тексте. Эти свойства обычно называются признаками, а совокупность свойств, которые мы выделили у объекта – его признаковым описанием. Вот несколько простых и распространённых разновидностей признаков: Численные – например, рост или доход. Иногда отдельно",
        "Что такое машинное обучение и каким оно бывает. Основные понятия машинного обучения: признаки, таргеты, метрики, переобучение Машинное обучение — это наука, изучающая алгоритмы, автоматически улучшающиеся благодаря опыту. Когда Алан Тьюринг работал над первыми (компьютерами), он пытался расшифровать сообщения немецких военных, закодированные машиной Энигма. Поиск расшифровки требовал перебора массы вариантов. Люди с этой задачей справлялись плохо, зато машина могла решить её сравнительно быстро. Очевидно, далеко не для каждой задачи, с которой люди справляются с трудом, можно написать программу для эффективного поиска решения. Более того, есть целый класс задач (так называемые NP-трудные задачи), которые нельзя решить за разумное время. Можно даже явно доказать, что никакой компьютер здесь чуда тоже не совершит. Самое интересное это то, что бывают и задачи, которые для людей особенного труда не составляют, но которые почему-то крайне трудно запрограммировать, например: перевести текст с одного языка на другой; диагностировать болезнь по симптомам; сравнить, какой из двух документов в интернете лучше подходит под данный поисковый запрос; сказать, что изображено на картинке; оценить, по какой цене удастся продать квартиру. У всех этих задач есть много общего. Во-первых, их решение можно записать как функцию, которая отображает объекты или примеры (samples) в предсказания (targets). Например, больных надо отобразить в диагнозы, а документы в оценку релевантности. Во-вторых, вряд ли у этих задач есть единственно верное, идеальное решение. Даже профессиональные переводчики могут по-разному перевести один и тот же текст, и оба перевода будут верными. Так что лучшее в этих задачах — враг хорошего. В конце концов, и доктора иногда делают ошибки в диагнозах, и вы не всегда можете сказать, что же именно изображено на картинке. В-третьих, у нас есть много примеров правильных ответов (скажем, переводов предложения на другой язык или подписей к заданной картинке), а примеры неправильных ответов (если они нужны), как правило, не составляет труда сконструировать. Мы назовём функцию, отображающую объекты в предсказания, — моделью, а имеющийся у нас набор примеров — обучающей выборкой или датасетом. Обучающая выборка состоит из: объектов (к примеру, скачанные из интернета картинки, истории больных, активность пользователей сервиса и так далее); и ответов (подписи к картинкам, диагнозы, информация об уходе пользователей с сервиса), которые мы также будем иногда называть таргетами. Постановка задачи Описанные выше задачи являются примерами задач обучения с учителем (supervised learning), так как правильные ответы для каждого объекта обучающей выборки заранее известны. Задачи обучения с учителем делятся на следующие виды в зависимости от того, каким может быть множество Y Y всех возможных ответов (таргетов): Y = R Y=R или Y = R M Y=R M — регрессия. Примерами задач регрессии является предсказание продолжительности поездки на каршеринге, спрос на конкретный товар в конкретный день или погода в вашем городе на завтра (температура, влажность и давление — это несколько вещественных чисел, которые формируют вектор нашего предсказания). Y = 0 , 1 Y=0,1 — бинарная классификация. Например, мы можем предсказывать, кликнет ли пользователь по рекламному объявлению, вернёт ли клиент кредит в установленный срок, сдаст ли студент сессию, случится ли определённое заболевание у пациента, есть ли на картинке банан. Y=1,…,K — многоклассовая (multiclass) классификация. Например, определение предметной области для научной статьи (математика, биология,",
        "и value векторов для каждого токена, настакаем эмбеддинги входных токенов в матрицу X X и посчитаем матрицы Q=W Q ∗X, K=W K ∗X и V=W V ∗X. Затем происходит повторение описанных в предыдущем абзаце шагов, только для матриц. Посчитаем итоговую матрицу Z Z, подав матрицы Q, K и V в формулу: norm const ) V ˙ Z=softmax( norm const В оригинальной статье Vaswani et al., 2017 в качестве нормализующей константы выбрали число 8 (квадратный корень размерности key-векторов). Нормализация приводила к более стабильным градиентам в процессе обучения. Интересно, что обычно используют параллельно несколько self-attention блоков. Такая схема называется multi-head self-attention. Вычисление self-attention происходит несколько раз с разными матрицами весов, затем полученные матрицы конкатенируются и умножаются на еще одну матрицу весов W O W O (см. схему). Это позволяет разным self-attention головам фокусироваться на разных взаимосвязях, например, одна голова может отвечать за признаковые описания, другая за действия, третья за отношения «объект-субъект». Разные головы могут вычисляться параллельно, при этом входная матрица эмбеддингов отображается в разные подпространства представлений, что значительно обогащает возможности внутреннего внимания моделировать взаимосвязи между словами. В виде формулы вычисление multihead self-attention можно представить так: MultiHead(Q,K,V)=Concat(head 1 ,head 2 ,...,head где norm const ) V ˙ head i (Q,K,V)=softmax( norm const Схема вычисления multi-head self-attention. Источник Есть много реализаций self-attention (PyTorch, TensorFlow). Также советуем ознакомиться с jupyter-ноутбуком от Гарвардской NLP-группы, в котором представлена реализация архитектуры «трансформер» с подробными объяснениями. Еще один отличный источник, позволяющий подробнее разобраться с self-attention и трансформером, - это статья Jay Alammar под названием «Illustrated Transformer». Особенности работы с текстами Предобработка текстов Перед тем, как применять описанные выше архитектуры (или даже использовать простые подходы, вроде TF-IDF или word2vec), нужно разобраться, как делать предобработку текстов. Первым делом надо научиться представлять связный текст в виде последовательности. Для начала имеет смысл разбить текст на предложения, а дальше уже на слова или символьные n-граммы. Этот процесс называется токенизацией. Можно делать токенизацию вручную, например, с помощью регулярных выражений, или воспользоваться готовыми методами из библиотеки NLTK. Представим, что мы получили упорядоченный список слов, из которых состоит текст. Но это еще не все. Обычно тексты содержат разные грамматические формы одного и того же слова. Привести все словоформы к начальной форме можно с помощью лемматизации. Лемматизация - это алгоритм приведения слова к его начальной форме с использованием морфологическего анализа и знаний об особенностях конкретного языка. Пример работы лемматизатора: «собаки, собака, с собакой, собаками -> собака» Другой способ приведения всех словоформ к одной форме - это стемминг. Стемминг — это более грубый процесс на основе эвристик, который действует без знания контекста, словарей и морфологии. Стеммер не поймет, что слова с чередованием имеют один и тот же корень (только если прописать в явном виде такую эвристику) или что слова «есть», «буду» и «был» - это формы глагола «быть». Стемминг - менее аккуратный процесс по сравнению с лемматизацией, зато гораздо более быстрый. Еще один важный этап предобработки текстов - это удаление стоп-слов. Стоп-словами называют междометия, союзы, предлоги, артикли, в общем все слова, которые будут вносить шум в работу алгоритма машинного обучения. Иногда дополнительно убирают слова общей лексики, оставляя только специфические"
      ]
    }
  ]
}
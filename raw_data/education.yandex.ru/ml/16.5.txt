---
title: Независимость и условные распределения вероятностей
url: https://education.yandex.ru/handbook/ml/article/nezavisimost-i-uslovnye-raspredeleniya-veroyatnostej
course: ml
chapter: 16. Теормин
chapter_id: 16.5
---
В этом параграфе описываются, пожалуй, главные фичи теории вероятностей: независимые события и условные вероятности. Эти концепции имеют большое прикладное значение, да и с теоретической точки зрения главным образом благодаря им теория вероятностей выделяется в отдельную ветвь математики.
Условная вероятность
Условная вероятность возникает при ответе на вопрос о том, каковы шансы события
A
A при условии,что случилось событие
B
B, и обозначается
P(A∣B).
Пример. Согласно исследованиям, в среднем
5
%
5% пациентов испытывают приступы кашля в течение дня, однако среди курильщиков доля кашляющих составляет
40
%
40%. То есть (безусловная) вероятность
P
(
кашляет
)
=
0.05
P(кашляет)=0.05 при добавлении обусловливания может существенно измениться:
P
(
кашляет
∣
курит
)
=
0.4
P(кашляет∣курит)=0.4.
Упражнение. Известно, что в семье два ребёнка, причём один из них мальчик. Какова вероятность, что другой ребёнок тоже мальчик?
В общем случае условная вероятность
P(B∣A) при
P(A)

=0 полагается равной
P(B∣A)=
P(A)
P(A∩B)
.
В зависимости от соотношения событий
A
A и
B
B условная вероятность
P(B∣A) может принимать разные значения, например:
если
A
∩
B
=
∅
A∩B=∅, то событие
A
A исключает реализацию события
B
B, и
P(B∣A)=0;
если
A
⊂
B
A⊂B, то событие
A
A гарантирует осуществление события
B
B, и
P(B∣A)=1.
Разумеется, чаще всего события
A
A и
B
B соотносятся между собой более хитрым образом, и значение условной вероятности
P(B∣A) находится строго между
0
0 и
1
1.
Формула полной вероятности
Пусть пространство
Ω
Ω разбивается на попарно несовместные события
,…,B
при
i
≠
j
.
Ω=B
1
∪…∪B
n
,B
i
∩B
j
=∅ при i

=j.
Тогда
A=A∩Ω=(A∩B
1
)∪…∪(A∩B
n
);
отсюда по свойству конечной аддитивности находим, что
P(A)=P(A∩B
1
)+…+P(A∩B
n
).
Переходя к условным вероятностям, получаем формулу полной вероятности:
P(A)=
k=1
∑
n
P(A∣B
k
)P(B
k
).
Пример. Среди населения
33.7
%
33.7% имеют первую группу крови,
37.5
%
37.5% — вторую,
20.9
%
20.9% — третью,
7.9
%
7.9% — четвёртую. При переливании крови надо учитывать группы крови донора и рецепиента:
реципиенту с четвёртой группой крови можно перелить кровь любой группы;
реципиентам со второй и третьей группами можно перелить кровь той же группы или первой;
реципиентам с первой группой крови можно перелить только кровь первой группы.
С какой вероятностью допустимо переливание в случайно взятой паре донор—реципиент?
Решение. Пусть событие
A
A состоит в том, что переливание возможно, а событие
B
k
B
k
— в том, что донор имеет группу
k
k. По формуле полной вероятности
P(A)=P(A∣B
1
)P(B
1
)+P(A∣B
2
)P(B
2
)+P(A∣B
3
)P(B
3
)+P(A∣B
4
)P(B
4
).
Вероятности
P
(
B
k
)
P(B
k
) даны в условии, оттуда же находим, что
P(A∣B
1
)=1,
P(A∣B
2
)=P(B
2
)+P(B
P(A∣B
3
)=P(B
3
)+P(B
P(A∣B
4
)=P(B
4
).
Подставляя численные значения, получаем
P
(
A
)
=
0.337
+
(
0.375
+
0.079
)
⋅
0.375
+
(
0.209
+
0.079
)
⋅
0.209
+
0.07
9
2
=
0.573683.
P(A)=0.337+(0.375+0.079)⋅0.375+(0.209+0.079)⋅0.209+0.079
2
=0.573683.
Упражнение. Решите предыдущий пример, выбирая в качестве разбиения набор событий
C
k
C
k
, каждое из которых заключается в том, что реципиент имеет группу
k
k.
Формула полной вероятности легко обобщается на случай счётного числа попарно несовместных событий
B
k
B
k
, а также на случай обусловливания по некоторому событию
C
C, например:
P(A∣C)=
n
∑
P(A∣B
n
,C)P(B
n
∣C).
Формула Байеса
Заметим, что вероятность
P(A∩B) можно записать двумя способами
P(B∣A)P(A)=P(A∩B)=P(A∣B)P(B).
Оставим
P(B∣A) в левой части и получим формулу Байеса.
Формула Байеса. Для любых событий
A
A,
B
B c положительной вероятностью
P(B∣A)=
P(A)
P(A∣B)P(B)
.
Для вычисления знаменателя в формуле Байеса часто используется формула полной вероятности.
Упражнение. Среди определенной группы людей вероятность некоторой болезни 0.02. Тест, позволяющий выявить болезнь, несовершенен. На больном он дает позитивный результат в 98 случаях из 100, и, кроме того, он дает позитивный результат в 4 случаях из 100 на здоровом. Найдите вероятность того, что человек, на котором тест дал положительный результат, действительно болен.
Для непрерывного случая тоже есть своя формула полной вероятности, см. раздел про условную вероятность.
Независимые события
События
A
A и
B
B называются независимыми, если
P(A∣B)=P(A), то есть информация о реализации события
B
B никак не влияет на вероятность события
A
A.
По определению условной вероятности независимость событий
A
A и
B
B эквивалентна тому, что
P(A∩B)=P(A)P(B).
Последнее равенство годится для определения независмости событий
A
A и
B
B даже в том случае, если
P(A)=0 или
P(B)=0.
Пример. В полной колоде карт находится
52
52 карты:
4
4 масти от двойки до туза. Вероятность вытащить туза равна
P(Ace)=
52
4
=
13
1
, карту пиковой масти —
P(♠)=
52
13
=
4
1
. Эти события независимы, поскольку в пересечении этих событий лежит ровно одна карта — туз пик, вероятность появления которого равна
=P(Ace)P(♠).
Пусть теперь вытаскивается сразу две карты. Зависимы ли события «вытащены две карты пиковой масти» и «вытащены туз и король»? Посчитаем:
P(♠♠)=
52⋅51
13⋅12
663
.
P(AK)=
52⋅51
32
=
663
8
.
Вероятность вытащить туза и короля пик равна
1326
≈
0.00075
1326
1
≈0.00075, что отличается от
11271
≈
0.00071
P(♠♠)P(AK)=
11271
8
≈0.00071. Таким образом, эти события зависимы.
События
,…,A
n
попарно независимы, если
P(A
i
∩A
j
)=P(A
i
)P(A
j
) при
i
≠
j
i

=j. Эти же события независимы в совокупности, если
P(A
i
1
∩…∩A
i
m
)=
k=1
∏
m
P(A
i
k
)
для любого набора индексов
для любого набора индексов 1⩽i
1
<…<i
m
⩽n.
Упражнение. Приведите пример попарно независимых событий
, не являющихся независимыми в совокупности.
Определение независимости случайных величин из предыдущего параграфа полностью согласуется с только что введённым определением независимых событий. Например, для случая дискретных случайных величин
ξ
ξ и
η
η обозначим
=P(ξ=x
i
),B
j
=P(η=y
j
);
тогда
P(ξ=x
i
,η=y
j
)=P(A
i
∩B
j
), и поэтому независимость случайных величин
ξ
ξ и
η
η эквивалентна независимости событий
для всевозможных значений
i
i и
j
j.
Условная независимость
Бывает так, что зависимые события
A
A и
B
B становятся независимыми при выполнении некоторого третьего события
C
C. Более формально, события
A
A и
B
B условно независимы по отношению к событию
C
C, если
P(C)>0 и
P(A∣B,C)=P(A∣C).
Поскольку
P(A∣B,C)=
P(B∩C)
P(A∩B∩C)
,P(A∣C)=
P(C)
P(A∩C)
,
то условная независимость событий
A
A и
B
B эквивалетна равенству
P(C)
P(A∩B∩C)
=
P(C)
P(A∩C)
⋅
P(C)
P(B∩C)
,
а это, в свою очередь, означает, что
P(A∩B∣C)=P(A∣C)P(B∣C).
Таким образом, вероятность произведения условно независимых событий равна произведению условных вероятностей. Эта формула полностью аналогична формуле
P(A∩B)=P(A)P(B) для (безусловно) независимых событий.
Пример (цепь Маркова). Последовательность событий
,…,S
t
,… называется марковской цепью, если выполняется марковское свойство
P(S
t+1
∣S
t
,S
t−1
,…,S
0
)=P(S
t+1
∣S
t
),t∈N∪{0}.
В марковском свойстве заложен следующий смысл: в каждый момент времени
t
t «будущее»
S
t
+
1
S
t+1
зависит только от «настоящего»
S
t
S
t
, но не зависит от «прошлого»
t−1
∩…∩S
0
.
Итак, цепь Маркова характеризуется равенством
P(S
t+1
∣P
t
,S
t
)=P(S
t+1
∣S
t
), которое означает, что события
S
t
+
1
S
t+1
и
P
t
P
t
условно независимы по отношению к событию
S
t
S
t
.
Условные распределения
Пусть
ξ
ξ и
η
η — дискретные случайные величины и
P(η=y)>0. По аналогии с условными вероятностями условное распределение случайной величины
ξ
ξ при условии, что значение случайной величины
η
η равно
y
y, определяется по формуле
P(ξ=x
i
∣η=y)=
P(η=y)
P(ξ=x
i
,η=y)
.
Это действительно распределение вероятностей, поскольку
P(ξ=x
i
∣η=y)⩾0 и
P(ξ=x
i
∣η=y)=
P(η=y)
1
i
∑
P(ξ=x
i
,η=y)=1.
В непрерывном случае условное распределение задаётся условной плотностью
ξ∣η
(x∣y)=
p
η
(y)
p(x,y)
,
где
p(x,y) — совместная плотность случайных величин
ξ
ξ и
η
η. И снова проведением маргинализации по
x
x убеждаемся в том, что с нормировкой всё в порядке:
ξ∣η
(x∣y)dx=
p
η
(y)
1
−∞
∫
+∞
p(x,y)dx=
p
η
(y)
p
η
(y)
=1.
Поскольку
p(x,y)dy=p
ξ
(x), из формулы условной плотности получаем непрерывный аналог формулы полной вероятности:
(x)=
R
∫
p
ξ∣η
(x∣y)p
η
(y)dy.
Пример. Выберем случайное число
x∈[
2
1
,1], а затем — случайное число
y∈[0,x]. Как распределена случайная величина
y
y?
Переформулируем задачу: известно, что
ξ∼U[
2
1
,1] и
η∣ξ∼U[0,x]. Требуется найти плотность случайной величины
η
η. Имеем
(x)=2I
[
2
1
,1]
(x),p
η∣ξ
(y∣x)=
x
1
I
[0,x]
(y).
Применяя формулу полной вероятности, находим
(y)=
1/2
∫
1
x
2
I[y⩽x]dx={
2ln2,
−2lny,
0⩽y<
2
1
,
2
1
⩽y⩽1.
Упражнение. Пусть случайные величины
∼Exp(λ
k=1,…,n, независимы в совокупности. Чему равна вероятность
P
(
ξ
k
=
min
P(ξ
k
=min{ξ
1
,…,ξ
n
})?
Условные математические ожидания
Условное математическое ожидание
E(ξ∣η=y) отвечает на вопрос «чему равно среднее значение случайной величины
ξ
ξ при условии, что
η
=
y
η=y?».
Имея в распоряжении матрицу условного дискретного распределения
P(ξ=x
i
∣η=y
j
) или условную плотность
ξ∣η
(x∣y), условное математическое ожидание можно вычислить следующим образом:
E(ξ∣η)≡E(ξ∣η=y)=
i
∑
x
i
P(ξ=x
i
∣η=y) в дискретном случае;
E(ξ∣η)≡E(ξ∣η=y)=
R
∫
xp
ξ∣η
(x∣y)dx для непрерывных
ξ
ξ и
η
η.
Важно отметить, что после суммирования или интегрирования по переменной
x
x в формуле условного математического ожидания остаются зависимость от
y
y. Таким образом, в отличие от обычного среднего, которое является просто числом, условное ожидание представляет собой случайную величину
ζ=E(ξ∣η=y), поскольку его значение зависит от случайного значения
η
=
y
η=y.
Свойства условного математического ожидания
E(aξ
1
+bξ
2
∣η)=aE(ξ
1
∣η)+bE(ξ
2
∣η) (линейность).
Если
, то
E(ξ
1
∣η)⩽E(ξ
2
∣η) (монотонность).
Если случайные величины
ξ
ξ и
η
η независимы, то
E(ξ∣η)=Eξ.
E(g(η)ξ∣η)=g(η)E(ξ∣η).
E(E(ξ∣η))=Eξ (law of total expectation).
Упражнение. Prove the law of total expectation.
Условная дисперсия определяется по формуле
V(ξ∣η)=E((ξ−E(ξ∣η))
2
∣η)=E(ξ
2
∣η)−(E(ξ∣η))
2
.
Справедливо равенство
Vξ=E(V(ξ∣η))+V(E(ξ∣η)) (law of total variance).
Регрессия
В машинном обучении часто встречается задача регрессии, в которой требуется восстановить зависимость
Y=f(X) при наличии выборки
),…,(X
n
,Y
n
)
из некоторого неизвестного распределения с совместной плотностью
p(x,y). Стандартный способ решения задачи регресии — минимизация среднего значения функции потерь
L(Y,f(X)):
min
⁡
.
E[L(Y,f(X))]=
R
2
∬
L(y,f(x))p(x,y)dxdy→min.
В качестве функции потерь на одном объекте
(
x
,
y
)
(x,y) в задаче регрессии обычно выбирают квадратичную функцию:
L(y,f(x))=(y−f(x))
2
. Тогда
E[L(Y,f(X))]=
R
2
∬
(y−f(x))
2
p(x,y)dxdy;
для минимизации этого функционала применим немножко вариационного исчисления и продифференцируем по функции
f
(
x
)
f(x). Получим
(f(x)−y)p(x,y)dxdy=0,
откуда
f(x)=
p(x)
1
−∞
∫
+∞
yp(x,y)dy=
−∞
∫
+∞
yp
Y∣X
(y∣x)dy=E(Y∣X=x).
Полученное условное математическое ожидание, называемое функцией регрессии, показывает, чему в среднем равно значение зависимой переменной
Y
Y при условии, что
X
=
x
X=x.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
16.4. Многомерные распределения
Следующий параграф
16.6. Параметрические оценки

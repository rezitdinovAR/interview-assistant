---
title: Обобщающая способность – классическая теория
url: https://education.yandex.ru/handbook/ml/article/obobshayushaya-sposobnost-klassicheskaya-teoriya
course: ml
chapter: 13. Теория глубокого обучения
chapter_id: 13.2
---
Как мы уже видели во введении, мы не можем напрямую оптимизировать истинный риск модели
f
(
x
)
f(x)
R(f)=E
x,y∼D
r(y,f(x)),
так как нам недоступно полное распределение данных
D
D. Поэтому вместо задачи минимизации истинного риска, мы будем минимизировать эмпирический риск
(f)=E
x,y∈S
m
r(y,f(x))
на доступном нам наборе данных
S
m
S
m
.
Классическая теория предлагает оценивать разность эмпирического и истинного равномерно, что даёт
sup
f∈F
sup
(R(f)−
R
^
m
(f)).
Такая оценка не зависит от алгоритма обучения; она зависит лишь от класса моделей
F
F, в котором происходит поиск. Так, в случае нейронных сетей в качестве класса
F
F можно взять класс всех нейронных сетей фиксированной архитектуры, отличающихся только весами.
Если класс
F
F настолько велик, что для большинства наборов данных размера
m
m содержит модель
f
f, у которой эмпирический риск мал, а истинный велик, то оценка выше теряет смысл. Работа Understanding deep learning requires rethinking generalization показала, что именно это и происходит в нейронных сетях, применяемых на практике, на реальных наборах данных. А именно, пусть
A
A – алгоритм, применяемый для обучения сети, например, градиентный спуск. Предположим, что с высокой вероятностью
(A(S
m
))=0, если только размер выборки
m
m не слишком велик. Пусть
S
m
S
m
– наша выборка, а
– датасет, в котором примеры берутся из выборки, а разметка случайна. По предположению, модель
m,m
′
=A(S
m
∪S
m
′
′
), обученная на объединённом датасете, имеет нулевой риск на «настоящем» датасете
S
m
S
m
, если только
m
+
m
′
m+m
′
не слишком велик. С другой стороны, если
≫m, то
m,m
′
≈A(S
m
′
′
) – истинный риск такой модели близок к риску случайного угадывания.
Тем не менее, если в качестве
F
F взять не все модели, реализуемые данной архитектурой нейронной сети, а лишь реализуемые данным алгоритмом обучения на наборах данных из распределения с высокой вероятностью, то можно надеятся, что равномерная оценка окажется осмысленной.
Мы говорим «с высокой вероятностью» для того, чтобы исключить «нереалистичные» наборы данных, обучение на которых ведёт к плохим результатам, а также ничтожно-редкие случаи реализации шума в алгоритме обучения, при котором последний сходится в «плохие» решения. Подробнее о том, какие модели реализуются градиентным спуском, мы обсудим в параграфе про implicit bias.
Оценка супремума
Попробуем оценить супремум разницы рисков. Будем считать, что выборка
S
m
S
m
выбирается случайным (и равновероятным) образом из распределения данных
D
D. Некоторые из выборок могут быть катастрофически плохими, поэтому мы будем рассматривать оценки, которые верны не обязательно всегда, а просто с достаточно большой вероятностью.
Предположим сначала, что класс моделей
F
F конечен. Тогда
P
(
sup
f∈F
sup
(R(f)−
R
^
m
(f))≥ϵ)=
=P(∃f∈F:(R(f)−
R
^
m
(f))≥ϵ)≤
f∈F
∑
P(R(f)−
R
^
m
(f)≥ϵ)≤
≤
∣
F
∣
sup
≤∣F∣
f∈F
sup
P(R(f)−
R
^
m
(f)≥ϵ)∀ϵ>0
Заметим, что
R(f)=E
(f). Поэтому при фиксированном
f
f разницу рисков
(f)−R(f) можно оценить с помощью неравенства Хёффдинга.
Неравенство Хёффдинга (Hoeffding's inequality). Пусть
,…,X
m
– независимые одинаково распределённые случайные величины со значениями в
[
0
,
1
]
[0,1]. Тогда для всех
ϵ
>
0
ϵ>0 имеют место неравенства
i=1
∑
m
X
i
−E
i=1
∑
m
X
i
≥ϵ)≤e
P(E
i=1
∑
m
X
i
−
i=1
∑
m
X
i
≥ϵ)≤e
−
m
2ϵ
2
.
Как следствие неравенства Хёффдинга, получаем, что для любого
ϵ
>
0
ϵ>0 и для любой
f
∈
F
f∈F.
P(R(f)−
R
^
m
(f)≥ϵ)≤e
−2mϵ
2
Заметим, что тогда для любой
f
∈
F
f∈F,
log
⁡
1
δ
с вероятностью
R(f)−
R
^
m
(f)≤
2m
1
log
δ
1
с вероятностью ≥1−δ по S
m
.
Несмотря на то, что эта оценка является оценкой на обобщающую способность, она не имеет смысла, так как модель
f
f в ней задана априори и не зависит от
S
m
S
m
. Другими словами, она верна для необученных моделей
f
f.
Возвращаясь к нашей оценке, получаем:
P
(
sup
f∈F
sup
(R(f)−
R
^
m
(f))≥ϵ)≤∣F∣e
−2mϵ
2
∀ϵ>0,
где
∣
F
∣
∣F∣ – мощность класса
F
F. Следовательно,
sup
log
⁡
1
δ
+
log
⁡
∣
F
∣
)
с вероятностью
f∈F
sup
(R(f)−
R
^
m
(f))≤
2m
1
(log
δ
1
+log∣F∣)
с вероятностью ≥1−δ по S
m
.
В случае бесконечного
F
F используем следующее обобщение неравенства Хёффдинга:
Неравенство МакДайармида (McDiarmid's inequality). Пусть
,…,X
m
– независимые одинаково распределённые случайные величины,
g
g – скалярная функция с
m
m аргументами, такая что
sup
,…,x
m
,
x
~
i
sup
∣g(x
1
,…,x
i
,…,x
m
)−g(x
1
,…
x
~
i
,…x
m
)∣≤c
i
∀i=1,…,m
для некоторых
c
i
c
i
. Тогда для любого
ϵ
>
0
ϵ>0 имеет место неравенство
P(g(X
1
,…,X
m
)−Eg(X
1
,…,X
m
)≥ϵ)≤e
−
∑
i=1
Применяя теорему к
sup
g({(x
i
,y
i
)}
i=1
m
)=sup
f∈F
(R(f)−
R
^
m
(f)), получаем:
P
S
m
(
sup
sup
f∈F
sup
(R(f)−
R
^
m
(f))−E
S
m
′
f∈F
sup
(R(f)−
R
^
m
′
(f))≥ϵ)≤e
−2mϵ
2
,
из чего следует:
sup
sup
log
⁡
1
δ
с вероятностью
f∈F
sup
(R(f)−
R
^
m
(f))≤E
S
m
′
f∈F
sup
(R(f)−
R
^
m
′
(f))+
2m
1
log
δ
1
с вероятностью ≥1−δ по S
m
,
где
(f) – эмпирический риск на выборке
. В следующем подразделе мы постараемся оценить жёлтое слагаемое.
Симметризация и сложность Радемахера
Оценим сверху матожидание супремума:
E
S
m
′
sup
sup
f∈F
sup
(R(f)−
R
^
m
′
(f))=E
S
m
′
f∈F
sup
(f)−
R
^
m
′
(f))≤
sup
f∈F
sup
(
R
^
m
′′
(f)−
R
^
m
′
(f))=
sup
f∈F
sup
(
m
1
i=1
∑
m
(r(y
i
′′
,f(x
i
′′
))−r(y
i
′
,f(x
i
′
)))).
Этот шаг называется «симметризация»: теперь выражение выше зависит от двух равнозначных обучающих выборок
. Ниже для краткости будем обозначать
(f)=r(y
i
′
,f(x
i
′
)) и
(f)=r(y
i
′′
,f(x
i
′′
)).
Как оценить сверху супремум разности рисков? Наивная оценка, супремум суммы, слишком слаба: в самом деле, при фиксированном наборе данных вполне вероятно может существовать модель, имеющая большой риск на нём (достаточно взять модель, обученную на тех же данных, но с «неправильными» метками), поэтому матожидание супремума эмпирического риска может быть велико.
Для обхода этой сложности заметим, что выражение выше симметрично относительно перестановки местами двух выборок:
sup
sup
f∈F
sup
(
m
1
i=1
∑
m
(r
i
′′
(f)−r
i
′
(f)))=E
f∈F
sup
(
m
1
i=1
∑
m
(r
i
′
(f)−r
i
′′
(f))).
Более того, так как элементы обеих выборок выбираются независимо, значение выражения не меняется и при перестановке местами отдельно
i
i-ых элементов двух выборок. А именно, для любого набора
,…,σ
m
∈{−1,1}
sup
f∈F
sup
(
m
1
i=1
∑
m
(r
i
′′
(f)−r
i
′
(f)))=
sup
f∈F
sup
(
m
1
i=1
(f)−r
i
′
(f))).
Будем выбирать
σ
i
σ
i
независимо и равновероятно из
{−1,1}. Такие случайные величины называются переменными Радемахера.
Поскольку оценки выше были верны для любых сигм, они верны и в среднем по переменным Радемахера, выбранным независимо от выборки:
sup
f∈F
sup
(
m
1
i=1
∑
m
(r
i
′′
(f)−r
i
′
(f)))=
sup
1:m
f∈F
sup
(
m
1
i=1
(f)−r
i
′
(f))).
После введения переменных Радемахера оценка супремума разницы рисков через сумму супремумов становится не такой плохой. В самом деле, рассмотрим бинарную классификацию с помощью линейной модели. Если данные хорошо разделяются плоскостью, то
E
S
m
sup
sup
f∈F
(
m
1
∑
i=1
m
r
i
(f)) будет большим, так как в качестве
f
f можно взять линейную модель с противоположно ориентированной разделяющей плоскостью для
S
m
S
m
. В то же время для того, чтобы
sup
1:m
E
S
m
sup
f∈F
(
m
1
∑
i=1
m
σ
i
r
i
(f)) было большим, необходимо, чтобы существовала модель, отвечающая правильно на тех примерах, где
=−1, и неправильно, где
=1; для линейной модели это невозможно при большинстве конфигураций сигм.
Величина
sup
Rad
D,m
(H)=E
z
1:m
∼D
m
E
σ
1:m
∼U({−1,1}
m
)
h∈H
sup
(
m
1
i=1
∑
m
σ
i
h(z
i
)).
называется сложностью Радемахера класса функций
H
:
X
→
R
H:X→R (для распределения
D
D на
X
X и длины выборок
m
m). Она велика, если в классе
H
H содержатся функции, принимающие большие значения с заданными знаками на любом наборе данных фиксированного размера. Другими словами, сложность Радемахера измеряет, насколько выходы функций из класса
H
H могут коррелировать со случайным шумом.
Для нас актуальна сложность Радемахера классов вида
H
=
r
∘
F
H=r∘F, то есть композиций моделей из класса
F
F и функции риска
r
r. Если
F
F – класс линейных моделей в пространстве размерности меньшей, чем
m
m, то сложность Радемахера невелика. В то же время если
F
F – множество всех возможных решающих деревьев, то, если только наборы данных непротиворечивы, она равна единице. В самом деле, решающее дерево способно запомнить всю обучающую выборку, то есть добиться единичной корреляции с любым случайным шумом.
Вернёмся к оценке разницы рисков:
E
S
m
′
sup
sup
f∈F
sup
(R(f)−
R
^
m
′
(f))≤E
f∈F
sup
(
m
1
i=1
∑
m
(r
i
′′
(f)−r
i
′
(f)))=
sup
1:m
f∈F
sup
(
m
1
i=1
(f)−r
i
′
(f)))≤
sup
sup
1:m
(
f∈F
sup
(
m
1
i=1
(f))+
f∈F
sup
(
m
1
i=1
(f)))=
sup
=2E
S
m
′
E
σ
1:m
f∈F
sup
(
m
1
i=1
∑
m
σ
i
r(y
i
′
,f(x
i
′
)))=
=2Rad
D,m
(r∘F).
Оценка для «0/1-риска»
Сложность Радемахера зависит от функции риска. Рассмотрим задачу бинарной классификации с классами
+
1
+1 и
−
1
−1. Возьмём в качестве функции риска индикатор ошибки бинарной классификации, или «0/1-риск»:
r(y,z)=r
0/1
(y,z)=I[yz<0].
Название «0/1-риск» обусловлено тем, что риск принимает значения
0
0 и
1
1.
Заметим следующее:
E
σ
1
:
m
sup
max
1:m
f∈F
sup
(
m
1
i=1
(f))=E
σ
1:m
f∈F
S
m
max
(
m
1
i=1
(f)),
где
– класс эквивалентности функций из
F
F, в котором две функции считаются эквивалентными тогда и только тогда, когда их образы на выборке
S
m
S
m
имеют одинаковые знаки. Другими словами, среди всех функций, принимающих одни и те же знаки на
S
m
S
m
, мы выберем по одной и сформируем из них множество
. Заметим, что это множество конечно:
∣≤2
m
.
Нам понадобится следующая
Лемма. Пусть
X
X – случайная величина со значениями в
[
a
,
b
]
[a,b] и нулевым средним. Тогда для любых
s
>
0
s>0 имеет место неравенство
(b−a)
2
s
2
.
С её помощью получаем:
E
σ
1
:
m
sup
max
1:m
f∈F
sup
(
m
1
i=1
(f))=E
σ
1:m
f∈F
S
m
max
(
m
1
i=1
(f))=
=
1
m
s
log
⁡
exp
max
logexp(sE
σ
1:m
f∈F
S
m
max
(
i=1
(f)))≤
≤
1
m
s
log
exp
⁡
(
s
max
logE
σ
1:m
exp(s
f∈F
S
m
max
(
i=1
(f)))≤
≤
1
m
s
log
exp
log
f∈F
S
m
∑
E
σ
1:m
exp(s
i=1
(f))=
=
1
m
s
log
log
f∈F
S
m
∑
i=1
(f)
)≤
≤
1
m
s
log
log
log
f∈F
log(∣F
log
log∣F
Эта оценка верна для любого
s
>
0
s>0. Минимизируем её по
s
s. Легко видеть, что оптимальное
s
s равняется
(
2
/
m
)
log
(2/m)log∣F
S
m
∣
; подставляя его, получаем:
log
Rad
D,m
(r∘F)≤E
S
m
m
2
log∣F
S
m
∣
.(1)
Определим функцию роста класса
F
F как
max
(m)=
S
m
max
∣F
S
m
∣.
Эта функция показывает, сколько различных разметок класс функций
F
F может породить на наборе данных, в зависимости от размера этого набора. Очевидно, что
(m)≤2
m
и монотонно не убывает.
Например, для линейной модели на
d
d-мерном пространстве признаков
(m)=2
m
при
m
≤
d
+
1
m≤d+1 (любое подмножество
d
+
1
d+1 точек в общем положении в
d
d-мерном пространстве всегда можно отделить гиперплоскостью), но строго меньше этого числа при
m
>
d
+
1
m>d+1 (например, если точки – углы квадрата на плоскости, его диагонали нельзя разделить прямой).
Когда
∣=2
m
, будем говорить, что «
F
F разделяет
S
m
S
m
».
Определим размерность Вапника-Червоненкиса (или VC-размерность) как максимальное
m
m, при котором семейство
F
F разделяет любой датасет
max
VC(F)=max{m∣Π
F
(m)=2
m
}.
Таким образом, VC-размерность линейной модели равна
d
+
1
d+1.
Следующая лемма даёт связь между размерностью Вапника-Червоненкиса и функцией роста:
Лемма (Sauer–Shelah, см. подробнее здесь)
(m)≤
k=0
∑
VC(F)
(
k
m
)
Изучим асимптотическое поведение сложности Радемахера при
m
→
∞
m→∞. Обозначим
D=VC(F). Для
m
≤
D
m≤D имеем
(m)=2
m
, а для
m
>
D
m>D:
(m)≤
k=0
∑
D
(
k
m
)≤(
D
m
)
D
k=0
k=0
(1+
Подставляя это выражение в (1), получаем окончательную оценку на сложность Радемахера:
log
⁡
m
−
log
Rad
D,m
(r∘F)≤
m
2
VC(F)(1+logm−log(VC(F)))
log
m→∞
(
VC(F)
m
logm
).
Соответствующая оценка на истинный риск тогда примёт вид:
log
log
⁡
m
m
)
с вероятностью
log
δ
1
+Θ
m→∞
(
VC(F)
m
logm
)с вероятностью ≥1−δ по S
m
.
Для того, чтобы эта оценка была осмыслена, необходимо гарантировать
log
⁡
m
)
VC(F)<m/(2logm). Для линейных моделей, при условии
m
≫
d
m≫d (данных намного больше, чем признаков), оценки действительно получаются осмысленными.
К сожалению, для нейронных сетей это подчас неверно. В работе Nearly-tight VC-dimension and Pseudodimension Bounds for Piecewise Linear Neural Networks показано, что если
F
F обозначает класс моделей, реализуемых полносвязной сетью ширины
n
n с
N
N параметрами, то
VC(F)=Θ(nN). Таким образом, наша оценка на сложность Радемахера становится бесполезной в реалистичных сценариях, когда число весов сети
N
N много больше числа примеров в обучающей выборке
m
m.
Если априори известно, что результат обучения лежит в некотором классе
F
B
F
B
, то в оценке сложности Радемахера можно использовать именно этот класс, а не полный класс моделей
F
F. Очевидно, что сложность
F
B
F
B
, лежащего в
F
F, не больше сложности
F
F. Так, в работе Spectrally-normalized margin bounds for neural networks получены оценки для сложности полносвязной сети с липшицевыми функциями активации при условии, что нормы весов ограничены; см. также полный конспект лекций. В этом случае под
F
B
F
B
будем понимать класс сетей с весами нормы не больше
B
B. Обозначим соответствующую оценку через
B
B:
sup
с вероятностью
f∈F
B
sup
(R(f)−
R
^
m
(f))≤B(B,δ)с вероятностью ≥1−δ по S
m
.
К сожалению, нет гарантий, что градиентный спуск всегда сходится в решение с нормой меньше какого-то числа. Чтобы обойти это ограничение, используют следующую технику. Возьмём последовательность ограничений
B
j
B
j
, такую что
j+1
и
j=1
⋃
∞
F
B
j
=F.
Также возьмём последовательность
δ
j
δ
j
, монотонно убывающую к нулю и суммирующуюся в
δ
δ. Тогда для любого
j
≥
1
j≥1
sup
с вероятностью
f∈F
B
j
sup
(R(f)−
R
^
m
(f))≤B(B
j
,δ
j
)с вероятностью ≥1−δ
j
по S
m
.
А значит,
sup
с вероятностью
f∈F
B
j
sup
(R(f)−
R
^
m
(f))≤B(B
j
,δ
j
)∀j≥1с вероятностью ≥1−∑
j=1
∞
δ
j
=1−δ по S
m
.
Из этого следует, что
с вероятностью
)≤B(B
)с вероятностью ≥1−δ по S
m
,
где
– минимальное
j
j, при котором
Такая техника используется, например, в работах Spectrally-normalized margin bounds for neural networks и A PAC-Bayesian Approach to Spectrally-Normalized Margin Bounds for Neural Networks.
Фундаментальная проблема равномерных оценок
Пример модели (розовая кривая), имеющей малый истинный риск, но большой эмпирический на заданном наборе данных (кружочки). Данные одного класса лежат на желтом круге, другого – на голубом; оптимальная разделяющая поверхность обозначена пунктиром. Имея набор из кружочков, мы строим противоположный набор, обозначенный крестиками; заметим, что он мог прийти из того же распределения. Если алгоритм обучения старается отодвинуть границу классов как можно дальше от примеров, то результатом обучения на наборе крестиков может стать розовая кривая. Пример взят из работы Uniform convergence may be unable to explain generalization in deep learning.
Напомним, что построение равномерных оценок проходило в несколько шагов:
Оценка супремумом
sup
f∈F
sup
(R(f)−
R
^
m
(f))
Применение неравенства макДайармида:
sup
sup
log
⁡
1
δ
с вероятностью
f∈F
sup
(R(f)−
R
^
m
(f))≤E
S
m
′
f∈F
sup
(R(f)−
R
^
m
′
(f))+
2m
1
log
δ
1
с вероятностью ≥1−δ по S
m
,
Оценка матожидания супремума (жёлтое слагаемое выше) с помощью симметризации с дальнейшим выходом на сложность Радемахера:
E
S
m
′
sup
sup
sup
f∈F
sup
(R(f)−
R
^
m
′
(f))=E
S
m
′
f∈F
sup
(f)−
R
^
m
′
(f))≤E
f∈F
sup
(
R
^
m
′′
(f)−
R
^
m
′
(f)).
На каждом шаге предыдущая величина оценивается сверху, и потенциально каждое из этих неравенств может оказаться слишком слабым и привести к бессмысленной оценке. Давайте это проиллюстрируем.
Выше мы уже отмечали, что если класс
F
F содержит модель, для которой
(f) мал, а
R
(
f
)
R(f) велик, то равномерная оценка становится бессмысленной. По этой причине, имеет смысл выбирать класс
F
F как можно более маленьким. Самым лучшим из возможных классов мог бы быть класс моделей, к которым сходится наш алгоритм обучения с высокой вероятностью.
Рассмотрим случай, близкий к идеальному: тот, в котором существует
ϵ
>
0
ϵ>0, для которого при любых
f
∈
F
f∈F имеем
R(f)<ϵ. Иными словами, предположим, что все модели класса
F
F хорошо обобщают. В этом случае оценка выше близка к идеальной:
с вероятностью
)≤ϵс вероятностью ≥1−δ по S
m
.
Но что будет, если мы начнём честно воспроизводить процесс построения равномерных оценок? После второго шага мы получаем оценку вида
sup
log
⁡
1
δ
с вероятностью
f∈F
sup
(R(f)−
R
^
m
(f))≤ϵ+
2m
1
log
δ
1
с вероятностью ≥1−δ по S
m
,
которая не сильно хуже предыдущей, но в которой всё равно появилось лишнее слагаемое.
Но допустим, что мы хотим честно проделать третий шаг процедуры получения равномерных оценок. Для этого нам необходимо было оценить матожидание супремума, которое после симметризации получает вот такую верхнюю оценку:
sup
f∈F
sup
(
R
^
m
′′
(f)−
R
^
m
′
(f)).
Таким образом, малость истинного риска не гарантирует малость эмпирического риска на любом наборе данных. Так, авторы статьи Uniform convergence may be unable to explain generalization in deep learning предъявили пример, в котором для любого
существует модель
∈F, такая что
)≈1, но при этом
) и
) малы. Иллюстрация такой ситуации приведена в начале параграфа. Тогда
sup
sup
f∈F
(
R
^
m
′′
(f)−
R
^
m
′
(f)) велик, и оценки теряют смысл.
К счастью, даже эта фундаментальная проблема не ставит крест на равномерных оценках. Так, работы Uniform Convergence of Interpolators: Gaussian Width, Norm Bounds, and Benign Overfitting и Stability and Deviation Optimal Risk Bounds with Convergence Rate
O(1/n) рассматривают равномерную оценку в классе интерполирующих моделей, то есть, имеющих нулевой эмпирический риск:
sup
f∈F:
R
^
m
(f)=0
sup
R(f).
Для таких моделей контрпример выше не работает.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
13.1. Введение в теорию глубокого обучения
Следующий параграф
13.3. PAC-байесовские оценки риска

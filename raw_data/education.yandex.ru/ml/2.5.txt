---
title: Градиентный бустинг
url: https://education.yandex.ru/handbook/ml/article/gradientnyj-busting
course: ml
chapter: 2. Классическое обучение с учителем
chapter_id: 2.5
---
Как устроено самое мощное семейство не-нейросетевых моделей: градиентный бустинг над решающими деревьями
В прошлых разделах мы научились соединять базовые алгоритмы в ансамбль с помощью бэггинга (и, в частности, строить из решающих деревьев случайные леса). Теперь мы рассмотрим другой способ объединять базовые алгоритмы в композицию — градиентный бустинг.
В ходе обучения случайного леса каждый базовый алгоритм строится независимо от остальных. Бустинг, в свою очередь, воплощает идею последовательного построения линейной комбинации алгоритмов. Каждый следующий алгоритм старается уменьшить ошибку текущего ансамбля.
Бустинг, использующий деревья решений в качестве базовых алгоритмов, называется градиентным бустингом над решающими деревьями, (Gradient Boosting on Decision Trees, GBDT).
Он отлично работает на выборках с «табличными», неоднородными данными. Пример таких данных — описание пользователя Яндекса через его возраст, пол, среднее число поисковых запросов в день, число заказов такси и так далее. Такой бустинг способен эффективно находить нелинейные зависимости в данных различной природы.
Этим свойством обладают все алгоритмы, которые используют деревья решений, однако именно GBDT обычно выигрывает в подавляющем большинстве задач. Благодаря этому он широко применяется во многих конкурсах по машинному обучению и задачах из индустрии:
поисковом ранжировании;
рекомендательных системах;
таргетировании рекламы;
предсказании погоды;
выбора пункта назначения такси и многих других.
Не так хорошо бустинг проявляет себя на однородных данных: текстах, изображениях, звуке, видео. В таких задачах нейросетевые подходы почти всегда демонстрируют лучшее качество.
И хотя деревья решений — традиционный выбор для объединения в ансамбли, никто не запрещает использовать и другие алгоритмы (например, линейные модели) в качестве базовых. Эта возможность реализована в пакете XGBoost.
Стоит только понимать, что построенная композиция окажется линейной комбинацией линейных моделей, то есть опять-таки линейной моделью - или нейросетью с одним полносвязным слоем. Это уменьшает возможности ансамбля эффективно определять нелинейные зависимости в данных. Поэтому в этом параграфе мы рассмотрим только бустинг над решающими деревьями.
Интуиция
Рассмотрим задачу регрессии с квадратичной функцией потерь:
min
⁡
L(y,x)=
2
1
i=1
∑
N
(y
i
−a(x
i
))
2
→min
Для решения будем строить композицию из
K
K базовых алгоритмов:
a(x)=a
K
(x)=b
1
(x)+b
2
(x)+⋯+b
K
(x)
Если мы обучим единственное решающее дерево, то качество такой модели, скорее всего, будет низким. Однако мы знаем, на каких объектах построенное дерево давало точные предсказания, а на каких ошибалось.
Попробуем использовать эту информацию и обучим ещё одну модель. Допустим, что предсказание первой модели на объекте
x
l
x
l
на 10 больше, чем необходимо (т.е.
)=y
l
+10). Если бы мы могли обучить новую модель, которая на
x
l
x
l
будет выдавать ответ
−
10
−10, то сумма ответов этих двух моделей на объекте
x
l
x
l
в точности совпала бы с истинным значением:
)+b
2
(x
l
)=(y
l
+10)+(−10)=y
l
Другими словами, если вторая модель научится предсказывать разницу между реальным значением и ответом первой, то это позволит уменьшить ошибку композиции.
В реальности вторая модель тоже не сможет обучиться идеально, поэтому обучим третью, которая будет «компенсировать» неточности первых двух. Будем продолжать так, пока не построим композицию из
K
K алгоритмов.
Для объяснения метода градиентного бустинга полезно воспользоваться следующей аналогией. Бустинг можно представить как гольфиста, цель которого — загнать мяч в лунку с координатой
y
ball
y
ball
. Положение мяча здесь – ответ композиции
a
(
x
ball
)
a(x
ball
). Гольфист мог бы один раз ударить по мячу, не попасть в лунку и пойти домой, но настырность заставляет его продолжить.
Источник
По счастью, ему не нужно начинать каждый раз с начальной позиции. Следующий удар гольфиста переводит мяч из текущего положения
a
k
(
x
ball
)
a
k
(x
ball
) в положение
ball
)
a
k+1
(x
ball
). Каждый следующий удар — это та поправка, которую вносит очередной базовый алгоритм в композицию. Если гольфист все делает правильно, то функция потерь будет уменьшаться:
L(y,a
k+1
(x))<L(y,a
k
(x)),
то есть мяч постепенно будет приближаться к лунке.
Удары при этом делаются не хаотично. Гольфист оценивает текущее положение мяча относительно лунки и следующим ударом старается нивелировать те проблемы, которые он создал себе всеми предыдущими. Подбираясь к лунке, он будет бить всё аккуратнее и, возможно, даже возьмет другую клюшку, но точно не будет лупить так же, как из первоначальной позиции. В итоге комбинация всех ударов рано или поздно перенесет мяч в лунку.
Подобно тому, как гольфист постепенно подводит мяч к цели, бустинг с каждым новым базовым алгоритмом всё больше приближает предсказание к истинному значению метки объекта.
Рассмотрим теперь другую аналогию — разложение функции в ряд Тейлора. Из курса математического анализа известно, что (достаточно хорошую) бесконечно дифференцируемую функцию
f
(
x
)
f(x) на интервале
x∈(a−R,a+R) можно представить в виде бесконечной суммы степенных функций:
f(x)=
n=0
∑
∞
n!
f
(n)
(a)
(x−a)
n
.
Одна, самая первая степенная функция в разложении, очень грубо приближает
f
(
x
)
f(x). Прибавляя к ней следующую, мы получим более точное приближение. Каждая следующая элементарная функция увеличивает точность приближения, но менее заметна в общей сумме. Если нам не требуется абсолютно точное разложение, вместо бесконечного ряда Тейлора мы можем ограничиться суммой его первых
k
k элементов. Таким образом, интересующую нас функцию мы с некоторой точностью представили в виде суммы «простых» функций.
Перенесём эту идею на задачи машинного обучения. В машинном обучении мы пытаемся по выборке
) восстановить неизвестную истинную зависимость. Прежде всего, мы выбираем подходящий алгоритм. Мы можем выбрать «сложный» алгоритм, который сразу хорошо выучит истинную зависимость.
А можем обучить «простой», который выучит истинную зависимость посредственно. Затем мы добавим к нему ещё один такой простой алгоритм, чтобы уточнить предсказание первого алгоритма. Продолжая этот процесс, мы получим сумму простых алгоритмов, где первый алгоритм грубо приближает истинную зависимость, а каждый следующий делает приближение всё точнее.
Пример с задачей регрессии: формальное описание
Рассмотрим тот же пример с задачей регрессии и квадратичной функцией потерь:
min
⁡
L(y,x)=
2
1
i=1
∑
N
(y
i
−a(x
i
))
2
→min
Для решения также будем строить композицию из
K
K базовых алгоритмов семейства
a(x)=a
K
(x)=b
1
(x)+b
2
(x)+⋯+b
K
(x)
В качестве базовых алгоритмов выберем, как и условились в начале параграфа, семейство
B
B решающих деревьев некоторой фиксированной глубины.
Используя известные нам методы построения решающих деревьев, обучим алгоритм
(x)∈B, который наилучшим образом приближает целевую переменную:
argminb∈B
(x)=
b∈B
argmin
L(y,b(x))
Построенный алгоритм
(x), скорее всего, работает не идеально. Более того, если базовый алгоритм работает слишком хорошо на обучающей выборке, то высока вероятность переобучения: низкий уровень смещения, но высокий уровень разброса. Далее вычислим, насколько сильно отличаются предсказания этого дерева от истинных значений:
Теперь мы хотим скорректировать
(x) с помощью
(x). В идеале так, чтобы
(x) идеально предсказывал величины
, ведь в этом случае
)=b
1
(x
i
)+b
)+s
)+(y
i
−b
1
(x
i
))=y
i
Найти совершенный алгоритм, скорее всего, не получится, но по крайней мере мы можем выбрать из семейства наилучшего представителя для такой задачи. Итак, второе решающее дерево будет обучаться предсказывать разности
argminb∈B
(x)=
b∈B
argmin
L(s
1
,b(x))
Ожидается, что композиция из двух таких моделей
(x)=b
1
(x)+b
2
(x) станет более качественно предсказывать целевую переменную
y
y.
Далее рассуждения повторяются до построения всей композиции. На
k
k-ом шаге вычисляется разность между правильным ответом и текущим предсказанием композиции из
k
−
1
k−1 алгоритмов:
k−1
=y
i
−
j=1
∑
k−1
b
j
(x
i
)=y
i
−a
k−1
(x
i
)
Затем
k
k-й алгоритм учится предсказывать эту разность:
argminb∈B
(x)=
b∈B
argmin
L(s
k−1
,b(x)),
а композиция в целом обновляется по формуле
(x)=a
k−1
(x)+b
k
(x)
Обучение
K
K базовых алгоритмов завершает построение композиции.
Обобщение на другие функции потерь
Интуиция
Отметим теперь важное свойство функции потерь в рассмотренном выше примере с регрессией. Для этого посчитаем производную функции потерь по предсказанию
z=a
k
(x
i
) модели для
i
i-го объекта:
∂L(y
i
,z)
z=a
−z)
2
z=a
)−y
i
Видим, что разность, на которую обучается
k
k-й алгоритм, выражается через производную:
)=−
∂z
∂L(y
i
,z)
z=a
k
(x
i
)
Таким образом, для каждого объекта
x
i
x
i
очередной алгоритм в бустинге обучается предсказывать антиградиент функции потерь по предсказанию модели
∂L(y
i
,z)
в точке
) предсказания текущей части композиции на объекте
x
i
x
i
.
Почему же это важно? Дело в том, что это наблюдение позволяет обобщить подход построения бустинга на произвольную дифференцируемую функцию потерь. Для этого мы заменяем обучение на разность
обучением на антиградиент функции потерь
(−g
i
k
), где
∂L(y
i
,z)
z=a
k
(x
i
)
Вспомните аналогию с гольфистом: обучение композиции можно представить как перемещение предсказания из точки
),a
k
(x
2
),…,a
k
(x
N
)) в точку
k+1
(x
1
),a
k+1
(x
2
),…,a
k+1
(x
N
)). В конечном итоге мы ожидаем, что точка
),a
K
(x
2
),…,a
K
(x
N
)) будет располагаться как можно ближе к точке с истинными значениями
,…,y
N
).
5
В случае квадратичной функции потерь интуиция вполне подкрепляется математикой. Изменится ли что-либо в наших действиях, если мы поменяем квадратичную функцию потерь на любую другую? С одной стороны, мы, как и прежде, можем двигаться в направлении уменьшения разности предсказания и истинного значения: любая функция потерь поощряет такие шаги для каждого отдельного объекта, ведь для любой адекватной функции потерь выполнено
L(y,y)=0.
Но мы можем посмотреть на задачу и с другой стороны: не с точки зрения уменьшения расстояния между вектором предсказаний и вектором истинных значений, а с точки зрения уменьшения значения функции потерь. Для наискорейшего уменьшения функции потерь нам необходимо шагнуть в сторону её антиградиента по вектору предсказаний текущей композиции, то есть как раз таки в сторону вектора
(−g
1
k
,…,−g
N
k
). Это направление не обязано совпадать с шагом по направлению уменьшения разности предсказания и истинного значения. Например, может возникнуть гипотетическая ситуация, как на рисунке ниже:
5
В изображённом примере рассматриваются два объекта
. Текущее предсказание для них —
),a
k
(x
2
)), а окружность определяет варианты следующего шага: первый вариант — пойти в направлении
), как делалось ранее; второй — пойти в направлении антиградиента. Также показаны линии уровня значений функции потерь. Функция потерь в этом примере устроена таким образом, что
, из-за чего шаг по антиградиенту оказывается более выгодным.
Движение в сторону антиградиента более выгодно с точки зрения минимизации функции потерь — плюс оно также позволяет справляться с ситуациями, когда явно посчитать остаток (разницу между целевым значением и предсказанием) не представляется возможным.
Один из таких примеров — задача ранжирования. В задаче ранжирования объекты в датасете разбиты на группы и требуется построить модель, по предсказаниям которой можно было бы «правильно» упорядочить документы в каждой группе (обычно по убыванию предсказания модели).
Что значит упорядочить «правильно»? Это значит, что полученная по предсказаниям модели перестановка объектов в группе должна быть близка к идеальной по некоторой метрике.
Как задается идеальная перестановка? Есть два способа:
Первый способ — проставить каждому объекту число
y
y, по которому можно отсортировать объекты для получения идеальной перестановки. Это число можно рассматривать как таргет и обучать модель регрессии — в некоторых случаях это даже будет работать хорошо.
Второй способ — задать набор пар объектов, которые обозначают их порядок относительно друг друга в идеальной перестановке. То есть пара
(
i
,
j
)
(i,j) означает, что объект с номером
i
i должен стоять раньше в перестановке, чем объект с номером
j
j.
Во втором способе таргетов у объектов нет, но дифференцируемая функция потерь есть — в библиотеке CatBoost она называется PairLogit и вычисляется по формуле:
PairLogit=
∣Pairs∣
−
p,n∈Pairs
∑
(log(
1+e
−(a
где
— это предсказания модели на объектах
p
p и
n
n соответственно. Градиент такой функции потерь посчитать можно, а разницу между предсказанием и истинным значением — нет.
Математическое обоснование
Попробуем записать наши интуитивные соображения более формально. Пусть
L
L – дифференцируемая функция потерь, а наш алгоритм
a
(
x
)
a(x) представляет собой композицию базовых алгоритмов:
a(x)=a
k
(x)=b
1
(x)+…+b
k
(x)
Мы строим нашу композицию «жадно»:
(x)=a
k−1
(x)+b
k
(x),
где вновь добавляемый базовый алгоритм
b
k
b
k
обучается так, чтобы улучшить предсказания текущей композиции:
b
k
=
argminb∈B
b∈B
argmin
i=1
∑
N
L(y
i
,a
k−1
(x
i
)+b(x
i
))
Модель
b
0
b
0
выбирается так, чтобы минимизировать потери на обучающей выборке:
b
0
=
argminb∈B
b∈B
argmin
i=1
∑
N
L(y
i
,b(x
i
))
Для построения базовых алгоритмов на следующих шагах рассмотрим разложение Тейлора функции потерь
L
L до первого члена в окрестности точки
k−1
(x
i
)):
L(y
i
,a
k−1
(x
i
)+b(x
i
))≈L(y
i
,a
k−1
(x
i
))+b(x
i
)
∂z
∂L(y
i
,z)
z=a
k−1
(x
i
)
=L(y
i
,a
k−1
(x
i
))+b(x
i
)g
i
k−1
Избавившись от постоянных членов, мы получим следующую оптимизационную задачу:
b
k
≈
argminb∈B
b∈B
argmin
i=1
∑
N
b(x
i
)g
i
k−1
Поскольку суммируемое выражение — это скалярное произведение двух векторов, его значение минимизируют
b
(
x
i
)
b(x
i
), пропорциональные значениям
k−1
. Поэтому на каждой итерации базовые алгоритмы
b
k
b
k
обучаются предсказывать значения антиградиента функции потерь по текущим предсказаниям композиции.
Итак, использованная нами интуиция шага в сторону «уменьшения остатка» удивительным образом привела к оптимальным смещениям в случае квадратичной функции потерь, но для других функций потерь это не так: для них смещение происходит в сторону антиградиента.
Получается, что в общем случае на каждой итерации базовые алгоритмы должны приближать значения антиградиента функции потерь. Однако есть частный случай, в котором в качестве таргета для базового алгоритма выгоднее использовать именно «остатки» — это касается функции потерь MAE. Её производная равна -1, 0 или +1.
Приближая базовым алгоритмом антиградиент MAE, количество итераций до сходимости будет расти пропорционально масштабу таргета. То есть, если домножить целевое значение на 10, то потребуется в 10 раз больше итераций градиентного бустинга. Использование остатков в качестве таргета для базового алгоритма не имеет такой проблемы. Аналогичные рассуждения верны также для функции MAPE, в которой проблема с масштабом таргета может проявляться еще сильнее.
Обучение базового алгоритма
При построении очередного базового алгоритма
b
k
+
1
b
k+1
мы решаем задачу регрессии с таргетом, равным антиградиенту функции потерь исходной задачи на предсказании
+…+b
k
.
Теоретически можно воспользоваться любым методом построения регрессионного дерева. Важно выбрать оценочную функцию
S
S, которая будет показывать, насколько текущая структура дерева хорошо приближает антиградиент. Её нужно будет использовать для построения критерия ветвления:
max
⁡
,
∣R∣⋅S(R)−∣R
right
∣⋅S(R
right
)−∣R
left
∣⋅S(R
left
)→max,
где
S
(
R
)
S(R) — значение функции
S
S в вершине
S(R
left
),S(R
right
) — значения в левом и правом сыновьях
R
R после добавления предиката,
∣
⋅
∣
∣⋅∣ — количество элементов, пришедших в вершину.
Например, можно использовать следующие оценочные функции:
(g,p)=
i=1
Cosine(g,p)=−
i=1
i=1
∑
N
g
i
2
i=1
где
p
i
p
i
— предсказание дерева на объекте
— антиградиент, на который учится дерево,
p=p
i
i=1
g=g
i
N
. Функция
L
2
L
2
представляет собой среднеквадратичную ошибку, а функция
Cosine определяет близость через косинусное расстояние между векторами предсказаний и антиградиентов.
В итоге обучение базового алгоритма проходит в два шага:
по функции потерь вычисляется целевая переменная для обучения следующего базового алгоритма:
∂L(y
i
,z)
z=a
k
(x
i
)
строится регрессионное дерево на обучающей выборке
,−g
i
k
), минимизирующее выбранную оценочную функцию.
На практике
Поскольку для построения градиентного бустинга достаточно уметь считать градиент функции потерь по предсказаниям, с его помощью можно решать широкий спектр задач. В библиотеках градиентного бустинга даже реализована возможность создавать свои функции потерь: для этого достаточно уметь вычислять ее градиент, зная истинные значения и текущие предсказания для элементов обучающей выборки.
Типичный градиентный бустинг имеет в составе несколько тысяч деревьев решений, которые необходимо строить последовательно. Построение решающего дерева на выборках типичного размера и современном железе, даже с учетом всех оптимизаций, требует небольшого, но всё-таки заметного времени (0.1-1c), которое для всего ансамбля превратится в десятки минут. Это не так быстро, как обучение линейных моделей, но всё-таки значительно быстрее, чем обучение типичных нейросетей.
Темп обучения (learning rate)
Обучение композиции с помощью градиентного бустинга может привести к переобучению, если базовые алгоритмы слишком сложные. Например, если сделать решающие деревья слишком глубокими (более 10 уровней), то при обучении бустинга ошибка на обучающей выборке даже при довольно скромном
K
K может приблизиться к нулю, то есть предсказание будет почти идеальным, но на тестовой выборке всё будет плохо.
Существует два решения этой проблемы.
Во-первых, необходимо упростить базовую модель, уменьшив глубину дерева (либо примерив какие-либо ещё техники регуляризации).
Во-вторых, мы можем ввести параметр, называемый темпом обучения (learning rate)
η∈(0,1]:
k+1
(x)=a
k
(x)+ηb
k+1
(x)
Присутствие этого параметра означает, что каждый базовый алгоритм вносит относительно небольшой вклад во всю композицию: если расписать сумму целиком, она будет иметь вид
k+1
(x)=b
1
(x)+ηb
2
(x)+ηb
3
(x)+…+ηb
k+1
(x)
Значение параметра обычно определяется эмпирически по входным данным. В библиотеке CatBoost темп обучения может быть выбран автоматически по набору данных. Для этого используется заранее обученная линейная модель, предсказывающая темп обучения по мета-параметрам выборки данных: числу объектов, числу признаков и другим.
Темп обучения связан с количеством итераций градиентного бустинга. Чем меньше learning rate, тем больше итераций потребуется сделать для достижения того же качества на обучающей выборке.
Feature importance
Отдельные деревья решений можно легко интерпретировать, просто визуализируя их структуру. Но в модели градиентного бустинга содержатся сотни деревьев, и поэтому её нелегко интерпретировать с помощью визуализации входящих в неё деревьев. При этом хотелось бы, как минимум, понимать, какие именно признаки в данных оказывают наибольшее влияние на предсказание композиции.
Можно сделать следующее наблюдение: признаки из верхней части дерева влияют на окончательное предсказание для большей доли обучающих объектов, чем признаки, попавшие на более глубокие уровни.
Таким образом, ожидаемая доля обучающих объектов, для которых происходило ветвление по данному признаку, может быть использована в качестве оценки его относительной важности для итогового предсказания. Усредняя полученные оценки важности признаков по всем решающим деревьям из ансамбля, можно уменьшить дисперсию такой оценки и использовать ее для отбора признаков. Этот метод известен как MDI (mean decrease in impurity).
Существуют и другие методы оценки важности признаков для ансамблей: например, Permutation feature importance (см. описание в sklearn) и множество разных подходов, предлагаемых в библиотеке CatBoost. Все эти техники отбора признаков применимы также и для случайных лесов.
Реализации
Для общего развития имеет смысл посмотреть реализацию в sklearn, но на практике она весьма медленная и не такая уж умная.
Хороших реализаций GBDT есть, как минимум, три: LightGBM, XGBoost и CatBoost. Исторически они отличались довольно сильно, но за последние годы успели скопировать друг у друга все хорошие идеи.
Форма деревьев
Одно из основных отличий LightGBM, XGBoost и CatBoost — форма решающих деревьев.
LightGBM строит деревья по принципу: «На каждом шаге делим вершину с наилучшим скором», а основным критерием остановки выступает максимально допустимое количество вершин в дереве. Это приводит к тому, что деревья получаются несимметричными, то есть поддеревья могут иметь разную глубину — например, левое поддерево может иметь глубину
2
2, а правое может разрастись до глубины
15
15.
С одной стороны, это позволяет быстро подогнаться под обучающие данные. С другой — бесконтрольный рост дерева в глубину неизбежно ведет к переобучению, поэтому LightGBM позволяет помимо количества вершин ограничивать и максимальную глубину. Впрочем, это ограничение обычно все равно выше, чем для XGBoost и CatBoost.
tree
XGBoost строит деревья по принципу: «Строим дерево последовательно по уровням до достижения максимальной глубины». Отдельного ограничения на количество вершин нет, так как оно естественным образом получается из ограничения на глубину дерева. В XGBoost деревья «стремятся» быть симметричными по глубине, и в идеале получается полное бинарное дерево, если это не противоречит другим ограничениям (например, ограничению на минимальное количество объектов в листе). Такие деревья обычно являются более устойчивыми к переобучению.
tree
CatBoost строит деревья по принципу: «Все вершины одного уровня имеют одинаковый предикат». Одинаковые сплиты во всех вершинах одного уровня позволяют избавиться от ветвлений (конструкций if-else) в коде инференса модели с помощью битовых операций и получить более эффективный код, который в разы ускоряет применение модели, в особенности в случае применения на батчах.
Кроме этого, такое ограничение на форму дерева выступает в качестве сильной регуляризации, что делает модель более устойчивой к переобучению. Основной критерий остановки, как и в случае XGBoost, — ограничение на глубину дерева. Однако, в отличие от XGBoost, в CatBoost всегда создаются полные бинарные деревья, несмотря на то, что в некоторые поддеревья может не попасть ни одного объекта из обучающей выборки.
tree
Где используется градиентный бустинг
Если коротко — везде.
Сегодня это один из двух главных подходов, которые используются на практике (второй — это нейронные сети, конечно). Формально градиентный бустинг слабее и менее гибок, чем сети, но выигрывает в простоте настройки темпа обучения и применения, размере и интерпретируемости модели.
Во многих компаниях, так или иначе связанных с ML, он используется для всех задач, которые не связаны с однородными данными (картинками, текстами, и так далее). Типичный поисковый запрос в Яндексе, выбор отеля на Booking.com или сериала на вечер в Netflix задействует несколько десятков моделей GBDT.
Впрочем, в будущем можно ожидать плавного исчезновения этого подхода, так как улучшение архитектур глубинного обучения и дальнейшее развитие железа нивелирует его преимущество по сравнению с нейросетями.
Почитать по теме
Серия блог-постов о градиентном бустинге от Terence Parr and Jeremy Howard
Раздел документации sklearn с теоретическими выкладками для градиентного бустинга
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
2.4. Ансамбли в машинном обучении
Как смешать несколько моделей в одну. Стэкинг, бэггинг, случайные леса
Следующий параграф
3.1. Метрики классификации и регрессии
Как оценить качество модели для классификации или регрессии и почему для разных задач нужны разные метрики

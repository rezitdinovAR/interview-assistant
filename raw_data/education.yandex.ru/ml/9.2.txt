---
title: Рекомендации на основе матричных разложений
url: https://education.yandex.ru/handbook/ml/article/rekomendacii-na-osnove-matrichnyh-razlozhenij
course: ml
chapter: 9. Рекомендательные системы
chapter_id: 9.2
---
Допустим, мы работаем в сервисе рекомендаций фильмов и перед нами стоит задача подобрать для каждого пользователя набор наиболее релевантных фильмов. Пользователь может разными способами провзаимодействовать с фильмом: посмотреть его, оставить отзыв, поставить оценку (например, от 1 до 5).
В этом параграфе мы будем строить рекомендации на основе матрицы оценок user-item. Её строки соответствуют объектам, а столбцы – пользователям. На
(
i
,
j
)
(i,j)-й позиции матрицы мы ставим либо пропуск, либо оценку, выставленную
i
i-му объекту
j
j-м пользователем. Разумеется, не все оценки нам известны: вряд ли каждый пользователь имел возможность ознакомиться с каждым объектом. В процессе решения задачи мы будем пытаться восстановить оценки на местах пропусков. Сделав это, мы сможем, например, порекомендовать пользователю те объекты, которые он ещё не смотрел, но предсказанная оценка которых для этого пользователя максимальна.
user
Все типы взаимодействия пользователей с объектами мы можем рассматривать как пользовательский фидбек. Обычно различают явный (explicit) и неявный (implicit) виды фидбека. Фидбек называется явным, если он отражает степень интереса пользователя к объекту. Например, к этому типу относят рейтинги, лайки и дизлайки. Такого фидбека обычно мало, он поступает только от тех пользователей, которые соглашаются нам его дать.
Обычно гораздо больше информации имеется о неявных предпочтениях – просмотры, клики, добавление в закладки. Но если пользователь, например, посмотрел фильм, мы ещё не можем сделать вывод, что он ему понравился. Мы можем лишь утверждать, что до просмотра этот фильм казался ему достаточно интересным. Поэтому обычно неявная обратная связь более шумная, чем явная.
Для начала научимся работать с явным фидбеком.
Связь с задачей матричной факторизации
Вернёмся к задаче восстановления матрицы оценок и предположим, что каждый пользователь и объект можно закодировать набором из
S
S скрытых признаков, а оценка
i
i-го объекта
u
u-м пользователем равна скалярному произведению соответствующих векторов скрытых представлений
. Тогда если бы наша матрица оценок была заполнена полностью, её можно было бы представить в виде произведений двух матриц
X
X и
Y
Y, составленных по столбцам из скрытых представлений пользователей и объектов:
U=X
T
⋅Y
Decomp31
Правда, в таком случае нам бы и не требовалось ничего решать: мы могли бы просто рекомендовать пользователю объекты с самыми высокими оценками в соответствующей строке. Но суровая реальность такова, что зачастую матрица оценок сильно разрежена. Мы можем поступить следующим образом: восстановить латентные векторы для пользователей и объектов по имеющемуся набору оценок, после чего предсказать оценки для всех отсутствующих позиций. В параграфе, посвящённом матричной факторизации, мы уже обсуждали способы решения данной задачи с помощью SVD и стохастического градиентного спуска. У SVD есть существенные недостатки: из-за большого количества пропусков в матрице полученное решение будет слишком шумным, а кроме того, его придется каждый раз рассчитывать заново при добавлении новых пользователей или объектов. Градиентный спуск не имеет данных проблем, но тоже не очень практичен. В этом параграфе мы рассмотрим более эффективный алгоритм, называемый Alternating Least Squares (ALS).
Постановка задачи
Пусть, как и раньше,
– скрытые представления пользователей и объектов соответственно размерности
T
T. Запишем эти векторы по строкам в матрицы
X
X и
Y
Y размера
S
×
N
S×N и
S
×
D
S×D соответственно, где
N
N – количество пользователей, а
D
D – количество объектов.
Обозначим через
R
R множество таких пар
(
u
,
i
)
(u,i) пользователей и объектов, для которых имеются явно проставленные оценки.
Предсказывать рейтинги мы будем как скалярное произведение скрытых представлений:
В результате мы приходим к следующей задаче оптимизации. Мы хотим научиться как можно лучше приближать известные рейтинги:
min
min
(u,i)∈R
Добавив регуляризацию получаем следующую функцию потерь:
min
min
(u,i)∈R
∣∣x
∣∣y
i
∣∣
2
C
i
Alternating Least Squares (ALS)
Оптимальные параметры можно найти с помощью хорошо знакомого нам градиентного спуска, но есть более быстрые и надёжные способы. Если мысленно заморозить параметры, соответствующие латентным факторам пользователей, задача оптимизации латентных представлений объектов сведётся к задаче наименьших квадратов, для которой мы знаем точное решение.
Итоговый процесс оптимизации функции потерь будет иметь следующий вид.
В цикле до сходимости:
Фиксируем матрицу
X
X (скрытые представления пользователей);
Решаем задачу L2-регуляризованной регрессии для каждого товара и находим оптимальную матрицу
Y
Y;
Фиксируем матрицу
Y
Y (скрытые представления объектов);
Решаем задачу L2-регуляризованной регрессии для каждого пользователя и находим оптимальную матрицу
X
X;
Решение, получаемое путём попеременного вычисления точных аналитических решений, обычно точнее тех, что получаются с помощью наивного градиентного спуска. Более того, данное решение имеет эффективную реализацию, позволяющую использовать преимущества параллельных вычислений.
Для лучшего понимания распишем каждый шаг данного алгоритма оптимизации:
ALS - шаг по (одному)
x
u
x
u
:
argminxu
argmin
(u,i)∈R
∣∣x
∣∣y
i
∣∣
2
C
i
Раскроем квадратичный член:
argminxu
argmin
(u,i)∈R
∑
r
ui
2
−2
(u,i)∈R
(u,i)∈R
∣∣x
∣∣y
i
∣∣
2
C
i
В первой сумме константы, они уходят. Из второй и третьей возьмём только те слагаемые, в которых участвует
x
u
x
u
. Из четвёртой остается только член с
x
u
x
u
, так как все
x
v
x
v
независимы. Последняя сумма пропадает, так как
независимы:
argminxu
argmin
−2
i:(u,i)∈R
i:(u,i)∈R
+λC
В первой сумме индекс
u
u фиксирован, поэтому
x
u
x
u
можно вынести за знак суммы:
argminxu
argmin
−2x
u
T
(u,i)∈R
(u,i)∈R
+λC
Объединим второй и третий члены формулы, вынесем умножение на
x
u
x
u
за скобки:
argminxu
argmin
−2x
u
T
(
(u,i)∈R
∑
r
ui
y
i
)+x
u
T
(
(u,i)∈R
+λC
u
)x
u
=
Теперь воспользуемся тем, что
argminxu
argmin
−2x
и выпишем ответ:
i:(u,i)∈R
+λC
i
I)
−1
(
j:(i,j)∈R
Таким образом, мы получили аналитическое выражение для вычисления каждого
x
u
x
u
на шаге алгоритма. Отметим, что каждый вектор
x
u
x
u
мы можем вычислить независимо от других
x
v
x
v
. Данное наблюдение позволяет нам использовать всю мощь параллельных вычислений для эффективного решения оптимизационной задачи. Распределив данные так, что на каждой вычислительной машине хранятся все
y
i
y
i
для некоторого подмножества
x
u
x
u
, на одной итерации алгоритма мы можем параллельно вычислить все
x
u
x
u
. На следующей итерации аналогичным образом вычисляем все
y
i
y
i
.
IALS (Implicit ALS)
Оригинальная статья
Раньше мы работали с матрицей
R
R как с матрицей рейтингов, явно проставленных пользователем. Как мы говорили выше, такого фидбека обычно довольно мало, а куда больше неявного фидбека. При этом количество данных может быть критичным при работе с такими разреженными структурами, как матрицы рейтингов, поэтому хочется научиться работать и с неявным фидбеком тоже.
Неявным фидбеком является в том числе и факт взаимодействия, поэтому мы можем заполнить всю матрицу user-item целиком: на тех позициях, где пользователь положительно взаимодействовал с объектом, поставим
1
1, а на тех, где взаимодействие было негативным или его вообще не произошло, поставим
0
0. Эта компонента фидбека называется предпочтением (preference):
или
r
u
i
не определено
≤0 или r
ui
не определено
Тем самым мы избавились от пропусков в матрице, но использовали не всю информацию. Согласитесь, если один пользователь посмотрел часовое видео польностью, а другой выключил после 5 минут, несправедливо считать, что это видео им понравилось в одинаковой степени. Введём ещё степень уверенности (confidence), отражающую уверенность в оценке пользователя:
степень уверенности в
=1+α∣r
ui
∣ ( степень уверенности в p
ui
),
где
α
α – некоторая константа.
На местах пропусков мы явно проставляем
=0. На остальных позициях мы можем сами регулировать степень уверенности в зависимости от фидбека пользователя.
Рассмотрим следующую функцию потерь:
∀u,i
∣∣x
∣∣y
Она позволяет:
Учитывать неявный фидбек, которого обычно на порядок больше, чем явного,
Регулировать степень уверенности в действиях пользователей.
IALS: оптимизация
Распишем нашу функцию потерь по аналогии с ALS и приведем к форме
−2x
argminxu
argminxu
argminxu
argminxi
argmin
u,i
∣∣x
∣∣y
argmin
+λC
argmin
−2x
+λC
argmin
−2x
)+x
+λC
+λC
Разобьём сумму на 2 части. В первой будет сумма по тем элементам, с которыми у пользователя не было положительного взаимодействия. Во второй – сумма по всем остальным элементам. Также заметим, что во втором множителе суммирование имеет смысл только по ненулевым элементам:
∀i:p
∀i:p
+λC
u
I)
−1
(
∀i:p
Заметим, что в первой сумме все
c
u
i
c
ui
будут равны 1 (так как везде
=0). Прибавим и вычтем единицу к
c
u
i
c
ui
во второй сумме и разобьем её на две компоненты. Вторый из них будет сумма по всем
, где
=0. Объединив её с первой суммой, получим
просто
Y+λC
u
I+
∀i:p
−1)y
∀i:p
Заметим, что произведение
Y
T
Y
Y
T
Y никак не зависит от
u
u. Мы можем посчитать его один раз для всех
x
u
x
u
перед очередной итерацией. В остальном же мы точно так же, как и в случае с обычным ALS, можем распределить данные так, чтобы на одной машине содержались все
y
j
y
j
, необходимые для обновления
x
v
x
v
, хранящихся на этой машине, и сделать следующий шаг оптимизации нашей функции потерь.
Обобщения ALS и IALS
Обе модели: и ALS, и Imlicit ALS – можно несколько усложнить, вместо
рассмотрев
+μ. В таком случае
играют роль некоторых априорных усреднённых оценок пользователя и объекта соответственно, а
μ
μ является глобальной априорной константой.
В модели IALS мы обычно полагаем элементы
p
u
i
p
ui
равными
1
1 во всех случаях, когда имело место взаимодействие, но можем использовать и другие значения, в том числе зависящие от того, что ещё нам известно о пользователях и объектах.
Для уверенности
=1+α∥r
ui
∥ для IALS необязательно использовать
1
1 в качестве значения по умолчанию. Например, события «пользователь не посмотрел популярный фильм» и «пользователь не посмотрел редкий фильм» могут иметь для нас разный вес.
FunkSVD
Этот подход получил широкую известность после конкурса Netflix Prize в 2006 году. Пост Саймона Фанка про участие в Netflize Prize
Фанк предложил моделировать рейтинг как
=μ+b
. Однако, в отличие от ALS, оптимизация производилась с помощью стохастического градиентного спуска. Правила обновления весов выглядели следующим образом:
+η(e
ui
y
i
−λx
+η(e
ui
x
u
−λy
+η(e
ui
−λb
+η(e
ui
−λb
i
)
Этот подход не получил большой популярности, так как градиентный спуск, в отличие от ALS, намного сложнее распараллелить.
Singular Value Decomposition with implicit feedback (SVD++)
Оригинальная статья
Ранее мы отдельно рассматривали факторизации для явного и неявного фидбека. Но, ограничиваясь только одним типом фидбека, мы теряем много информации. Если мы работаем над стриминговым сервисом, то в качестве неявного фидбека мы можем взять, например, историю фильмов, взятых в прокат. Такие данные не предоставляют нам явных оценок пользователей, но позволяют выявить неявные предпочтения. Учесть неявный фидбек в модели можно следующим образом:
≈(x
u
+
∣{j∣p
uj

=0}∣
1
∀j:p
В данной модели пользователь представлен скрытым представлением
x
u
x
u
, а также слагаемым, отражающим историю неявных взаимодей с айтемами:
∣{j∣p
uj

=0}∣
1
∀j:p
Важно отметить, что вектора
y
^
j
y
j
не совпадают с векторами
y
i
y
i
. Это своего рода «неявные» вектора айтемов.
Collaborative Filtering with Temporal Dynamics (timeSVD++)
Оригинальная статья
Особенностью всех рассмотренных на данный момент разложений является отсутствие учёта порядка просмотра объектов.
Однако, как показывает практика, со временем пользователь может менять своё мнение о тех или иных айтемах. Тогда, отсортировав взаимодействия по времени, мы можем разбить события на бакеты и модифицировать приведённую выше функцию потерь, в которой таргет выражается следующим образом:
(t)≈(x
u
(t)+
∣{j∣p
uj

=0}∣
1
∀j:p
(t)+b
i
(t)+μ
SLIM (Sparse Linear Methods)
Оригинальная статья
Описанные выше методы демонстрируют хорошее качество, однако требуют больших усилий для эффективной работы в онлайн сервисах. Возникает потребность в лёгких моделях, эффективность которых значительно выше, но качество которых не сильно хуже. Для этого была предложена линейная разреженная модель.
Итак, пусть
A
A – бинарная матрица
N
×
D
N×D user-item взаимодействий, например, матрица кликов/показов. Будем определять ответ алгоритма
a
u
i
a
ui
как взвешивание событий из истории пользователя:
При этом наложим ограничение
≥0. В такой постановке мы будем учить модель находить «похожие» объекты. Добавим ещё условие
=0, которое позволит нам избежать элементарного решения – единичной матрицы
W
=
I
W=I.В результате вес
w
i
j
w
ij
выступает в качестве некоторой меры схожести
i
i-го и
j
j-го объектов. Осталось определиться с методом оптимизации данных параметров.
Для оптимизации используется функция потерь MSE с
L
1
L
1
- и
L
2
L
2
-регуляризаторами:
min
⁡
W
2
1
u,i
i,j
i,j
min
Можно заметить, что задачу можно разбить на
D
D независимых по строкам матрицы
min
,...,w
iD
min
(∀i)
Данную задачу можно решать покоординатным спуском:
Фиксируем все строки
W
W, кроме одной координаты
переходим в оптимум по
переходим к следующей координате;
повторять до сходимости.
Применение данной модели выглядит следующим образом:
Рассчитываем вектор взаимодействий пользователя
i=1
D
;
Считаем
a
t
a
u
i
ata
ui
для всех непросмотренных объектов;
Отбираем топ
k
k непросмотренных объектов по
Так как в задаче оптимизации мы пользуемся
L
1
L
1
-регуляризацией, матрица
W
W получается разреженной. Матрица просмотров
A
A тоже разреженная (по определению). Эти обстоятельства позволяют заметно улучшить эффективность применения модели.
Итоги
В этом параграфе мы рассмотрели некоторые рекомендательные модели на основе матричных факторизаций. Такие модели редко используется в чистом виде для формирования рекомендательной выдачи. Обычно результаты матричной факторизации используются для генерации кандидатов в рекомендации, когда из сотен тысяч и миллионов объектов необходимо отобрать небольшое количество (например, сотни) самых релевантных. Для генерации кандидатов требуется перемножить вектор пользователя с вектором каждого из сотен тысяч объектов и отобрать топ самых релевантных.
В онлайн-сервисах, когда время формирования рекомендаций составляет несколько сотен миллисекунд, нет возможности при каждом запросе рассчитывать релевантность каждого объекта для данного пользователя. Оптимизировать поиск можно с помощью инструментов для поиска ближайших соседей. Для любой функции близости, в том числе и для скалярного произведения, можно построить индекс – структуру данных, с помощью которой для любого пользователя мы сможем быстро приближённо, но зато быстро искать «ближайшие» объекты. В результате, принцип работы выглядит следующим образом:
обучаются эмбеддинги объектов и пользователей;
для представлений эмбеддингов строится индекс;
в рантайме по вектору пользователя происходит приближённый поиск
n
n самых релевантных объектов; таким образом генерируется список кандидатов в рекомендации;
дальше список кандидатов обрабатывается с помощью более хитрых методов машинного обучения.
Подробнее о том, как быстро искать ближайших соседей, вы можете узнать в параграфе посвященном метрическим методам
Помимо генерации кандидатов, полученные представления можно использовать в качестве признаков в более сложных моделях.
Основной недостаток методов, основанных на матричной факторизации, состоит в том, что они используют лишь информацию о взаимодействии пользователей и объектов, но не о них самих. В следующем параграфе мы рассмотрим контентные методы, которые используют атрибуты объектов и пользователей.
Список литературы
Статья про Implicit ALS
Статья про SVD++
Статья про TimeSVD++
Статья про SLIM
Пост Саймона Фанка про участие в конкурсе Netflix Prize
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
9.1. Введение в рекомендательные системы
Следующий параграф
9.3. Контентные рекомендации

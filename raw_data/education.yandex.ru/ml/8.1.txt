---
title: Введение в генеративное моделирование
url: https://education.yandex.ru/handbook/ml/article/vvedenie-v-generativnoe-modelirovanie
course: ml
chapter: 8. Генеративные модели
chapter_id: 8.1
---
До этого вы изучали модели машинного обучения, которые в основном предсказывают какие-то характеристики объектов.Например, метки класса или регрессионные метки. Подобные задачи называют дискриминативным моделированием.
В то же время, существуют обратные задачи, в которых по какой-то характеристике нужно создать объект или оценить плотность распределения объектов. Это называется генеративным моделированием — его нюансы мы и рассмотрим в этом разделе.
Обучение генеративных моделей существенно сложнее обучения дискриминативных моделей. Последние работают с намного более простыми распределениями. Например, предсказать вероятность конкретной цифры, нарисованной на картинке, гораздо проще, чем создать картинку с нужной цифрой. При этом генеративные модели в последние годы достигли невероятных успехов и позволяют генерировать изображения, которые трудно отличить от настоящих фотографий.
generative
Генеративные модели помогают решать множество задач, которые мы рассмотрим далее. Самая основная задача — это приближение распределения данных и генерация новых данных.
Допустим у нас есть набор картинок с нарисованными от руки числами. Будем считать, что мы получили этот набор из генеральной совокупности (то есть из всех возможных изображений). Нам бы хотелось так или иначе смоделировать распределение этой генеральной совокупности.
Мы можем это сделать двумя подходами:
Явное моделирование. В этом случае мы построим и как-то оценим функцию плотности распределения данных
p
(
x
)
p(x). Из этого распределения мы сможем семплировать новые объекты. Примеры таких моделей: авторегрессионные модели (например, PixelCNN++, Video Transformer), диффузионные модели, модели на основе нормализующих потоков и вариационные автокодировщики.
Неявное моделирование. При неявном моделировании мы доступ к функции плотности не получим. Но мы сможем из этого распределения сэмплировать новые объекты. В случае нашего примера с нарисованными числами мы сможем генерировать такие изображения. Примерами таких моделей являются генеративно-состязательные сети.
Рассмотрим дискриминативные и генеративные задачи чуть более формально. При дискриминативном моделировании для объекта
x
x и характеристики
y
y мы обычно хотим получить плотность распределения
p(y∣x).
При генеративном моделировании ставится противоположная задача: восстановить плотность
p
(
x
)
p(x) или
p(x∣y). В качестве
y
y тут может выступать как метка класса, так и другой объект. Например, если мы хотим уметь генерировать изображения на основе текстового описания, то изображения будут являться
x
x, а текст —
y
y.
Интерполяции в латентном пространстве
Большинство моделей генеративного моделирования позволяют семплировать новые объекты. Как правило, в результате обучения генеративной модели мы получаем генератор — функцию, которая на выходе выдаёт объект.
В таких моделях, как генеративные состязательные нейронные сети, диффузионные модели, вариационные автокодировщики, генератор на вход принимает вектор случайных значений из простого вероятностного распределения (например, нормального или равномерного). Получается, что
x=G(z), где
x
x — объект,
G
G — функция генератора, а
z
z — вектор случайных значений. Пространство, в котором располагается
z
z, называется латентным.
Обычно распределение
z
z задаётся ещё до обучения модели и не меняется в процессе. Поскольку мы знаем распределение, мы можем семплировать из него сколько угодно разных
z
z.
Рассмотрим два вектора
из латентного пространства и два соответствующих им сгенерированных объекта
=G(z
=G(z
2
). Так как
— это две точки в латентном пространстве, между ними можно провести линию.
Точки, лежащие на этой линии, будут так же принадлежать этому пространству. Если двигаться по этой линии и использовать точки с неё в качестве входа для генератора, то можно получить плавно изменяющийся сгенерированный объект.
Пример изображений, полученных с помощью интерполяции в латентном пространстве. Источник
В примере выше мы рассмотрели движение вдоль линии, однако на практике интерполяция может быть по более сложной траектории.
Манипуляции с латентным пространством позволяют не только создавать плавные переходы между объектами, но так же редактировать объекты. Обычно в таких случаях требуется найти направления в латентном пространстве, которое отвечает за нужное свойство сгенерированных объектов.
Например, направление, отвечающее за цвет волос или улыбку человека. Подробнее такие методы мы рассмотрим в параграфах про конкретные модели.
Применения генеративных моделей
Зачем может понадобиться генерировать новые данные или восстанавливать их плотность? Самый простой пример – это аугментация набора данных, которая мешает переобучению и улучшает обобщаемость модели.
Простые аугментации данных (случайные сдвиги, повороты, масштабирование, изменения цвета и контраста) активно используются почти во всех методах машинного обучения. Генеративные же модели представляют собой более сложный вид аугментации данных, который способен существенно расширить датасет, или обогатить его совершенно новыми элементами.
Например, генеративную модель, которая переносит стиль одного изображения на другое (style transfer), можно использовать для обучения более робастных моделей классификации. В статье Sandfort et al. используют аугментацию генеративными нейросетями, чтобы улучшить качество сегментации компьютерной томографии.
Помимо этого, у генеративных моделей есть ряд других применений для редактирования изображений. Их используют, чтобы повысить разрешение картинок (задача super-resolution).
На изображении ниже оригинальную картинку (original) сначала сжали в четыре раза, а потом попробовали восстановить до исходных размеров разными методами. Видно, что метод SRGAN, метод на основе генеративных состязательных нейронных сетях работает гораздо лучше бикубической интерполяции (bicubic), которая обычно применяется по умолчанию и смазывает картинку.
ссылка на источник картинки
С помощью генеративных моделей можно закрашивать пропущенные куски изображений. Это полезно, когда мы хотим удалить с фото других людей, и нам нужно закрасить участки, образовавшиеся после их удаления. Эта функция представлена в некоторых современных смартфонах.
ссылка на источник картинки
В последние несколько лет хорошо стали работать модели, которые генерируют изображения на основе их текстового описания. Среди таких моделей:
Stable Diffusion (Демо). Модель с открытым исходным кодом
DALLE 2. Доступ по платному API
Midjourney. Доступ через Discord
Imagen
stable
Примеры генерации изображений из текстового описания. Модель stable diffusion Источник
Появились даже специальные базы изображений, сгенерированных нейронными сетями: Lexica, Openart.
Доступность таких моделей приводит к появлению множества приложений:
Иллюстрации для книг
Создание логотипов
Создание дизайнов помещений
Генерация тату
Кроме этого, некоторые модели позволяют совместить несколько задач и делать закрашивание изображения на основе текстового описания. Например, удалять какую-то область и говорить модели, что там должно быть нарисовано.
Пример закрашивания части изображения на основе текстового описания. Источник
На основе этой технологии появились редакторы изображений с генеративными моделями внутри: Neural love, Photoroom, ZMO.
Современные генеративные модели достигли очень хорошего качества и уже стали использоваться в реальных задачах, о которых мы вам рассказали. В следующих параграфах этой главы мы рассмотрим основные методы генеративного обучения более детально.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
7.2. Дистилляция знаний
Следующий параграф
8.2. Variational Autoencoder (VAE)

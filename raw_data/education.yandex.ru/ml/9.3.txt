---
title: Контентные рекомендации
url: https://education.yandex.ru/handbook/ml/article/kontentnye-rekomendacii
course: ml
chapter: 9. Рекомендательные системы
chapter_id: 9.3
---
Все рекомендательные системы можно поделить на три типа в зависимости от того, какую информацию они используют для построения рекомендаций:
Контентные;
Коллаборативые;
Гибридные.
В данном разделе мы подробнее рассмотрим основные алгоритмы построения контентных рекомендаций.
Основная идея контентных рекомендаций состоит в том, что для их построения будут использоваться атрибуты объектов и пользователей. На основе данных атрибутов мы можем найти релевантные данному пользователю объекты и рекомендовать их.
Представим, например, что мы работаем в музыкальном онлайн-сервисе и хотим подбирать наиболее релевантную музыку нашим пользователям. Допустим у нас есть пользователь Иван, который интересуется русским роком. Тогда наша система может рекомендовать Ивану музыку этого или подобных жанров.
Можно придумать много различных атрибутов трека: жанр, автор, год выхода, продолжительность и так далее. Также можно использовать дополнительную информацию о пользователе: возраст, уровень дохода и тому подобные.
Какими бывают контентные признаки
Допустим, мы работаем в музыкальном сервисе. Тогда в качестве признаков объектов можно использовать:
Стандартные статистики объекта: количество лайков, кликов, полных прослушиваний;
Признаки автора: количество слушателей, жанр;
Неструктурированные данные: названия треков, обложки альбомов или даже предобученные эмбеддинги треков целиком.
В качестве признаков пользователей можно использовать:
Информацию про пользователя, если она нам доступна: возраст, пол, язык, насколько долго пользуется сервисом;
Информацию про контекст запроса: с какого устройства был сделан, в какое время.
Информацию про друзей пользователя и их взаимодействия. Например, усреднённый эмбеддинг всех треков, которые слушал каждый из друзей. Или же можно обучить RNN или Transformer на истории и результат конкатенировать к остальным признакам.
Факторизационные машины
Начнём с постановки задачи. Пусть I – множество объектов (айтемов), U - множество пользователей. Для каждой пары объект-пользователь построим вектор размерности
∣U∣+∣I∣ взаимодействия этой пары, в котором единицы стоят на месте соответствующих пользователя и объекта:
one
Предсказывать будем пользовательские рейтинги объектов
a
(
x
)
a(x).
Можно рассмотреть простейшую регрессионную модель:
a(x)=w
0
+
t=1
∑
∣U∣+∣I∣
w
t
x
t
Заметим, что к этой модели легко добавить любые фичи объектов, пользователей или пар объект-пользователь:
factorization
Дальше будем обозначать через
n
n общее число фичей. Модель можно обогатить признаками, отвечающими за взаимодействия второго порядка:
a(x)=w
0
+
t=1
r=1
∑
n
s=r+1
Матрицу
W=(w
rs
) можно считать симметричной: в любом случае, мы используем только её верхний треугольник.
Из-за использования попарных взаимодействий пользователей и объектов в полученной модели будет
n(n+1)
+n+1 параметр, и так как
n⩾∣U∣+∣I∣ может быть очень большим, работать с такой моделью может оказаться непросто.
Для решения этой проблемы можно использовать следующий трюк. Сопоставим каждому признаку
x
t
x
t
вектор
для некоторого не очень большого
k
k и представим модель в виде:
a(x)=w
0
+
t=1
r=1
∑
n
s=r+1
Таким образом, мы заменяем симметричную матрицу коэффициентов
W
W на её низкоранговое приближение
V
T
V
V
T
V, где
V
V – матрица
n
×
k
n×k с векторами
v
i
v
i
по столбцам. Число параметров модели при этом можно снизить до
nk+n+1. На практике матрица
W
W разреженная, и, как правило, даже при небольшом
k
k получается её неплохо приблизить. В то же время, при небольших
k
k модель обладает лучшей обобщающей способностью.
Вычислить
r=1
n
∑
s=1
по можно за
O
(
n
k
)
O(nk):
r=1
∑
n
s=r+1
r=1
∑
n
s=1
r=1
r=1
∑
n
s=1
∑
n
f=1
r=1
∑
n
f=1
f=1
∑
k
(
r=1
)⋅(
s=1
r=1
f=1
∑
k
((
r=1
r=1
Итоговая модель имеет вид
a(x)=w
0
+
r=1
r=1
r=1
∑
n
∣∣v
Данная модель и называется факторизационной машиной.
Первоначально факторизационные машины использовали только коллаборативный сигнал, но, как мы уже видели, в такую модель можно естественным образом добавить и контентную информацию.
Факторизацонную машину можно обучать для решения разных задач. Например:
Предсказание рейтинга. Ответ модели
a
(
x
)
a(x) можно интерпретировать, как вещественный рейтинг, и решать задачу регрессии.
Бинарную классификацию рекомендовать/не рекомендовать. Тогда
a
(
x
)
a(x) имеет смысл логита, и мы можем оптимизировать оптимизировать log loss или hinge loss.
Ранжирование объектов. Тогда
a
(
x
)
a(x) – это ранжирующая функция.
Модель обычно обучается градиентным спуском.
FFM – Field-aware Factorization Machines
Оригинальная статья
Статья про практическое применение
Как следующий этап развития факториационных машин, появилась идея иметь несколько различных латентных представлений для каждой из фичей.
Пример: есть три разных по своей природе признака: год выпуска, цвет и марка автомобиля. В факторизационной машине для учёта взаимодействия год-цвет и год-марка используется один и тот же вектор для года. Но так как эти признаки разные по смыслу, то и характер их взаимодействия может отличаться.
Идея: использовать 2 разных вектора для признака «год выпуска» при учёте взаимодействий год-цвет и год-марка. Таким образом, модель принимает вид:
a(x)=w
0
+
t=1
r=1
∑
n
s=r+1
∑
m
<v
r,s
,v
s,r
>x
r
x
s
FFM
Авторы статьи выложили исходный код своей библиотеки libffm, с помощью которой они смогли войти в топ-3 сразу в трёх соревнованиях на kaggle (Criteo, Avazu, Outbrain). Подробнее об этом можно почитать вот тут.
DSSM (deep sematic similiarity model)
Теперь рассмотрим ещё одну популярную модель, которая использует контентную информацию для построения рекомендаций – DSSM.
Оригинальная статья
В оригинальной статье DSSM была использована для нахождения «схожести» между поисковым запросом и документом. Для этого она использовала текст запроса и текст документа.
DSSM представляет из себя «двуногую» (two-tower) нейронную сеть. В исходной постановке на первый вход подаётся текст запроса, а на второй – текст документа. Далее, независимо для текста запроса и текста документа строятся эмбеддинги. Итоговая «схожесть» вычисляется, как косинусная мера близости между ними.
На схеме ниже Q – это запрос (query), а D – документ (document).
DSSM
Некоторые авторы пытались в качестве меры близости рассматривать вместо косинусной меры обучаемый MLP, но это оказалось гиблой идеей.
Эта архитектура оказалась крайне удобной при использовании на практике, так как эмбеддинги пользователя и объекта можно предподсчитать независимо и дальше хранить сразу готовые представления для них, а при запросе к рекомендациям просто пересчитывать меру близости, что ускоряет применение модели.
Данная идея хорошо обобщается на построение рекомендаций. Поиск релевантных объектов можно представить, как задачу ранжирования, где вместо текстов запроса и документа мы будем иметь некоторую контентную информацию о пользователе и объекте.
Обучение DSSM
Давайте считать, что мы для каждого запроса
q
q предсказываем один релевантный документ.
Обозначим через
построенные моделью эмбеддинги запроса
q
q и документа
d
d соответственно. Будем вычислять условную вероятность клика по документу
d
d при условии запроса
q
q следующим образом:
exp
exp
P(d∣q)=
∑
i=1
D
exp(b
0
R(q,d
i
))
exp(b
0
R(q,d))
где
cos
R(q,d)=cos(y
q
,y
d
)=
∣∣y
q
∣∣⋅∣∣y
Здесь
b
0
b
0
– коэффициент сглаживания, который подбирается эмпирически, а
D
D – число всех документов.
Если в качестве функции потерь мы выбираем кросс-энтропию, то на паре запрос-кликнутый документ
(q,d
+
) она принимает вид
L(q,d
+
)=−log(P(d
+
∣q)).
Но вычислять градиент такого функционала для каждого примера дорого, ведь для этого придётся для каждого запроса находить вероятность клика по всем документам. Что же делать? На помощь приходит negative sampling. Заметим, что среди документов
d
d в знаменателе
P(d∣q) есть лишь один кликнутый, а остальные тысячи и миллионы являются отрицательными примерами. Есть смысл на каждом шаге оптимизации рассматривать не все из них, а только небольшую выборку, вместо полной суммы
∑
i
=
1
D
exp
i=1
∑
D
exp(b
0
R(q,d
i
))
беря
exp
exp
exp(b
0
R(q,d
+
))+
i=1
∑
k
exp(b
0
R(q,d
i
−
)),
где
,…,d
k
−
– подобранные для запроса
q
q негативные примеры. Генерировать их можно по-разному; на практике чаще всего используют одну из следующих стратегий:
Равновероятно выбирать подмножество документов из некликнутых. В оригинальной статье предлагают брать позитивные и негативные в соотношении
4
:
1
4:1.
С большей вероятностью выбирать те из некликнутых документов, популярность которых выше.
На каждой эпохе обучения выбирать некликнутые документы, получившие максимальный скор для этого запроса на предыдущей эпохе.
Другие функции потерь
Pairwise loss
Задачу построения рекомендаций можно решать, как задачу ранжирования. Например, это можно делать с помощью попарного лосса. А именно, рассмотрим пару объектов, в которой
i
1
i
1
– релевантный, а
i
2
i
2
не релевантный для пользователя
u
u. Тогда мы можем использовать один из двух вариантов функции потерь:
CrossEntropy
(
1.0
L(R(u,i
1
),R(u,i
2
))=CrossEntropy(1.0,σ(R(u,i
1
)−R(u,i
2
))). Тем самым модель будет учиться ранжировать положительные примеры выше отрицательных.
max
L(R(u,i
1
),R(u,i
2
))=max(0,α−R(u,i
1
)+R(u,i
2
)) (triplet loss). При этом модель обучается так, чтобы положительный и отрицательный примеры как можно больше отличались. Эта функция потерь довольно популярна не только в DSSM сетках, но и в целом в задачах, где нужно обучить парные представления
) объектов
(
q
,
d
)
(q,d) из разных доменов так, чтобы для релевантных друг другу
q
q и
d
d эмбеддинги оказывались близкими, а для не релевантных далёкими.
Full Product Softmax loss
Рассмотрим батч
),…,(u
M
,i
M
,r
M
) размера
M
M, где
u
t
u
t
– пользователь,
i
t
i
t
– пользователю, а
r
t
r
t
– таргет, степень релевантности объекта пользователю. Построим по ним:
матрицу эмбеддингов пользователей
U∈R
M×D
;
матрицу эмбеддингов объектов
W∈R
M×D
;
вектор таргетов
r
∈
R
M
r∈R
M
.
Рассмотрим матрицу
softmax
softmax(αUW
T
+β),UW
T
∈R
M×M
,
где softmax берётся по строкам
DSSM
Рассмотрим функцию потерь вид
log
⁡
(
diag
(
softmax
L=−I{r>0}
T
⋅log(diag(softmax(αUW
T
+β)))
Эта функция потерь старается сделать так, чтобы для релевантных друг другу (с
r
>
0
r>0) пар
(
u
,
i
)
(u,i) скалярное произведение эмбеддингов
⟩ было максимальным.
Трансформеры для рекомендаций
В 2018 году появилась архитектура трансформеров на основе механизма внимания. Модели на основе трансформеров показали state-of-the-art результаты на большом числе NLP задач, а впоследствии оказалось, что они отлично подходят и для задач компьютерного зрения. С их помощью можно решать и задачи рекомендаций. Аналогия заключается в следующем: если в NLP трансформеры работают с последовательностями токенов, то в рекомендациях в качестве последовательности можно взять историю событий пользователя. Каждый элемент последовательности – это взаимодействие пользователя с объектом, например, клик на объект.
Классические модели рекомендаций часто игнорируют тот факт, что история пользователя – это направленная последовательность, в которой порядок событий имеет значение. Трансформеры позволяют учитывать как порядок событий, так и сложные паттерны в поведении и интересах пользователя. Например, исследователи из Alibaba представили модель, которую назвали Behaviour Sequence Transformer. Авторы заявляют, что модель используется в продакшене. Модель решает задачу Click Through Rate (CTR) prediction – предсказание вероятности клика по объекту.
transformer
На вход модели подается история кликов пользователя, на основе которой нужно предсказать вероятность клика по заданному объекту. Роль архитектуры трансформера здесь в том, чтобы качественно закодировать представление пользователя, после чего применяется обычный multi layer perceptron (MLP) для предсказания вероятности.
Помимо архитектур, которые специально разрабатываются под задачи рекомендаций, трансформеры можно использовать и как обособленные предобученные модели для построения векторых представлений текстов или изображений, которые затем подаются как признаки для решения downstream задач в домене рекомендаций. Несмотря на очевидные преимущества трансформеров с точки зрения качества, их использование в продакшене часто ограничивается имеющимися вычислительными ресурсами. Это особенно актуально для рекомендаций, где модели важно применять непосредственно в момент запроса пользователя.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
9.2. Рекомендации на основе матричных разложений
Следующий параграф
9.4. Хорошие свойства рекомендательных систем

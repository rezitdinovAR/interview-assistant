---
title: Вероятностный подход в ML
url: https://education.yandex.ru/handbook/ml/article/veroyatnostnyj-podhod-v-ml
course: ml
chapter: 4. Вероятностные модели
chapter_id: 4.1
---
Как описать привычные модели на языке статистики. Оптимизация функции потерь vs оценка максимального правоподобия
В этом разделе мы посмотрим на те же самые модели машинного обучения, но с другой стороны: будем интерпретировать их как вероятностные.
В первом параграфе мы расскажем, как обращаться с вероятностными моделями, и покажем, что привычный вам подбор параметров модели с помощью минимизации функции потерь соответствует подбору параметров методом максимального правдоподобия. Это даст возможность транслировать в мир ML известные результаты о свойствах оценок максимального правдоподобия, но в то же время и обнажит их недостатки. Благодаря этому мы сможем по-новому взглянуть на логистическую регрессию и с новым пониманием сформулировать её обобщение — generalized linear model (GLM).
По ходу дела мы обнаружим, что большинство классификаторов, хоть и делают вид, что предсказывают корректные вероятности, на самом деле вводят в заблуждение.
В третьем параграфе мы поговорим о том, как проверить отклонение предсказанных значений от истинных вероятностей и как поправить ситуацию.
Далее мы обсудим генеративный подход к классификации и разберём несколько примеров генеративных моделей, после чего перейдём к байесовскому подходу оценивания параметров, который, хоть зачастую и трудно осуществим вычислительно, однако обладает большей теоретической стройностью. Он позволяет оценивать распределение параметров и предсказаний (например, уверенность в нашей оценке), а кроме того — даёт нам возможность измерить качество модели, не прибегая к проверке на тестовой выборке.
Если вы готовы — давайте приступим!
Случайность как источник несовершенства модели
Практически любая наша модель — несовершенна. Но объяснять это несовершенство можно по-разному.
Представим, что мы решаем задачу регрессии
y≃⟨x,w⟩: например, пытаемся по университетским оценкам выпускника предсказать его годовую зарплату. Ясно, что точная зависимость у нас не получится как минимум потому, что мы многого не знаем о выпускнике: куда он пошёл работать, насколько он усерден, как у него с soft skills и так далее. Как же нам быть?
Первый вариант — просто признать, что мы не получим идеальную модель, но постараться выучить оптимальную, насколько это возможно. То есть приблизить таргет предсказаниями наилучшим образом с точки зрения какой-то меры близости, которую мы подберём из экспертных соображений.
Так мы получаем простой инженерный подход к машинному обучению: есть формула, в которой присутствуют некоторые параметры (
w
w), есть формализация того, что такое «приблизить» (функция потерь) — и мы бодро решаем задачу оптимизации по параметрам.
Второй вариант — свалить вину за неточности наших предсказаний на случайность. В самом деле: если мы что-то не можем измерить, то для нас это всё равно что случайный фактор. В постановке задачи мы заменяем приближённое равенство
y≃⟨x,w⟩ на точное
искажённое шумом
ε
)
y=(⟨x,w⟩, искажённое шумом ε)
Например, это может быть аддитивный шум (чаще всего так и делают):
y=⟨x,w⟩+ε
где
ε
ε — некоторая случайная величина, которая представляет этот самый случайный шум. Тогда получается, что для каждого конкретного объекта
x
i
x
i
соответствующий ему истинный таргет — это сумма
,w⟩ и конкретной реализации шума
ε
ε.
При построении такой модели мы можем выбирать различные распределения шума, кодируя тем самым, какой может быть ошибка. Чаще всего выбирают гауссовский шум:
ε∼N(0,σ
2
) с некоторой фиксированной дисперсией
σ
2
σ
2
— но могут быть и другие варианты.
Проиллюстрируем, как ведут себя данные, подчиняющиеся закону
y=ax+b+ε,
ε∼N(0,σ
2
):
9
Вопрос на подумать. Зачем человеку может прийти в голову предположить, что в модели линейной регрессии
y∼Xw+ε шум
ε
ε имеет распределение Лапласа? А распределение Коши? Чем свойства таких моделей будут отличаться от свойств модели с нормальным шумом?
Как вы могли заметить, в каждом из подходов после того, как мы зафиксировали признаки (то есть координаты
x
i
x
i
), остаётся своя степень свободы: в инженерном это выбор функции потерь, а в вероятностном — выбор распределения шума.
Дальше в этом параграфе мы увидим, что на самом деле эти два подхода глубинным образом связаны между собой, причём выбор функции потерь — это в некотором смысле то же самое, что выбор распределения шума.
Условное распределение на таргет, непрерывный случай
Допустим, что мы исследуем вероятностную модель таргета с аддитивным шумом
y=f
w
(x)+ε,
где
f
w
f
w
— некоторая функция, не обязательно линейная с (неизвестными пока) параметрами
w
w, а
ε
ε — случайный шум с плотностью распределения
ε∼p
ε
(t). Для каждого конкретного объекта
x
i
x
i
значение
) — это просто константа, но для
y
i
y
i
оно превращается в случайную величину, зависящую от
x
i
x
i
(и ещё от
w
w, на самом деле).
Таким образом, можно говорить об условном распределении
(y∣x,w)
Для каждого конкретного
w распределение соответствующего
y
i
y
i
— это просто
(y−f
w
(x
i
)), ведь
y−f
w
(X)=ε.
Пример. Рассмотрим вероятностную модель
y=⟨x,w⟩+ε, где
ε∼N(0,σ
2
). Тогда для фиксированного
x
i
x
i
имеем
=⟨x
i
,w⟩+ε. Поскольку
,w⟩ — константа, мы получаем
∼N(⟨x
i
,w⟩,σ
2
).
Это можно записать и так:
p(y
i
∣x
i
,w)∼N(y
i
∣⟨x
i
,w⟩,σ
2
),
где выражение справа — это значение функции плотности нормального распределения с параметрами
,w⟩,σ
2
в точке
y
i
y
i
. В частности,
,w⟩=E(y
i
∣x
i
).
Более сложные вероятностные модели
На самом деле, мы можем для нашей задачи придумывать любую вероятностную модель
(y∣x,w), не обязательно вида
y=f
w
(X)+ε.
Представьте, что мы хотим предсказывать точку в плоскости штанг, в которую попадает мячом бьющий по воротам футболист. Можно предположить, что она имеет нормальное распределение со средним (цель удара), которое определяется ситуацией на поле и состянием игрока, и некоторой дисперсией (то есть скалярной ковариационной матрицей), которая тоже зависит от состояния игрока и ещё разных сложных факторов, которые мы объявим случайными.
Состояние игрока — это сложное понятие, но, вероятно, мы можем выразить его, зная пульс, давление и другие физические показатели. В свою очередь, ситуацию на поле можно описать, как функцию от позиций и движений других игроков, судьи и зрителей — но всего не перечислишь, поэтому нам снова придётся привлекать случайность. Таким образом, мы получаем то, что называется графической моделью:
9
Здесь стрелки означают статистические зависимости, а отсутствие стрелок — допущение о статистической независимости. Конечно же, это лишь допущение, принятое нами для ограничения сложности модели: ведь пульс человека и давление взаимосвязаны, равно как и поведение различных игроков на поле. Но мы уже обсуждали, что каждая модель, в том числе и вероятностная, является лишь приблизительным отражением бесконечно сложного мира. Впрочем, если у нас много вычислительных ресурсов, то никто не мешает нам попробовать учесть и все пропущенные сейчас зависимости.
Расписав всё по определению условной вероятности, мы получаем следующую вероятностную модель:
9
в которой, конечно же, мы должны все вероятности расписать через какие-то понятные и логически обоснованные распределения — но пока воздержимся от этого.
Оценка максимального правдоподобия = оптимизация функции потерь
Мы хотим подобрать такие значения параметров
w
w, для которых модель
(y∣x,w) была бы наиболее адекватна обучающим данным. Суть метода максимального правдоподобия (maximum likelihood estimation) состоит в том, чтобы найти такое
w
w, для которого вероятность (а в данном, непрерывном, случае плотность вероятности) появления выборки
y={y
1
,…,y
N
} была бы максимальной, то есть
argmax⁡w
MLE
=
w
argmax
p(y∣X,w)
Величина
p(y∣X,w) называется функцией правдоподобия (likelihood). Если мы считаем, что все объекты независимы, то функция правдоподобия распадается в произведение:
p(y∣X,w)=p(y
1
∣x
1
,w)⋅…⋅p(y
i
∣x
i
,w)
Теперь, поскольку перемножать сложно, а складывать легко (и ещё поскольку мы надеемся, что раз наши объекты всё-таки наблюдаются в природе, их правдоподобие отлично от нуля), мы переходим к логарифму функции правдоподобия:
log
log
l(y∣X,w)=logp(y
1
∣x
1
,w)+…+logp(y
i
∣x
i
,w)
эту функцию мы так или иначе максимизируем по
w
w, находя оценку максимального правдоподобия
w
^
w
^
.
Как мы уже обсуждали выше,
p(y
i
∣x
i
,w)=p
ε
(y−f
w
(x
i
)), то есть
log
l(y∣X,w)=
i=1
∑
N
logp
Максимизация функции правдоподобия соответствует минимизации
log
i=1
∑
N
[−logp
))]
а это выражение можно интерпретировать, как функцию потерь. Вот и оказывается, что подбор параметров вероятностей модели с помощью метода максимального правдоподобия — это то же самое, что «инженерная» оптимизация функции потерь. Давайте посмотрим, как это выглядит в нескольких простых случаях.
Пример. Давайте предположим, что наш таргет связан с данными вот так:
=⟨x
i
,w⟩+ε
где
ε∼N(0,σ
2
), то есть
exp
p(ε)=
2πσ
2
1
exp(−
2σ
2
ε
2
)
Случайная величина
y
i
y
i
получается из шума
ε
ε сдвигом на постоянный вектор
,w⟩, так что она тоже распределена нормально с той же дисперсией
σ
2
σ
2
и со средним
,w⟩
exp
p(y
i
∣⟨x
i
,w⟩)=
2πσ
2
1
exp(−
2σ
2
(y
i
−⟨x
i
,w⟩)
2
)
Правдоподобие выборки имеет вид
exp
p(y∣X,w)=
i=1
∏
N
p(y
i
∣x
i
,w)=
i=1
∏
N
2πσ
2
1
exp(−
2σ
2
(y
i
−⟨w,x
i
⟩)
2
)
Логарифм правдоподобия можно переписать в виде
log
l(y∣X,w)=
i=1
∑
N
(−log(
2πσ
−⟨w,x
i
⟩)
2
)
Постоянными слагаемыми можно пренебречь, и тогда оказывается, что максимизация этой величины равносильна минимизации
i=1
∑
N
(y
i
−⟨w,x
i
⟩)
2
Мы получили обычную квадратичную функцию потерь. Итак, обучать вероятностную модель линейной регрессии с нормальным шумом — это то же самое, что учить «инженерную» модель с функцией потерь MSE.
Вопрос на подумать. Какая вероятностная модель соответствует обучению линейной регрессии с функцией потерь MAE
i=1
∑
N
∣y
i
−⟨w,x
i
⟩∣?
Предсказание в вероятностных моделях
Теперь представим, что параметры подобраны, и подумаем о том, как же теперь делать предсказания.
Рассмотрим модель линейной регрессии
y=⟨x,w⟩+ε,ε∼N(0,σ
2
)
Если
w
w известен, то для нового объекта
x
0
x
0
соответствующий таргет имеет вид
=⟨x
0
,w⟩+ε∼N(⟨x
0
,w⟩,σ
2
)
Таким образом,
y
0
y
0
дан нам не точно, а в виде распределения (и логично: ведь мы оговорились выше, что ответы у нас искажены погрешностью, проинтерпретированной, как нормальный шум). Но что делать, если требуют назвать конкретное число? Кажется логичным выдать условное матожидание
E(y
0
∣x
0
)=⟨x
0
,w⟩, тем более что оно совпадает с условной медианой и условной модой этого распределения.
Если же медиана, мода и математическое ожидание различаются, то можно выбрать что-то из них с учётом особенностей задачи. Но на практике в схеме
y∼f(x)+ε чаще всего рассматривают именно симметричные распределения с нулевым матожиданием, потому что для них
f
(
x
)
f(x) совпадает с условным матожиданием
E(y∣x) и является логичным точечным предсказанием.
Приведём пример. Допустим шум
ε
ε был бы из экспоненциального распределения. Тогда
f
(
x
)
f(x) была бы условным минимумом распределения. В принципе, можно придумать задачу, для которой такая постановка (предсказание минимума) была бы логичной. Но это всё же довольно экзотическая ситуация. Приводим для сравнения модели с нормальным, лапласовским и экспоненциальным шумом:
9
Условное распределение на таргет, дискретный случай
Допустим, мы имеем дело с задачей классификации с
K
K классами. Как мы можем её решать? Самый наивный вариант — научиться по каждому объекту
x
i
x
i
предсказывать некоторое число для каждого класса, и у кого число больше — тот класс и выбираем! Наверное, так можно сделать, если мы придумаем хорошую функцию потерь. Но сразу в голову приходит мысль: почему бы не начать предсказывать не просто число, а вероятность?
Таким образом, задача классификации сводится к предсказанию
P(y
i
=k∣x
i
)
и как будто бы выбору класса с наибольшей вероятностью. Впрочем, как мы увидим дальше, всё не всегда работает так просто.
Одну такую модель — правда, только для бинарной классификации — вы уже знаете. Это логистическая регрессия:
P(y
i
=1∣x
i
,w)=
1+e
−⟨x
i
,w⟩
1
,P(y
i
=0∣x
i
,w)=
1+e
−⟨x
i
,w⟩
e
−(x
i
,w)
=
1+e
⟨x
i
,w⟩
1
которую также можно записать в виде
∼Bern(
1+e
−⟨x
i
,w⟩
1
)
где
Bern(p) — распределение Бернулли с параметром
p
p.
Нахождение вероятностей классов можно разделить на два этапа:
Находим
x
i
→
логиты
Находим
x
i
логиты
(−⟨x
i
,w⟩,⟨x
i
,w⟩)
σ
(σ(−⟨x
i
,w⟩),σ(⟨x
i
,w⟩))
где, напомним,
σ
σ — это сигмоида:
σ(t)=
1+e
−t
1
Сигмоида тут не просто так. Она обладает теми счастливыми свойствами, что
монотонно возрастает;
отображает всю числовую прямую на интервал
(
0
,
1
)
(0,1);
σ(−x)=1−σ(x).
Вот такой вид имеет её график:
9
Иными словами, с помощью сигмоиды можно делать «вероятности» из чего угодно, то есть более или менее для любого отображения
f
w
f
w
(из признакового пространства в
R
R) с параметрами
w
w построить модель бинарной классификации:
P(y
i
=0∣x
i
,w)=σ(f
w
(−x
i
)),P(y
i
=1∣x
i
,w)=σ(f
w
(x
i
)).
Как и в случае логистической регрессии, такая модель равносильна утверждению о том, что
log
)=log
p(y=0∣x
i
,w)
p(y=1∣x
i
,w)
.
Похожим способом можно строить и модели для многоклассовой классификации. В этом нам поможет обобщение сигмоиды, которое называется softmax:
softmax(t
1
,…,t
K
)=(
∑
k=1
,…,
∑
k=1
А именно, для любого отображения
f
w
f
w
из пространства признаков в
R
K
R
K
мы можем взять модель
(P(y
i
=k∣x
i
,w))
k=1
K
=softmax(f
w
(x
i
))
Если все наши признаки — вещественные числа, а
)=x
i
W — просто линейное отображение, то мы получаем однослойную нейронную сеть
(P(y
i
=k∣x
i
,w))
k=1
K
=softmax(x
i
W)
9
Предостережение. Всё то, что мы описали выше, вполне работает на практике (собственно, классификационные нейросети зачастую так и устроены), но корректным не является.
В самом деле, мы говорим, что строим оценки вероятностей
P(y
i
=k∣x
i
,w), но для подбора параметров используем не эмпирические вероятности, а только лишь значения
argmax⁡k
argmax
P(y
i
=k∣x
i
,w), то есть метки предсказываемых классов. Таким образом, при обучении мы не будем различать следующие две ситуации:
9
Это говорит нам о некоторой неполноценности такого подхода.
Заметим ещё вот что. В случае бинарной классификации выбор предсказываемого класса как
argmax⁡k
argmax
P(y
i
=k∣x
i
,w) равносилен выбору того класса, для которого
P(y
i
=k∣x
i
,w)>
2
1
. Но если наши оценки вероятностей неадекватны, то этот вариант проваливается, и мы встаём перед проблемой выбора порога: каким должно быть значение
t
^
t
, чтобы мы могли приписать класс 1 тем объектам
x
i
x
i
, для которых
σ(f
w
(x
i
))>
t
?
В одном из следующих параграфов мы обсудим, как всё-таки правильно предсказывать вероятности.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
3.3. Подбор гиперпараметров
Как эффективно подбирать значения гиперпараметров модели и не переобучиться при этом
Следующий параграф
4.2. Экспоненциальный класс распределений и принцип максимальной энтропии
Самые главные семейства распределений в жизни любого data scientist’а

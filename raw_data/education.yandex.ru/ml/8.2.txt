---
title: Variational Autoencoder (VAE)
url: https://education.yandex.ru/handbook/ml/article/variational-autoencoder-(vae)
course: ml
chapter: 8. Генеративные модели
chapter_id: 8.2
---
В машинном обучении есть довольно широкая область, посвящённая обучению генеративных моделей. Их задача — выучить распределение, из которого могли бы быть насемплированы объекты обучающей выборки.
Обученная генеративная модель способна семплировать из выученного распределения новые объекты, не принадлежащие исходным данным. Чаще всего это связано с задачей генерации новых изображений: от изображений рукописных чисел до замены лиц на видео с помощью deepfake.
Модель, о которой пойдёт речь в данном параграфе, называется «Вариационный автоэнкодер» или VAE (variational autoencoder). Она относится к семейству генеративных моделей. Коротко расскажем, что вас ждёт дальше.
В разделах «Постановка задачи» и «Обучение VAE» мы опишем построение и обучение VAE в классическом описании. Этих двух разделов достаточно для общего представления о VAE.
Раздел «Обзор статей» для первоначального понимания не обязателен, но может быть интересен тем, кто захочет узнать о недавних интересных работах, связанных с VAE.
Прежде чем двинуться дальше — небольшое напоминание: большинство картинок в тексте кликабельны, и при клике вы сможете перейти к источнику, из которого была заимствована картинка.
Постановка задачи
Давайте представим себе, что нам нужно нарисовать лошадь. Как бы мы это сделали?
Наверное, сначала наметили бы общий силуэт лошади, её размер и позу, а затем стали бы добавлять детали: гриву, хвост, копыта, выбирать окраску шерсти и так далее. Кажется, что в процессе обучения рисованию мы учимся выделять для себя основной набор каких-то факторов, наиболее важных для генерации нового изображения: общий силуэт, размер, цвет и тому подобное, а во время рисования уже просто подставляем какие-то значения факторов.
При этом одинаковые сочетания одних и тех же факторов могут привести к разным картинкам — ведь нарисовать что-то два раза абсолютно одинаково вы, скорее всего, не сможете.
Попробуем формализовать описанный выше процесс. Пусть у нас есть датасет
D
D в многомерном пространстве исходных данных
X
N
X
N
, — объектов, которые мы желаем генерировать, — и пространство
Z
M
Z
M
скрытых (латентных) переменных меньшей размерности, которыми кодируются скрытые факторы в данных. Тогда генеративный процесс состоит из двух последовательных стадий (см. картинку ниже):
Семплирование
z
∈
Z
M
z∈Z
M
из распределения
p
(
z
)
p(z) (красное)
Семплирование
x
∈
X
N
x∈X
N
из распределения
p(x∥z) (синее)
1.
То есть, рассуждая в терминах рисования картинок с лошадками, мы сначала мысленно семплируем некоторое
z
z (размер, форму, цвет, ...), затем дорисовываем все необходимые детали, то есть семплируем из распределения
p(x∥z), и в итоге надеемся, что получившееся будет напоминать лошадку.
Таким образом, построить генеративную модель в нашем случае — значит уметь семплировать с помощью описанного двустадийного процесса объекты, близкие к объектам из обучающей выборки
D
D.
Говоря более формально, нам бы хотелось, чтобы наша модель максимизировала правдоподобие
p
(
x
)
p(x) элементов обучающего множества
D
D при описанной процедуре генерации:
max
⁡
p(x)=
Z
M
∫
p(x∣z)p(z)dz→max
Предположим, что совместное распределение
p(x,z) параметризовано некоторым параметром
θ
∈
Θ
θ∈Θ и выражается непрерывной по
θ
θ функцией при каждых фиксированных
x
x и
(x,z)=p(x,z∣θ)∈C(Θ)
Тогда
(x,z)=p(x∣z,θ)p(z∣θ)=p
θ
(x∣z)p
θ
(z),
и мы можем записать следующую задачу оптимизации:
max
(x)=
Z
M
∫
p
θ
(x∣z)p
θ
(z)dz→
θ∈Θ
max
(1)
Решив её, мы построим нашу генеративную модель.
Замечание 1. После приведённой выше аналогии с обучением рисованию может ошибочно показаться, что в скрытые переменные всегда заложен некоторый хорошо интерпретируемый смысл. Но на практике это всё же не обязано быть так: те скрытые переменные, которые мы найдём, могут как иметь простую интерпретацию, так и не иметь. С помощью объяснений выше мы прежде всего хотели проиллюстрировать понятие «скрытые переменные».
Замечание 2. Может показаться, что
p
(
x
)
p(x) нам откуда-то уже известно, и тогда не ясно, зачем все эти сложности с введением латентных переменных и интегралами. На самом деле, мы действительно можем построить статистическую оценку
(x) по данным
D
D и даже пытаться генерировать новые данные с помощью таких моделей (как, например, делается тут). Но у статистических методов есть разные ограничения, наиболее серьёзным из которых представляется проклятие размерности: чем больше измерений у ваших данных, тем больше разнообразных примеров вам нужно для построения адекватной оценки
(x). О проклятии размерности мы поговорим чуть подробнее далее.
Замечание 3. Также может возникать вопрос — а зачем вообще нужно вводить латентные переменные, моделировать совместное распределение
p(x,z), а целевое распределение
p
(
x
)
p(x) определять как маргинализацию
p(x,z) по
z
z? Почему такой подход в принципе должен работать? Ответ состоит в том, что, даже имея относительно простые выражения для
p
(
z
)
p(z) и
p(x∥z), можно описать достаточно сложное распределение
p
(
x
)
p(x), что достаточно наглядно проиллюстрировано в примере ниже.
Обучение VAE
Прежде чем пытаться решать задачу оптимизации
(
1
)
(1) давайте подумаем, а как мы вообще могли бы посчитать такой интеграл? Первое, что приходит на ум, — попробовать получить его приближённое значение методом Монте-Карло:
(x)=
Z
M
∫
p
θ
(x∣z)p
θ
(z)dz=E
z∼p
θ
(z)
[p
θ
(x∣z)]≈
(x∣z
k
),
где в последнем переходе мы используем сэмплы
(z). Однако, если
z
∈
Z
M
z∈Z
M
и
M
M — достаточно большое, мы столкнёмся с проклятием размерности — количество семплов, необходимых для того, чтобы хорошо покрыть
Z
M
Z
M
, растёт экспоненциально с ростом
M
M:
3
Есть ли способ как-то сократить число необходимых семплов для подсчёта
(
1
)
(1)? На самом деле, часто оказывается, что далеко не все возможные
z
z отображаются в элементы
D
D, и вклад большинства
z
z в оценку
(x∥z) практически нулевой. Это наводит на мысль, что для каждого
x
x нам может пригодиться знание распределения
q(z∥x) таких
z
z, которые являются прообразами
x
x. Мы можем предположить, что распределение
q
q параметризовано некоторым семейством параметров
q(z∣x)=q
ϕ
(z∣x),ϕ∈Φ
Зная распределение
(z∥x), мы могли бы семлировать уже только из него, а не из всего
(z), и, если распределение
q
q окажется достаточно хорошим, число необходимых семплов значительно сократится.
О том, как построить
q
ϕ
q
ϕ
, мы поговорим позже. Сейчас стоит обратить внимание на то, что процессы семплирования из распределений
(z∥x) и
(x∥z) взаимно обратны друг к другу: первое отображает элементы датасета в подмножество латентного пространства
Z
M
Z
M
, то есть действует как энкодер, а второе отображает латентные переменные в подмножество
X
N
X
N
, то есть действует как декодер:
2
Так как оба эти распределения будут участвовать в обучении VAE, возникает аналогия между VAE и моделями-автоэнкодерами, имеющими похожую структуру.
Вывод функции потерь
Сейчас у нас всё готово для того, чтобы записать общий вид функции потерь для обучения вариационного автоэнкодера. Напомним, что мы обучаем модель путём максимизации правдоподобия
(x) по
θ
θ. Для удобства мы перейдём к логарифму правдоподобия:
log
log
max
⁡
θ
∈
Θ
logp
θ
(x)=log∫
Z
M
p
θ
(x∣z)p
θ
(z)dz→
θ∈Θ
max
Оптимизировать напрямую это выражение тяжело из-за проклятия размерности, обсуждавшегося в прошлом разделе. Чтобы победить проклятие размерности, мы хотели бы заменить семплирование из априорного распределения
(z) на семплирование из
(z∥x), для чего придётся осуществить некоторый трюк. Для любого
(z∥x), отличного от нуля для всех
z
∈
Z
M
z∈Z
M
, мы можем выписать следующую цепочку равенств:
log
log
logp
θ
(x)=E
q
ϕ
(z∣x)
[logp
θ
(x)]=
log
(z∣x)
[log(
p
θ
(z∣x)
p
θ
(x,z)
)]=
log
(z∣x)
[log(
q
ϕ
(z∣x)
p
θ
(x,z)
p
θ
(z∣x)
q
ϕ
(z∣x)
)]=
log
log
θ,ϕ
(x)(ELBO)
E
q
ϕ
(z∣x)
[log(
q
ϕ
(z∣x)
p
θ
(x,z)
(z∣x)∥p
θ
(z∣x))
E
q
ϕ
(z∣x)
[log(
p
θ
(z∣x)
q
ϕ
(z∣x)
)]
Второе слагаемое в последнем равенстве —
K
L
KL-дивергенция между
(z∥x) и
(z∥x), которая, как известно, неотрицательна:
(z∣x)∥p
θ
(z∣x))≥0
А первое слагаемое — это величина, именуемая в английской литературе evidence lower bound (ELBO):
log
log
θ,ϕ
(x)=E
q
ϕ
(z∣x)
[logp
θ
(x,z)−logq
ϕ
(z∣x)]=
log
reconstruction loss
regularization term
=
reconstruction loss
E
q
ϕ
(z∣x)
[logp
θ
(x∣z)]
−
regularization term
D
KL
(q
ϕ
(z∣x)∥p
θ
(z))
Первое слагаемое в последнем переходе обычно называют reconstruction loss, так как оно оценивает качество восстановления декодером объекта
x
x из его латентного представления
z
z. А второе играет роль регуляризационного члена и подталкивает распределение, генерируемое энкодером, быть ближе к априорному распределению.
Так как
K
L
KL-дивергенция неотрицательна, ELBO является нижней границей для логарифма правдоподобия данных:
log
log
θ,ϕ
(x)=logp
θ
(x)−D
KL
(q
ϕ
(z∣x)∥p
θ
(z∣x))≤logp
θ
(x)
Посмотрим повнимательнее на равенства, которые мы выписали.
Функцию
L
θ
,
ϕ
L
θ,ϕ
можно оптимизировать градиентным спуском (SGD), предварительно выбрав удобный вид для
(x∥z),
(z∥x) и
(z). Максимизируя
L
θ
,
ϕ
L
θ,ϕ
, мы растим
log
logp
θ
(x), тем самым улучшая нашу генеративную модель. Оптимизацию ELBO с помощью SGD мы будем подробно обсуждать в следующем разделе.
Максимизируя
L
θ
,
ϕ
L
θ,ϕ
, мы одновременно минимизируем
(z∥x)∥p
θ
(z∥x)). Распределение
(z∥x) оценивает, из каких
z
z мог бы быть сгенерирован объект
x
x, и заранее оно нам не известно. Но если мы выберем достаточно большую модель для
(z∥x), то
(z∥x) в процессе оптимизации может очень сильно приблизиться к
(z∥x), и тогда мы будем напрямую оптимизировать
log
logp
θ
(x). Заодно мы получаем приятный бонус: для оценки распределения прообразов
x
x мы сможем использовать
(z∥x) вместо невычислимого
(z∥x). То есть
q
ϕ
q
ϕ
, которое мы при выводе формулы ввели в рассмотрение как произвольное распределение, действительно будет играть роль энкодера для модели.
Обучение VAE с помощью градиентного спуска
Важное свойство ELBO в том, что его можно оптимизировать градиентным спуском относительно параметров
ϕ
ϕ и
θ
θ. Если объекты датасета
D
D независимы и одинаково распределены, то
θ,ϕ
(D) запишется как сумма (или среднее) значений
θ,ϕ
(x) на объектах
x
∈
D
x∈D:
θ,ϕ
(D)=
x∈D
∑
L
θ,ϕ
(x)
Значения
θ,ϕ
(x) и их градиенты
θ,ϕ
(x) в общем случае вычислить невозможно, однако можно получить их несмещённые оценки, что позволит нам использовать стохастический градиентный спуск.
Оценку для градиента по параметрам
θ
θ получить несложно:
log
log
θ,ϕ
(x)=∇
θ
E
q
ϕ
(z∣x)
[logp
θ
(x,z)−logq
ϕ
(z∣x)]=
log
log
(z∣x)
[∇
θ
(logp
θ
(x,z)−logq
ϕ
(z∣x))]=
log
(z∣x)
[∇
θ
logp
θ
(x,z)]≈
log
logp
θ
(x,z
k
),
где в последней строчке
(z∥x). Однако оценку на градиент по параметрам
ϕ
ϕ получить сложнее, ведь они также участвуют и в семплировании:
log
log
θ,ϕ
(x)=∇
ϕ
E
q
ϕ
(z∣x)
[logp
θ
(x,z)−logq
ϕ
(z∣x)]
log
log
(z∣x)
[∇
ϕ
(logp
θ
(x,z)−logq
ϕ
(z∣x))]
В общем случае эта проблема не разрешима. Однако некоторые распределения позволяют применить репараметризацию (reparameterization trick): представить переменную
z
z как обратимую дифференцируемую функцию от случайного шума, параметров
ϕ
ϕ и переменнной
x
∈
D
x∈D:
z=g(ε,ϕ,x)
Здесь распределение
ε
∼
p
ε
ε∼p
ε
не зависит от
ϕ
ϕ и
x
x. Например, пусть
ε∼N(0,I). Тогда
g
g может иметь следующий вид:
z=g(ε,ϕ,x)=μ
ϕ
(x)+ε⋅σ
ϕ
(x)∼N(μ
ϕ
(x),σ
ϕ
2
(x))
После такой замены мы сможем получить оценку на градиент по
log
log
θ,ϕ
(x)=∇
ϕ
E
q
ϕ
(z∣x)
[logp
θ
(x,z)−logq
ϕ
(z∣x)]=
log
log
[logp
θ
(x,g(ε,ϕ,x))−logq
ϕ
(g(ε,ϕ,x)∣x)]=
log
log
(logp
θ
(x,g(ε,ϕ,x))−logq
ϕ
(g(ε,ϕ,x)∣x))]≈
log
log
(logp
θ
(x,g(ε
k
,ϕ,x))−logq
ϕ
(g(ε
k
,ϕ,x)∣x)),
где в последней строчке
. Репараметризация хорошо иллюстрируется следующей картинкой:
2
Здесь
f
f — функция потерь. Значения
f
f на обеих схемах одинаковы, но на левой картинке градиенты по
ϕ
ϕ рассчитать не получится, так как мы не можем дифференцировать по случайной переменной
z
z.
Однако на правой картинке источник случайности перемещается во входные данные благодаря репараметризации, а градиенты вычисляются по детерминированным переменным. Таким образом, мы получили сетап, типичный для оптимизации с помощью SGD: там мы приближаем градиент функции потерь по случайным батчам входных данных, а здесь роль случайных батчей играют одновременно батчи из переменных
x
x и случайных переменных
ε
ε.
Кроме нормального распределения, есть довольного много примеров распределений, допускающих репараметризацию. Их можно найти по ссылке в разделе "The reparameterization trick". Однако большая часть реализаций VAE используют именно нормальное распределение.
В итоге примерный алгоритм обучения VAE такой:
dataset = np.array(...)
epsilon = RandomDistribution(...)
# Энкодер q_phi(z|x) — нейронная сеть с параметрами phi
encoder = Encoder()
# Декодер p_theta(x|z) — нейронная сеть с параметрами theta
decoder = Decoder()
for step in range(max_steps):
# Семплируем батч исходных данных и случайного шума
batch_x = sample_batch(dataset)
batch_noise = sample_batch(epsilon)
# Считаем параметры распределения q(z | x) с помощью энкодера
latent_distribution_parameters = encoder(batch_x)
# Делаем репараметризацию (семплируем из q(z | x))
z = reparameterize(latent_distribution_parameters, batch_noise)
# Декодер отдаёт параметры выходного распределения
output_distribution_parameters = decoder(z)
# Вычисляем ELBO и обновляем параметры моделей
L = -ELBO(
latent_distribution_parameters,
output_distribution_parameters,
batch_x
)
L.backward()
Стоит подчеркнуть, что декодер выдаёт именно параметры выходного распределения, а не конкретный семпл из этого распределения. Например, если вы моделируете выходные изображения с помощью нормального распределения
N(μ(z),σ
2
(z)), то декодер на выходе предскажет некоторые
(z) и
(z), которые вместе с параметрами латентного распределения (выход энкодера) будут поданы в ELBO.
Для генерации конкретной картинки на этапе инференса нужно будет либо честно провести семплирование из
(z),
σ
^
2
(z)), либо, как часто делают, просто взять среднее
(z) в качестве выходного изображения. В общем случае конкретный способ проведения инференса зависит от вида используемого выходного распределения.
Выбор вида используемых распределений
Пришло время привести примеры конкретных
(x∥z),
(z∥x) и
(z), с которыми можно построить VAE. Для начала предположим, что
(z) можно положить равным стандартному нормальному распределению:
(z)=N(0,I)
Заметим, что в этом случае у априорного распределения
z
z отсутствует зависимость от параметров
θ
θ.
Распределение
(x∥z) зависит от того, к какому распределению принадлежат ваши данные. Если ваши данные имеют непрерывное распределение, то
(x∥z) можно задать, например, как гауссовское распределение:
(x∣z)=N(f
θ
(z),σ
2
)
Вектор средних в этом примере определяется функцией
f
f с переменными
θ
θ и
z
z, а матрица ковариаций определяется постоянной диагональной матрицей. Функцию
f
f можно задать с помощью нейронной сети с параметрами
θ
θ. При желании, матрицу ковариаций тоже можно задавать некоторой функцией и не ограничивать её вид только постоянными матрицами. Если же ваши данные дискретны, то может подойти категориальное распределение:
Categorical
(x∣z)=Categorical(f
θ
(z)),
в котором вектор вероятностей
(z)=(p
1
,…,p
n
) — выход нейросети после применения
softmax
softmax. Если у вас бинарные данные, вы можете использовать бернуллиевское распределение:
Bernoulli
(x∣z)=Bernoulli(f
θ
(z)),
где
(z)=p — выход нейронной сети после применения сигмоиды.
Распределение
(z∥x) может, в принципе, быть любым, но в самом простом случае оно имеет вид гауссовского распределения c диагональной матрицей ковариаций:
(z∣x)=N(μ
ϕ
(x),σ
ϕ
2
(x))
Такое распределение позволяет, в частности, применить репараметризацию, обсуждавшуюся выше. Если выбрать
z
z двумерным, то распределения, определямые
q
q, хорошо визуализируются:
2
А теперь вспомним, как определяется ELBO:
log
θ,ϕ
(x)=E
q
ϕ
(z∣x)
[logp
θ
(x∣z)]−D
KL
(q
ϕ
(z∣x)∥p
θ
(z))
Вычислим его для приведённых выше распределений.
Начнём с
(z∥x)∥p
θ
(z)).
K
L
KL-дивергенция между распределениями
N(μ,Σ) и
N(0,I) равна:
log
⁡
(
det
(N(μ,Σ)∥N(0,I))=
2
1
(μ
T
μ+trΣ−M−log(detΣ)),
где
M
M — размерность этих распределений. Вывод этого соотношения можно найти здесь. В нашем случае
(x)=(μ
1
,…,μ
diag
(x)=diag(σ
1
2
,…,σ
M
2
) и
(z∥x)∥p
θ
(z))=D
KL
(N(μ
ϕ
(x),σ
ϕ
2
(x))∥N(0,I))=
j=1
−1−lnσ
j
2
)
Тогда ELBO будет вычисляться как:
log
θ,ϕ
(x)=E
q
ϕ
(z∣x)
[logp
θ
(x∣z)]−D
KL
(q
ϕ
(z∣x)∥p
θ
(z))=
log
N(μ
ϕ
(x),σ
ϕ
2
(x))
[logp
θ
(x∣z)]−
2
1
j=1
−1−lnσ
log
k=1
∑
K
logp
θ
(x∣z
k
)+
2
1
j=1
∑
M
(1+lnσ
где
∼N(μ
ϕ
(x),σ
ϕ
2
(x)). Как было упомянуто в этой статье от авторов VAE в разделе 2.3, число семплирований
K
K можно положить равным единице при достаточно большом размере батча (например, 100).
Если вы выберете биномиальное
(x∥z), то
log
log
log
⁡
Bernoulli
logp
θ
(x∣z)=
j=1
∑
D
logp
θ
(x
j
∣z)=
j=1
∑
D
logBernoulli(x
log
log
j=1
∑
D
x
j
logp
j
+(1−x
j
)log(1−p
j
)
Если гауссовское
N(f
θ
(z),σ
2
), то
log
log
log
exp
logp
θ
(x∣z)=
j=1
∑
D
logp
θ
(x
j
∣z)=
j=1
∑
D
log(
2πσ
2
1
exp(−
2σ
2
(x
j
−f
θ,j
(z))
2
))=
=
−
D
2
log
⁡
2
π
−
D
log
log2π−Dlogσ−
2σ
2
1
j=1
∑
D
(x
j
−f
θ,j
(z))
2
Пример реализации обучения и применения VAE на датасете MNIST на Keras можно найти здесь, а на PyTorch — здесь.
Инференс обученной модели
Когда мы обучили VAE, мы сможем генерировать новые семплы, просто подавая
z∼N(0,I) на вход декодеру:
![2](https://yastatic.net/s3/education-portal/media/vae_decoder_diagram_385be2e566_6c396a28e8.svg">
Энкодер для генерации новых семплов не нужен. Однако нам может понадобиться оценить
p(x)=∫p(x∥z)p(z)dz для
x
x из тестового множества, чтобы понять, с какой вероятностью модель сможет сгенерировать
x
x. Для оценки интеграла нам нужно насемплировать некоторое количество
z
z, и если брать семплы из
z∼N(0,I), то оценка может плохо сойтись. Но можно снова использовать ELBO как нижнюю границу для
log
⁡
p
(
x
)
logp(x) и оценивать уже её, семплируя из распределения
(z∥x). Такая оценка сойдётся быстрее и даст примерное представление о том, насколько хорошо модель справляется с конкретным примером
x
x.
Также интересно бывает взглянуть на то, как распределены коды обучающих примеров в латентном пространстве. Так, например, может выглядеть распределение латентных кодов цифр MNIST для обученного VAE в двумерном латентном пространстве:
2
Разные типы цифр обозначены разными цветами (соответствие цифр и цветов показано на шкале сбоку). Здесь видно, что лучше всего модель различает нули и единицы, а восьмёрки и тройки — хуже всего. Стоит, конечно, отметить, что латентное пространство выбрано двумерным в целях визуализации, и при большей его размерности модель могла бы научиться различать цифры более качественно.
Для двумерного латентного пространства есть ещё один интересный способ визуализировать структуру многообразия, выученного VAE. Можно взять равномерную сетку на единичном квадрате и отобразить её в латентное пространство, применив к ней функцию, обратную к CDF нормального распределения.
Полученные семплы можно подать в декодер и посмотреть, какие картинки будут соответствовать узлам сетки:
2
Здесь изображены примеры, сгенерированные для датасетов Frey Face и MNIST (оба доступны по ссылке). Такая визуализация позволяет увидеть плавный переход латентных кодов одних объектов в коды других, а также взаимное расположение латентных кодов.
Для MNIST снова видно, в частности, что коды нулей и единиц модель разнесла далеко друг от друга, а коды троек и восьмёрок очень близки. А ещё интересно наблюдать плавный переход от шестёрок к нулям и от семёрок к единицам. Для Frey Face видно, что весёлые лица расположены далеко от грустных, а по главной диагонали квадрата можно проследить плавный переход от серьёзного лица к улыбающемуся.
Ещё интересно посмотреть на то, как меняется качество генерируемых цифр в зависимости от размерности латентного пространства (на картинках просто случайные семплы из модели):
2
Заметный переход виден между размерностями 2 и 5, дальнейший рост размерности почти не оказывает значимого эффекта.
Conditional VAE (CVAE)
Иногда мы можем захотеть сгенерировать не просто какой-то произвольный объект из датасета, а относящийся к конкретной группе или классу. Ранее мы выписывали уравнение для
log
logp
θ
(x):
log
log
logp
θ
(x)=E
q
ϕ
(z∣x)
[logp
θ
(x∣z)]−D
KL
(q
ϕ
(z∣x)∥p
θ
(z))+D
KL
(q
ϕ
(z∣x)∥p
θ
(z∣x))
Все распределения, участвующие в этом уравнении, мы можем сделать обусловленными по переменной
y
y:
log
log
logp
θ
(x∣y)=E
q
ϕ
(z∣x,y)
[logp
θ
(x∣z,y)]−D
KL
(q
ϕ
(z∣x,y)∥p
θ
(z∣y))+D
KL
(q
ϕ
(z∣x,y)∥p
θ
(z∣x,y))
Переменная
y
y может быть лейблом объекта
x
x или вообще произвольным тензором, как-то характеризующим
x
x. Вместо
(z), единого для всех
x
x из обучающей выборки, для каждого значения
y
y теперь будет отдельное априорное распределение
(z∥y).
Переменная
y
y может принимать и дискретные, и непрерывные значения. Она может даже, например, быть половиной изображения, которую модели предлагается дополнить. На всякий случай подчеркнём, что обучение CVAE — это не то же самое, что обучение нескольких независимых VAE, так как веса CVAE общие для всех классов.
На уровне имплементации это реализуется довольно просто: нужно всего лишь сконкатенировать входы энкодера и декодера с тензором, соответствующим
y
y. Если
y
y имеет категориальные значения, то бывает полезно предварительно закодировать их one-hot векторами. Алгоритм будет примерно таким:
dataset, labels = np.array(...), np.array(...)
epsilon = RandomDistribution(...)
# Энкодер q_phi(z|x) — нейронная сеть с параметрами phi
encoder = Encoder()
# Декодер p_theta(x|z) — нейронная сеть с параметрами theta
decoder = Decoder()
for step in range(max_steps):
# Семплируем батч исходных данных, лейблов и случайного шума
batch_x = sample_batch(dataset)
batch_y = sample_batch(labels)
batch_noise = sample_batch(epsilon)
# Подаём в энкодер конкатенацию входных данных и лейблов
encoder_input = concatenate([batch_x, batch_y])
# Считаем параметры распределения z с помощью энкодера
latent_distribution_parameters = encoder(encoder_input)
# Делаем репараметризацию
z = reparameterize(latent_distribution_parameters, batch_noise)
# Конкатенируем полученный случайный вектор и лейблы
decoder_input = concatenate([z, batch_y])
# Декодер отдаёт нам выходное изображение
output_distribution_parameters = decoder(decoder_input)
# Вычисляем ELBO и обновляем параметры
L = -ELBO(
latent_distribution_parameters,
output_distribution_parameters,
batch_x
)
L.backward()
Реализацию CVAE на PyTorch и Tensorflow можно найти, например, здесь.
Если визуализировать распределение латентных кодов для цифр MNIST, полученных после обуславливания модели на класс цифры, то можно увидеть что-то такое:
2
Мы видим непонятную смесь из точек вместо явных кластеров, которые выделяла обычная модель VAE. Однако дело тут в том, что, вместо того, чтобы пытаться размещать все цифры в одном пространстве
p(z)∼N(0,I), модель использует отдельное латентное пространство
p(z∥y)∼N(0,I) для каждой цифры:
2
2
На картинке справа — априорные распределения для цифр 6 и 7, а слева — визуализация структуры выученных многообразий для этих цифр, построенная так же, как аналогичная визуализация для VAE. Качество изображений каждой отдельной цифры заметно повышается:
2
Видно, что вариабельность генерации цифр теперь тоже заметно выросла, и модель может имитировать написание цифр разными почерками.
Обзор статей
Кроме стандратного описания работы VAE, приведём результаты нескольких недавних интересных работ, базирующихся на идее VAE.
VQ-VAE и VQ-VAE-2
Модели VQ-VAE и VQ-VAE-2 интересны тем, что в них в качестве априорных распределений были задействованы дискретные распределения. В каких ситуациях дискретные распределения могут быть более применимы, чем непрерывные? Например, если мы имеем дело с токенам в задачах NLP или фонемами в обработке речи. Картинки также можно было бы кодировать некоторым набором из целых чисел: например, одно число могло бы кодировать тип объекта, другое — его цвет, третье — цвет фона и так далее:
2
Кроме того, существуют довольно мощные алгоритмы (например, Трансформер), предназначенные для работы с дискретными данными. Выучивание хороших дискретных представлений даёт возможность эффективно использовать такие алгоритмы для, например, задачи генерации картинок.
VQ-VAE
Авторы VQ-VAE вводят дискретное латентное пространство в виде
K
K вещественных векторов
,…,e
K
размерности
D
D. Векторы из этого пространства называются кодовыми векторами или кодами. На рисунке ниже приведена примерная схема обучения предлагаемой модели.
2
Энкодер принимает на вход картинку
x
x и выдаёт на выходе тензор
(x). На рисунке этот тензор имеет размерность
M
×
M
×
D
M×M×D: последняя размерность совпадает с длиной кодовых векторов, а
M
×
M
M×M — это пространственная размерность выхода CNN (для простоты мы здесь не пишем явно размерность батчей).
Каждый из
M
×
M
M×M векторов из
(x) отображается в ближайший к нему по
L
2
L
2
-расстоянию кодовый вектор. После такой процедуры тензор
(x) переходит в тензор
(x), состоящий из
M
×
M
M×M кодовых векторов. Декодер получает на вход тензор
(x) и отображает его в исходную картинку. Для работы с речью и текстами авторы использовали двумерный тензор
(x) вместо трёхмерного.
Выходное распределение энкодера
q(z∥x) определено здесь следующим образом:
arg
⁡
min
иначе
q(z=k∣x)={
1,
0,
k=argmin
j
∥z
e
(x)−e
j
∥
2
,
иначе
Во время обучения в качестве априорного распределения в латентном пространстве используется равномерное распределение
p(z)=
K
1
, поэтому слагаемое
(q(z∥x)∥p(z)) оказывается постоянным и равным
log
⁡
K
logK:
log
log
⁡
K
D
KL
(q(z∣x)∥p(z))=−
k=1
∑
K
q(z=k∣x)log(
q(z=k∣x)
p(z)
)=logK
В точках, где
q(z=k∥x)=0, предпоследнее выражение продолжается нулём по непрерывности. Таким образом, ELBO для таких распределений примет вид
log
log
log
⁡
K
,
ELBO(x)=E
q(z∣x)
[logp
θ
(x∣z
e
(x))]−D
KL
(q(z∣x)∥p(z))=logp
θ
(x∣z
q
(x))−logK,
где
θ
θ — параметры декодера. При оптимизации
log
⁡
K
logK можно не учитывать. Отображение выхода энкодера в кодовые векторы не дифференцируемо, поэтому при обучении применяется следующий трюк: при обратном проходе градиент копируется напрямую из декодера в энкодер, пропуская при этом слой, отображающий выходы энкодера в кодовые векторы.
Этот трюк очень близок к приёму, известному как straight-through estimator, впервые предложенному в этой статье (а его простое описание можно найти тут). Использование straight-through estimator, однако, не позволяет обучать сами кодовые векторы, так как по ним не будут вычисляться градиенты. Поэтому лосс для обучения модели складывается из трёх компонент:
L
=
log
L=logp(x∣z
q
(x))+∥sg[z
e
(x)]−z
q
(x)∥
2
2
+β∥z
e
(x)−sg[z
q
(x)]∥
2
2
Здесь
s
g
[
⋅
]
sg[⋅] обозначает оператор остановки дифференцирования: через его аргумент не текут градиенты.
В статье лосс записан несколько иначе:
L
=
log
L=logp(x∣z
q
(x))+∥sg[z
e
(x)]−e∥
2
2
+β∥z
e
(x)−sg[e]∥
2
2
Эти обозначения кажутся несколько путающими по двум причинам:
Буква
e
e в нижнем индексе
(x) призвана обозначить только то, что это выход энкодера, а не наличие связи между кодовыми векторами
e
e и параметрами энкодера. Но второе довольно легко для себя предположить.
Вычитание
e
e обозначает вычитание не всех элементов словаря из соответствующей позиции тензора
(x), а только лишь ближайшего соседа к элементу
(x) на этой позиции. То есть по факту вычитание
e
e в этой записи равносильно вычитанию
(x). Это не уточняется в статье, но можно увидеть в официальной реализации.
Первое слагаемое — это ELBO с точностью до константы. Второе слагаемое отвечает за сдвиг кодовых векторов в сторону выходов энкодера. Чтобы не получилось так, что выходы энкодера всё время меняют кодовые векторы за счёт второй компоненты лосса, а сами на каждой итерации выдают векторы, далёкие от текущих кодовых векторов, добавляется третье слагаемое. Оно отвечает за то, чтобы энкодер стремился выдавать векторы, близкие к кодовым векторам, а его значимость регулируется с помощью коэффициента
β
β.
Однако при обучении мы потеряли регуляризационное слагаемое
(q(z∥x)∥p(z)), из-за чего распределение энкодера не было обязано приближать собой априорное распределение и осталось его узким подмножеством. Из-за этого с наибольшей вероятностью при семплировании из равномерного категориального распределения мы будем получать просто шумы вместо хороших картинок:
2
Чтобы исправить эту проблему, авторы предлагают с помощью дополнительной модели выучить априорное распределение
p
(
z
)
p(z) тех латентных переменных, которые модель научилась генерировать в процессе обучения. Поскольку любое кодовое представление можно вытянуть в последовательность, а самих кодов — конечное наперёд заданное число, то эта задача близка к задаче обучения языковой модели.
Действительно, ведь там мы должны по последовательности предыдущих слов предложения предсказать следующее слово из доступного словаря, а в нашем случае — по входной последовательности дискретных латентных кодов предсказать следующий латентный код.
Для картинок авторы предложили моделировать априорное распределение латентных кодов с помощью PixelCNN. Детали архитектуры и обучения этой модели можно найти в оригинальной статье, здесь мы опишем только общую идею.
PixelCNN последовательно генерирует пиксели картинки, двигаясь из верхнего левого угла в правый нижний. Она проходит все ряды последовательно от верхнего до нижнего, а внутри каждого ряда движется слева направо:
2
Для цветных картинок каналы (R, G, B) также моделируются последовательно: канал B при генерации зависит от R и G, а G — только от R. При предсказании значения каждого следующего пикселя модель использует значения уже сгенерированных соседей из некоторого окружающего квадрата. Чтобы модель не могла читать пиксели, идущие после текущего предсказываемого пикселя, используется специальная маска, пример которой изображён на правой части рисунка.
В случае VQ-VAE обучение PixelCNN происходит не на пикселях, а на латентных кодах. Семплирование из выученного априорного распределения выглядит гораздо лучше, чем попытки семплировать из равномерного:
2
Для аудио вместо PixelCNN авторами используется WaveNet. При обучении моделей априорных распределений есть возможность подавать метки классов, чтобы потом можно было семплировать из этих классов (принцип тот же, что и для CVAE).
Результаты реконструкции картинок из ImageNet с помощью VQ-VAE выглядят довольно неплохо (под реконструкцией понимается выход полной модели, состоящей из энкодера и декодера):
2
А так выглядят результаты семплирования из VQ-VAE с априорным распределением, выученным PixelCNN:
2
VQ-VAE-2
Модель VQ-VAE-2 — это расширение VQ-VAE. Она показывает значительный скачок по качеству генерируемых изображений:
2
Впечатляет то, что на картинке именно результат семплирования из выученного моделью распределения, а не результат реконструкции. Первое основное отличие модели VQ-VAE от VQ-VAE-2 — использование иерархических латентных переменных:
2
Прежде чем перейти к описанию архитектуры, хочется сделать небольшой дисклеймер: когда в тексте далее будет говориться «тензор размера
M
×
M
M×M», то будет иметься в виду, что тензор имеет шейп
(B,M,M,C), где первая размерность соответствует батчам, а последняя — каналам.
На картинке показан пример двухуровневой архитектуры (хотя уровней может быть и больше). Каждому уровню соответствуют свои энкодер, декодер и набор кодовых векторов (общей размерности
D
D для всех уровней). Обозначим нижний и верхний энкодеры как
E
n
c
bottom
Enc
bottom
и
E
n
c
top
Enc
top
, а декодеры — как
D
e
c
bottom
Dec
bottom
и
D
e
c
top
Dec
top
.
E
n
c
bottom
Enc
bottom
принимает на вход трёхканальную картинку размера
256
×
256
256×256 пикселей, отображает её в тензор размера
64
×
64
64×64 и передаёт на вход
E
n
c
top
Enc
top
.
E
n
c
top
Enc
top
выдаёт тензор размера
32
×
32
32×32, который затем отображается в тензор из кодовых векторов
z
top
z
top
(квантизуется)
z
top
z
top
передаётся на вход
D
e
c
top
Dec
top
, затем выходы
E
n
c
bottom
Enc
bottom
и
D
e
c
top
Dec
top
конкатенируются и квантизуются в
z
bottom
z
bottom
z
top
z
top
и
z
bottom
z
bottom
конкатенируются и передаются на вход
D
e
c
bottom
Dec
bottom
, который отображает их в исходную картинку
Для обучения модели используется почти такой же лосс, как для VQ-VAE. Для VQ-VAE он имел вид:
L
=
log
L=logp(x∣z
q
(x))+∥sg[z
e
(x)]−z
q
(x)∥
2
2
+β∥z
e
(x)−sg[z
q
(x)]∥
2
2
Для VQ-VAE-2 первое и третье слагаемые сохраняют свой вид, а второе слагаемое заменяется на обновление кодовых векторов
e
i
e
i
с помощью экспоненциального скользящего среднего. Пусть
E(x)
(t)
— выход энкодера на шаге
t
t, выпрямленный в двумерный тензор, последняя размерность которого равна размерности
D
D кодовых векторов.
Пусть
i,1
(t)
,…,E
i,n
i
(t)
(t)
} — множество из
(t)
векторов, для которых на шаге
t
t ближайшим оказался кодовый вектор
(t−1)
. Тогда обновление
e
i
e
i
на шаге
t
t происходит по следующим формулам:
(t)
=
N
i
(t)
m
i
(t)
(t)
=m
i
(t−1)
⋅γ+
j
∑
n
i
(t)
E(x)
i,j
(t)
(1−γ)
(t)
=N
i
(t−1)
⋅γ+n
i
(t)
(1−γ)
Здесь
γ
γ — некоторый вещественный параметр.
Так же, как и для VQ-VAE, априорное распределение для VQ-VAE-2 выучивается отдельно уже после обучения основной модели, но в случае VQ-VAE-2 оно имеет иерархическую структуру. На картинке изображён пример такого распределения для двухуровневой архитектуры:
2
Для каждого уровня обучается отдельная модель PixelCNN: одна — на кодовых векторах первого уровня, вторая — на кодовых векторах первого и второго уровней. Обе модели также принимают на вход метку класса, изображение из которого нужно насемплировать.
Семплирование из финальной модели происходит так:
семплируются векторы
e
top
e
top
из верхнего распределения
из нижнего распределения семплируются векторы
e
bottom
e
bottom
при условии векторов
e
top
e
top
декодер принимает на вход векторы
e
top
e
top
и
e
bottom
e
bottom
и выдаёт финальную картинку
Результаты семплирования из двухуровневой модели VQ-VAE-2, обученной на ImageNet:
2
А это — результаты семплирования из трёхуровневой модели VQ-VAE-2, обучавшейся на FFHQ:
2
DALL-E
Одна из недавних работ, связанных с VAE, — это DALL-E от OpenAI. Они обучили модель с 12 миллиардами параметров, генерирующую картинки по их текстовому описанию. Для обучения авторами был собран датасет, состоящий из 250 миллионов пар картинок и их описаний. Вот примеры работы этой модели:
2
2
В блог-посте OpenAI, посвящённом DALL-E, есть возможность самостоятельно составлять текстовые описания из некоторого ограниченного словаря и смотреть на результаты. Осторожно, это затягивает 😃
2
DALL-E идейно основывается на результатах VQ-VAE: сначала выучиваются кодовые векторы для картинок, а затем обучается Трансформер, моделирующий совместное априорное распределение текстов и кодовых векторов. Подробнее о трансформерах мы рассказывали в главе 6.3 этого хендбука.
В DALL-E задействована архитектура, основанная на декодер-части исходной архитектуры Трансформера, поэтому стоит также почитать про модель GPT-2, работающую аналогичным образом.
Обучение проходит в две стадии:
Сначала обучается дискретизованный VAE (dVAE) c энкодером для сжатия RGB-картинок размера
256
×
256
256×256 в тензор из
32
×
32
=
1024
32×32=1024 кодовых векторов. Эта стадия обучения очень напоминает VQ-VAE, но вместо добавления в лосс дополнительных слагаемых для кодовых векторов авторы DALL-E используют релаксацию Гумбеля — трюк, позволяющий проводить честное дифференцирование по параметрам энкодера. Об обучении dVAE мы будем говорить подробнее далее.
Затем обучается Трансформер (точнее, только декодер-часть исходной архитектуры Трансформера), задача которого — выучить совместное распределение картинок и их текстовых описаний. Он принимает на вход конкатенацию из эмбеддингов текстовых токенов и кодовых векторов картинок и учится для каждой входной последовательности предсказывать её продолжение. О некоторых деталях обучения Трансформера также будет рассказано далее.
Инференс обученной модели происходит так: эмбеддинги текстового описания картинки подаются на вход Трансформеру, и он авторегрессионно предсказывает кодовые векторы картинки, соответствующей этому описанию, а затем полученные кодовые векторы пропускаются через декодер dVAE.
dVAE
Обучение dVAE происходит путём максимизации ELBO для картинок
x
x и их дискретных латентных представлений
log
lnp
θ
(x)≥E
q
ϕ
(z∣x)
[logp
θ
(x∣z)]−βD
KL
(q
ϕ
(z∣x)∥p(z)),
где
ϕ
ϕ и
θ
θ — параметры энкодера и декодера дискретизованного VAE, a
p
(
z
)
p(z) — равномерное категориальное распределение над кодовыми векторами. Здесь можно заметить дополнительный коэффициент
β
β, который в стандартном VAE всегда равен 1. Однако авторы DALL-E ввели дополнительный параметр
β
β, опираясь на результаты статьи о
β
β-VAE. Но, в отличие от исходной статьи, в их экспериментах значение
b
e
t
a
beta постепенно понижается в ходе обучения.
Энкодер dVAE отображает картинки размера
256
×
256
256×256 в тензор
(x) с шейпом
32
×
32
×
8192
32×32×8192, где
8192
8192 — число кодовых векторов. То есть каждой из
32
×
32
32×32 позиций энкодер сопоставляет категориальное распределение над
8192
8192 кодовыми векторами, параметризованное выходными логитами.
Для получения тензора
(x) из кодовых векторов можно было бы сначала применить
softmax
softmax к распределениям на каждой из
32
×
32
32×32 позиций, а затем сопоставить каждой позиции кодовый вектор, номеру которого соответствует максимальная вероятность (взять
argmax
argmax для этой позиции).
Однако операция
argmax
argmax не дифференцируема, и, к тому же, в концепции VAE на вход декодеру должен пойти семпл из распределения, предсказываемого энкодером, а взятие
argmax
argmax на каждой позиции не является семплированием из предсказанного распределения.
Поэтому нам потребуется применение некоторых трюков, которые позволят нам одновременно:
аппроксимировать семплирование из
softmax
softmax
сделать семплирование дифференцируемым
Gumbel-Max Trick и Gumbel-Softmax
Первый трюк известен в англоязычной литературе как Gumbel-Max Trick. Представим, что у нас есть логиты-выходы сетки
,…,x
k
, и мы хотим с их помощью получить семпл из категориального распределения, то есть стохастически предсказать класс. Для этого мы обычно применяем к логитам
softmax
softmax, чтобы получить вероятности
exp
⁡
x
i
∑
j
exp
expx
j
expx
i
,
а затем из получившегося категориального распределения
,…,π
k
} семплируем класс. Оказывается, этим двум шагам будет эквивалентна следующая процедура:
насемплировать числа
,...,g
k
из стандартного распределения Гумбеля,
прибавить к каждому из логитов
x
i
x
i
семпл
g
i
g
i
,
выбрать класс
j
j, такой что
j
=
argmax
j=argmax
О том, почему это действительно так, можно почитать здесь. Однако сам по себе Gumbel-Max Trick нам не поможет — ведь операция так и не стала дифференцируемой. Поэтому придётся использовать ещё один трюк, предложенный практически одновременно в двух статьях (первая и вторая) и названный Gumbel-Softmax в одной из них.
Чтобы описать этот трюк, отметим, что результат операции
argmax
argmax — это индекс некоторого класса
j
j. Такой индекс можно описать one-hot кодированием, то есть вектором длиной
k
k, в котором все элементы равны нулю, кроме
j
j-го, который равен единице.
Gumbel-Softmax состоит в том, чтобы вместо взятия
argmax
argmax на последнем этапе Gumbel-Max Trick делать следующее:
вычислить
y
i
=
exp
exp
j=1
k
exp((x
j
+g
j
)/τ)
exp((x
i
+g
i
)/τ)
i=1,…,k, — аппроксимацию one-hot при помощи
softmax
softmax с температурой
сложить кодовые векторы
e
i
e
i
с весами
z=∑
i
y
i
e
i
выдать вектор
z
z в качестве латентного вектора для данной позиции
На самом деле авторы DALL-E не уточняли, как выходной вектор
z
z агрегируется из кодовых векторов и
y
i
y
i
, но такой подход применён в реализации DALL-E на PyTorch.
При
τ
→
0
τ→0 семплирование из распределения
exp
exp
j=1
k
exp((x
j
+g
j
)/τ)
exp((x
i
+g
i
)/τ)
стремится к
argmax
argmax, и в процессе обучения dVAE авторы постепенно уменьшали значение
τ
τ. На следующей картинке слева — просто Gumbel-Max Trick, а справа — дифференцируемый вариант Gumbel-Max Trick:
2
Таким образом, для обучения кодовых векторов для dVAE не требуется дополнительных слагаемых в лоссе относительно ELBO, а также копирования градиентов из декодера в энкодер (как было в VQ-VAE).
Кроме того, стоит отметить, что
(z∣x)∥p(z)) в данном случае не вырождается в константу, а действительно действует как регурялизатор, заставляя категориальное распределение, параметризованное логитами энкодера, быть ближе к равномерному распределению над кодовыми векторами.
Распределение Logit-Laplace
Ещё один трюк в обучении dVAE касается выходного распределения
(x∥z). Авторы DALL-E подметили проблему, возникающую при часто встречающемся выборе лапласовского и гауссовского распределений в качестве
(x∥z): оба они определены на всей вещественной прямой, в то время как пиксели принимают значения из ограниченного интервала. Таким образом, часть плотности при моделировании «теряется», оказываясь вне возможных границ значений пикселей.
Чтобы исправить эту проблему, авторы предлагают использовать распределение, которое они назвали “Logit-Laplace”. Его плотность определена на интервале
(
0
,
1
)
(0,1) и выражается следующей формулой:
exp
⁡
(
−
∣
logit
f(x∣μ,b)=
2bx(1−x)
1
exp(−
b
∣logit(x)−μ∣
),
logit
logit(x)=
1−x
x
Эта плотность соответствует случайной переменной, полученной применением сигмоиды к распределённой по Лапласу случайной переменной. Выражение для распределения Logit-Laplace можно получить по стандартной формуле для плотности случайной величины, полученной применением монотонной дифференцируемой функции к другой случайной величине (см. формулу, например, тут). Логарифм этой плотности подставляется в ELBO вместо
lnp
θ
(x∥z).
Декодер на выходе выдаёт 6 тензоров: первые три соответствуют
μ
μ для RGB-каналов, оставшиеся три соответствуют
ln
⁡
b
lnb, и эти 6 тензоров используются для подсчёта лосса. При подаче в энкодер значения картинок нормируются функцией
ϕ
:
[
0
,
255
ϕ:[0,255]→(ε,1−ε):
255
x
+
ε
ϕ:x↦
255
1−2ε
x+ε
Этим авторы добиваются того, чтобы декодер моделировал значения из
(ε,1−ε), что позволяет нивелировать вычислительные проблемы, связанные с делением на
x(1−x) в формуле плотности. Во время инференса реконструкция
x
^
x
^
картинки
x
x вычисляется по формуле:
sigmoid
(sigmoid(μ)),
где
μ
μ — первые три тензора из выхода декодера. Выходы, соответствующие
ln
⁡
b
lnb, при этом не используются.
Априорное распределение на текстах и картинках
На втором этапе авторы фиксируют параметры
ϕ
ϕ и
θ
θ и моделируют совместное распределение картинок и их текстовых описаний с помощью Sparse Transformer с 12 миллиардами параметров. На вход он получает конкатенацию из текстового описания картинки и её кодовых векторов. Картинка представляется 1024 кодовыми векторами, получаемыми из энкодера
q
ϕ
q
ϕ
, причём при семплировании кодовых последовательностей используется обычный
argmax
argmax без добавления шума из распределения Гумбеля.
Текстовое описание токенизируется с помощью процедуры BPE (см. раздел про BPE здесь), и каждому токену ставится в соответствие представляющий его вектор из вещественных чисел (эмбеддинг). Для представления текста используется не более 256 токенов, а размер используемого словаря — 16 384 токена.
Задача Трансформера во время обучения — для каждого начального отрезка входной последовательности предсказать следующий за ним токен. Это может быть как текстовый токен, так и кодовый вектор картинки. Поскольку кодовые векторы картинок всегда идут за текстовыми токенами, при генерации кодовых векторов attention-механизм учитывает также и все предыдущие текстовые токены.
Кроме того, маска attention для кодовых векторов учитывает, что исходно они расположены не линейно друг за другом, а на прямоугольной сетке. В статье приводится несколько вариантов геометрических паттернов, которые использовались для attention-маски на кодовых векторах.
В качестве лосса используется взвешенная сумма кросс-энтропии для текстовых токенов и кросс-энтропии для кодовых векторов картинок c весами
соответственно (больший приоритет отдаётся генерации картнок, отсюда и больший вес для лосса).
Конечно, огромный Трансформер обучить крайне непросто, и очень существенная часть статьи посвящена трюкам, которые авторы применили для обучения такой большой модели.
2
Инференс
На этапе инференса в модель подаются токены текстового описания картинки, и на их основании модель авторегрессионно предсказывает кодовые векторы:
2
Кодовые векторы картинки подаются в декодер dVAE, который отображает их в финальную картинку:
2
Для повышения качества предсказания авторы сначала генерируют 512 картинок для каждого текстового описания, а затем выбирают лучшую картинку из предсказанных. Разные наборы кодовых векторов для одного и того же текста можно получить, например, случайно выбирая на каждом шаге генерации какой-то кодовый вектор согласно предсказанному Трансформером распределению. Ранжирование полученных 512 картинок осуществляется с помощью CLIP — большой нейросети, обучавшейся в режиме без учителя на большом количестве данных моделировать совместное распределение картинок и текстов.
Заключение
Итак, в этом параграфе мы поговорили о том, как устроен VAE в классическом смысле, — с непрерывным распределением латентных переменных, а также поговорили о работах, основанных на идеях использования дискретных распределений для VAE.
Конечно, различные модификации VAE не исчерпываются только лишь отказом от непрерывных латентных переменных в пользу дискретных. Есть множество других возможных направлений для улучшения модели: использование иерархических латентных распределений (которые мы, кстати, видели в контексте VQ-VAE-2), использование функций потерь, отличающихся от ELBO, выбор различных форм латентных пространств, применение adversarial-обучения и многое другое.
Хороший список различных статей, посвящённых модификациям VAE, можно найти здесь. Из недавних работ, связанных с применением иерархических распределений, интересной кажется NVAE — семплы из модели выглядят весьма впечатляюще. Про неё есть хороший видеообзор от Yannic Kilcher.
На этом мы завершаем рассказ о VAE. Будем надеяться, что он дал вам общее представление и об исходных идеях, из которых выросла модель VAE, и о наиболее интересных последних результатах, связанных с ней.
А в следующем параграфе мы поговорим о генеративно-состязательных сетях.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
8.1. Введение в генеративное моделирование
Следующий параграф
8.3. Генеративно-состязательные сети (GAN)

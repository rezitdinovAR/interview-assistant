---
title: Матричное дифференцирование
url: https://education.yandex.ru/handbook/ml/article/matrichnoe-differencirovanie
course: ml
chapter: 16. Теормин
chapter_id: 16.1
---
Как дифференцировать матрицы и дифференцировать по матрицам: всё, что вам не рассказали про дифференцирование на матанализе
Любая задача машинного обучения — это задача оптимизации, а задачи оптимизации удобнее всего решать градиентными методами (если это возможно, конечно). Поэтому важно уметь находить производные всего, что попадается под руку. Казалось бы, в чём проблема: ведь дифференцирование — простая и понятная штука (чего не скажешь, например, об интегрировании). Зачем же как-то специально учиться дифференцировать матрицы?
Да в принципе-то никаких проблем: в этом параграфе вы не узнаете никаких секретных приёмов или впечатляющих теорем. Но, согласитесь, если исходная функция от вектора
x
x имела вид
f(x)=∣∣Ax−b∣∣
2
(где
A
A — константная матрица, а
b
b — постоянный вектор), то хотелось бы уметь и производную выражать красиво и цельно через буквы
A
A,
x
x и
b
b, не привлекая отдельные координаты
. Это не только эстетически приятно, но и благотворно сказывается на производительности наших вычислений: ведь матричные операции обычно очень эффективно оптимизированы в библиотеках, чего не скажешь о самописных циклах по
i,j,k,s. И всё, что будет происходить дальше, преследует очень простую цель: научиться вычислять производные в удобном, векторно-матричном виде. А чтобы сделать это и не сойти с ума, мы должны ввести ясную систему обозначений, составляющую ядро техники матричного дифференцирования.
Основные обозначения
Вспомним определение производной для функции
f:R
m
→R
n
. Функция
f
(
x
)
f(x) дифференцируема в точке
x
0
x
0
, если
f(x
0
+h)=f(x
0
)+[D
x
0
f](h)+
o
ˉ
ˉ
(∣∣h∣∣),
где
f] — дифференциал функции
f
f: линейное отображение из мира
x
x-ов в мир значений
f
f. Грубо говоря, он превращает «малое приращение
h
=
Δ
x
h=Δx» в «малое приращение
Δ
f
Δf» («малые» в том смысле, что на о-малое можно плюнуть):
f(x
0
+h)−f(x
0
)≈[D
x
0
f](h)
Отметим, что дифференциал зависит от точки
x
0
x
0
, в которой он берётся:
f](h). Под
∣
∣
h
∣
∣
∣∣h∣∣ подразумевается норма вектора
h
h, например корень из суммы квадратов координат (обычная евклидова длина).
Давайте рассмотрим несколько примеров и заодно разберёмся, какой вид может принимать выражение
f](h) в зависимости от формы
x
x. Начнём со случаев, когда
f
f — скалярная функция.
В примерах выше нам дважды пришлось столкнуться с давним знакомцем из матанализа: градиентом скалярной функции (у нескалярных функций градиента не бывает). Напомним, что градиент
f функции в точке
x
0
x
0
состоит из частных производных этой функции по всем координатам аргумента. При этом его обычно упаковывают в ту же форму, что и сам аргумент: если
x
x — вектор-строка, то и градиент записывается вектор-строкой, а если
x
x — матрица, то и градиент тоже будет матрицей того же размера. Это важно, потому что для осуществления градиентного спуска мы должны уметь прибавлять градиент к точке, в которой он посчитан.
Как мы уже имели возможность убедиться, для градиента скалярной функции
f
f выполнено равенство
f](x−x
0
)=⟨∇
x
0
f,x−x
0
⟩,
где скалярное произведение — это сумма попарных произведений соответствующих координат (да-да, самое обыкновенное).
Посмотрим теперь, как выглядит дифференцирование для функций, которые на выходе выдают не скаляр, а что-то более сложное.
Простые примеры и свойства матричного дифференцирования
Производная константы. Пусть
f(x)=a. Тогда
f(x
0
+h)−f(x
0
)=0,
то есть
f] — это нулевое отображение. А если
f
f — скалярная функция, то и
f=0.
Производная линейного отображения. Пусть
f
(
x
)
f(x) — линейное отображение. Тогда
f(x
0
+h)−f(x
0
)=f(x
0
)+f(h)−f(x
0
)=f(h)
Поскольку справа линейное отображение, то по определению оно и является дифференциалом
f]. Мы уже видели примеры таких ситуаций выше, когда рассматривали отображения умножения на матрицу слева или справа. Если
f
f — (скалярная) линейная функция, то она представляется в виде
⟨
a
,
v
⟩
⟨a,v⟩ для некоторого вектора
a
a — он и будет градиентом
f
f.
Линейность производной. Пусть
f(x)=λu(x)+μv(x), где
λ
,
μ
λ,μ — скаляры, а
u
,
v
u,v — некоторые отображения, тогда
f]=λ[D
x
0
u]+μ[D
x
0
v]
Производная произведения. Пусть
f(x)=u(x)v(x), где
u
,
v
u,v — некоторые отображения, тогда
f]=[D
x
0
u]⋅v(x
0
)+u(x
0
)⋅[D
x
0
v]
Это же правило сработает и для скалярного произведения:
⟨u,v⟩]=⟨[D
x
0
u],v⟩+⟨u,[D
x
0
v]⟩
В этом нетрудно убедиться, повторив доказательство или заметив, что в доказательстве мы пользовались лишь дистрибутивностью (= билинейностью) умножения.
Производная сложной функции. Пусть
f(x)=u(v(x)). Тогда
f(x
0
+h)−f(x
0
)=u(v(x
0
+h))−u(v(x
0
))≈
≈[D
v(x
0
)
u](v(x
0
+h)−v(x
0
))≈[D
v(x
0
)
u]([D
x
0
v](h))
Здесь
v(x
0
)
u — дифференциал
u
u в точке
v
(
x
0
)
v(x
0
), а
v(x
0
)
u](…) — это применение отображения
v(x
0
)
u] к тому, что в скобках. Итого получаем:
u∘v](h)=[D
v(x
0
)
u]([D
x
0
v](h))
Важный частный случай: дифференцирование перестановочно с линейным отображением. Пусть
f(x)=L(v(x)), где
L
L — линейное отображение. Тогда
v(x
0
)
L] совпадает с самим
L
L и формула упрощается:
L∘v](h)=L([D
x
0
v](h))
Простые примеры вычисления производной
Вычислим дифференциал и градиент функции
f(x)=⟨a,x⟩, где
x
x — вектор-столбец,
a
a — постоянный вектор.
Вычислим производную и градиент
f(x)=⟨Ax,x⟩, где
x
x — вектор-столбец,
A
A — постоянная матрица.
Вычислим производную обратной матрицы:
f(X)=X
−1
, где
X
X — квадратная матрица.
Вычислим градиент определителя:
f
(
X
)
=
det
(
X
)
f(X)=det(X), где
X
X — квадратная матрица.
Вычислим градиент функции
f(x)=∣∣Ax−b∣∣
2
. С этой функцией мы ещё встретимся, когда будем обсуждать задачу линейной регрессии.
Примеры вычисления производных сложных функций
Вычислим градиент функции
f
(
X
)
=
log
(
det
(
X
)
)
f(X)=log(det(X)).
Вычислим градиент функции
f(X)=tr(AX
T
X).
Вычислим градиент функции
f
(
X
)
=
det
f(X)=det(AX
−1
B).
Вторая производная
Рассмотрим теперь не первые два, а первые три члена ряда Тейлора:
f(x
0
+h)=f(x
0
)+[D
x
0
f](h)+
f](h,h)+
o
ˉ
ˉ
(∣∣h∣∣
2
),
где
f](h,h) — второй дифференциал, квадратичная форма, в которую мы объединили все члены второй степени.
Вопрос на подумать. Докажите, что второй дифференциал является дифференциалом первого, то есть
f](h
1
)](h
2
)=[D
x
0
2
f](h
1
,h
2
)
Зависит ли выражение справа от порядка
Этот факт позволяет вычислять второй дифференциал не с помощью приращений, а повторным дифференцированием производной.
Вторая производная может оказаться полезной при реализации методов второго порядка или же для проверки того, является ли критическая точка (то есть точка, в которой градиент обращается в ноль) точкой минимума или точкой максимума. Напомним, что квадратичная форма
q
(
h
)
q(h) называется положительно определённой (соответственно, отрицательно определённой), если
q(h)⩾0 (соответственно,
q(h)⩽0) для всех
h
h, причём
q(h)=0 только при
h
=
0
h=0.
Теорема. Пусть функция
f:R
m
→R имеет непрерывные частные производные второго порядка
в окрестности точки
x
0
x
0
, причём
f=0. Тогда точка
x
0
x
0
является точкой минимума функции, если квадратичная форма
f положительно определена, и точкой максимума, если она отрицательно определена.
Если мы смогли записать матрицу квадратичной формы второго дифференциала, то мы можем проверить её на положительную или отрицательную определённость с помощью критерия Сильвестра.
Примеры вычисления и использования второй производной
Рассмотрим задачу минимизации
f(x)=∣∣Ax−b∣∣
2
по переменной
x
x, где
A
A — матрица с линейно независимыми столбцами. Выше мы уже нашли градиент этой функции; он был равен
f=2A
T
(Ax−b). Мы можем заподозрить, что минимум достигается в точке, где градиент обращается в ноль:
=(A
T
A)
−1
A
T
b. Отметим, что обратная матрица существует, так как
rk(A
T
A)=rkA, а столбцы
A
A по условию линейно независимы и, следовательно,
rk(A
T
A) равен размеру этой матрицы. Но действительно ли эта точка является точкой минимума? Давайте оставим в стороне другие соображения (например, геометрические, о которых мы упомянем в параграфе про линейные модели) и проверим аналитически. Для этого мы должны вычислить второй дифференциал функции
f(x)=∣∣Ax−b∣∣
2
.
Мы нашли квадратичную форму второго дифференциала; она, оказывается, не зависит от точки (впрочем, логично: исходная функция была второй степени по
x
x, так что вторая производная должна быть константой). Чтобы показать, что
x
∗
x
∗
действительно является точкой минимума, достаточно проверить, что эта квадратичная форма положительно определена.
Докажем, что функция
f
(
X
)
=
log
⁡
det
(
X
)
f(X)=logdet(X) является выпуклой вверх на множестве симметричных, положительно определённых матриц. Для этого мы должны проверить, что в любой точке квадратичная форма её дифференциала отрицательно определена. Для начала вычислим эту квадратичную форму.
Чтобы доказать требуемое в условии, мы должны проверить следующее: что для любой симметричной матрицы
X
0
X
0
и для любого симметричного (чтобы не выйти из пространства симметричных матриц) приращения
H
≠
0
H

=0 имеем
[
D
X
0
2
log
⁡
det
logdet(X)](H,H)<0
Покажем это явно.
Так как
X
0
X
0
— симметричная, положительно определённая матрица, у неё есть симметричный и положительно определённый квадратный корень:
1/2
⋅X
0
1/2
=X
0
1/2
⋅(X
0
1/2
)
T
. Тогда
⟨−X
0
−1
HX
0
−1
,H⟩=−tr(X
0
1/2
(X
0
1/2
)
T
HX
0
1/2
(X
0
1/2
−tr((X
0
1/2
)
T
HX
0
1/2
(X
0
1/2
1/2
=−tr((X
0
1/2
)
T
HX
0
1/2
[(X
0
1/2
)
T
HX
0
1/2
=−∣∣(X
0
1/2
)
T
HX
0
1/2
∣∣
2
,
что, конечно, меньше нуля для любой ненулевой
H
H.
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
15.4. Методы оптимизации в Deep Learning
Следующий параграф
16.2. Матричная факторизация

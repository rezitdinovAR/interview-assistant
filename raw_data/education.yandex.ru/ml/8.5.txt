---
title: Диффузионные модели
url: https://education.yandex.ru/handbook/ml/article/diffuzionnye-modeli
course: ml
chapter: 8. Генеративные модели
chapter_id: 8.5
---
В этом параграфе мы снова попробуем решить задачу генерации, когда нам дана выборка объектов из распределения
∼q(x), и хотим научиться генерировать новые объекты из распределения , которых нет в нашей выборке.
Вероятно, вы уже знакомы с другими генеративными моделями, например VAE или GAN-ы. Здесь же мы познакомим вас с еще одним видом генеративных моделей: диффузионные модели, которые стали крайне популярны в последнее время благодаря своему высокому качеству генерации объектов из заданного распределения. В общий чертах, они работают следующим образом: берем шум из
N(0,I) и шаг за шагом удаляем компоненты шума до тех пор, пока не получим объект
x
0
x
0
из распределения, см. иллюстрацию ниже.
Screenshot
Более детально
Для детального понимания стоит объяснить, что такое прямой и обратный диффузионные процессы. Прямой процесс заключается в постепенном зашумлении картинки с помощью распределения
q
q, а обратный, наоборот, в расшумлении с помощью распределения
p
p. Их можно схематично изобразить следующим образом:
Artboard
Прямой диффузионный процесс определяется как апостериорное распределение
q(x
1:T
∣x
0
). Это распределение также является Марковской цепочкой, которая постепенно добавляет гауссовский шум к объекту
x
0
x
0
. На каждом шаге шум добавляется с различной магнитудой, которая определяется расписанием дисперсий
,...,β
T
}. При правильном выборе расписания в пределе по числу шагов
T
T мы должны сойтись к шуму из
N(0,I). В качестве распределений
q
q берут нормальные распределения:
q(x
t
∣x
t−1
):=N(x
t
;
1−β
t
x
t−1
,β
t
I),       q(x
1:T
∣x
0
)=
t=1
∏
T
q(x
t
∣x
t−1
)
Теперь перейдем к обратному процессу и к самой диффузионной модели.
Диффузионная модель - это вероятностная модель с латентными переменными вида
):=∫p
θ
(x
0:T
)dx
1:T
, где промежуточные состояния
,...,x
T
соответствуют зашумленным объектам, a
x
0
x
0
- объект из распределения. Совместное распределение
0:T
) называет обратным диффузионным процессом, который представляет собой Марковскую цепочку из гауссовских распределений
i−1
p(x
0:T
)=p(x
0
)
t=1
∏
T
p
θ
(x
t−1
∣x
t
)         p
θ
(x
T
)=N(x
T
∣0,I)
t−1
∣x
t
):=N(x
t−1
;μ
θ
(x
t
,t),Σ
θ
(x
t
,t))
Таким образом, обратный процесс параметризуется моделью
θ
θ, которая по зашумленному объекту
x
t
x
t
и шагу
t
t предсказывает среднее
,t) и дисперсию
,t).
Обучение диффузионной модели
Диффузионный модели обучаются, максимизируя вариационную нижнюю оценку (ELBO) логарифма правдоподобия
log
logp
θ
(x
0
). По тому же принципу обучаются VAE, с тем лишь отличием, что у диффузионных моделей другая форма модели с латентными переменными. Итак, давайте выведем ELBO для диффузии:
−
log
log
log
log
log
log
log
log
Let
L
VLB
log
log
−logp
θ
(x
0
)
Let L
VLB
≤−logp
θ
(x
0
)+D
KL
(q(x
1:T
∣x
0
)∥p
θ
(x
1:T
∣x
0
))
=−logp
θ
(x
0
)+E
x
1:T
∼q(x
1:T
∣x
0
)
[log
p
θ
(x
0:T
)
q(x
1:T
=−logp
θ
(x
0
)+E
q
[log
p
θ
(x
0:T
)
q(x
1:T
∣x
0
)
+logp
[log
p
θ
(x
0:T
)
q(x
1:T
∣x
0
)
]
=E
q(x
0:T
)
[log
p
θ
(x
0:T
)
q(x
1:T
∣x
0
)
]≥−E
q(x
0
)
logp
θ
(x
0
)
Комментарий
Если вы знакомы с VAE, то вывод
L
V
L
B
L
VLB
должен быть вам понятен, однако ниже приведен вывод с помощью неравенства Йенсена
log
log
log
log
log
log
VLB
L
CE
=−E
q(x
0
)
logp
θ
(x
0
)
=−E
q(x
0
)
log(∫p
θ
(x
0:T
)dx
1:T
)
=−E
q(x
0
)
log(∫q(x
1:T
∣x
0
)
q(x
1:T
0:T
)
dx
1:T
)
=−E
q(x
0
)
log(E
q(x
1:T
∣x
0
)
q(x
1:T
0:T
)
)
≤−E
q(x
0:T
)
log
q(x
1:T
0:T
)
=E
q(x
0:T
)
[log
p
θ
(x
0:T
)
q(x
1:T
∣x
0
)
]=L
VLB
Теперь вернемся к распределению
q(x
t
∣x
t−1
). Для того чтобы получить
x
t
x
t
, придется итеративно получать
,...,x
t−1
. Однако это можно сделать более эффективно благодаря нормальным распределениям. Для этого обозначим
:=1−β
:=∏
i=1
t
α
i
, тогда
q(x
t
∣x
0
)=N(x
,(1−
α
ˉ
t
)I)
Формальный вывод этого факта
где
где
q(x
t−1
+
1−α
t
z
t−1
; где z
t−1
,z
t−2
,⋯∼N(0,I)
=
α
t
(
α
t−1
x
t−2
+
1−α
t−1
z
t−2
)+
1−α
t
z
t−1
=
α
t
α
t−1
x
t−2
+
1−α
t
α
t−1
z
ˉ
t−2
; где
z
ˉ
t−2
∼N(0,I)  (∗)
=N(x
,(1−
α
ˉ
t
)I)
(*) Пояснение ко второму переходу. У нас выходит
где
(1−α
t−1
)
z
t−2
+
1−α
t
z
t−1
=
α
t
(1−α
t−1
)+(1−α
t
)
z
ˉ
t−2
=
1−α
t
α
t−1
z
ˉ
t−2
; где z
t−1
,z
t−2
,
z
ˉ
t−2
∼N(0,I)
Тогда
L
V
L
B
L
VLB
может быть переписано как
log
VLB
(q(x
T
∣x
0
)∥p
θ
(x
T
))
++
t=2
∑
T
L
t−1
D
KL
(q(x
t−1
∣x
t
,x
0
)∥p
θ
(x
t−1
∣x
t
))
L
0
−logp
Долгий вывод
Серым в скобках комментарий к последующему переходу.
L
VLB
log
(расписываем
совместное
распределение)
=
E
q
[
log
(берем
логарифм)
=
E
q
[
−
log
log
(отщепляем
члены
суммы)
=
E
q
[
−
log
log
log
(*)
=
E
q
[
−
log
log
log
(лог
произведения
раскрываем)
=
E
q
[
−
log
log
log
log
(от
второй
суммы
останется
только
1ый
и
последний
член)
=
E
q
[
−
log
log
log
log
(комбинируем
1
и
3
член,
3
и
4
член)
=
E
q
[
log
log
log
log
VLB
=E
q(x
0:T
)
[log
p
θ
(x
0:T
)
q(x
1:T
∣x
0
)
](расписываем совместное распределение)
=E
q
[log
p
θ
(x
T
)∏
t=1
T
p
θ
(x
t−1
∣x
t
)
∏
t=1
T
q(x
t
∣x
t−1
)
]   (берем логарифм)
=E
q
[−logp
θ
(x
T
)+
t=1
∑
T
log
p
θ
(x
t−1
∣x
t
)
q(x
t
∣x
t−1
)
](отщепляем члены суммы)
=E
q
[−logp
θ
(x
T
)+
t=2
∑
T
log
p
θ
(x
t−1
∣x
t
)
q(x
t
∣x
t−1
)
+log
q(x
1
∣x
0
)
](*)
=E
q
[−logp
θ
(x
T
)+
t=2
∑
T
log(
p
θ
(x
t−1
∣x
t
)
q(x
t−1
q(x
t−1
∣x
0
)
q(x
t
∣x
0
)
)+log
q(x
1
∣x
0
)
](лог произведения раскрываем)
=E
q
[−logp
θ
(x
T
)+
t=2
∑
T
log
p
θ
(x
t−1
∣x
t
)
q(x
t−1
t=2
∑
T
log
q(x
t−1
∣x
0
)
q(x
t
∣x
0
)
+log
q(x
1
∣x
0
)
](от второй суммы останется только 1ый и последний член)
=E
q
[−logp
θ
(x
T
)+
t=2
∑
T
log
p
θ
(x
t−1
∣x
t
)
q(x
t−1
∣x
t
,x
0
)
+log
q(x
1
∣x
0
)
q(x
T
∣x
0
)
+log
q(x
1
∣x
0
)
](комбинируем 1 и 3 член, 3 и 4 член)
=E
q
[log
p
θ
(x
T
)
q(x
T
∣x
0
)
+
t=2
∑
T
log
p
θ
(x
t−1
∣x
t
)
q(x
t−1
∣x
t
,x
0
)
−logp
(q(x
T
∣x
0
)∥p
θ
(x
T
))
+
t=2
∑
T
L
t−1
D
KL
(q(x
t−1
∣x
t
,x
0
)∥p
θ
(x
t−1
∣x
t
))
L
0
−logp
Пояснение (*). Пользуемся тем, что у нас Марковский процесс, и теоремой Байеса:
q(x
t
∣x
t−1
)=q(x
t
∣x
t−1
,x
0
)=
q(x
t−1
∣x
0
)
q(x
t−1
∣x
t
,x
0
)q(x
t
∣x
0
)
Таким образом во время обучения, на каждой итерации параллельно оптимизируются случайные член
L
t
L
t
с помощью градиентного спуск (сэмлируем
t∼U{1,...,T}). Поскольку все распределения нормальные, то KL между ними можно выписать в явной форме (см. ниже).
Формула KL между двумя нормальными
KL(N
1
∣∣ N
2
)=
2
1
(Tr(Σ
2
−1
Σ
1
)+(μ
+ln
det(Σ
1
)
det(Σ
2
)
−d)
Если
I, Σ
KL(N
1
∣∣ N
+ln
σ
1
σ
2
)
Осталось только выписать
q(x
t−1
∣x
t
,x
0
) . Мы знаем, поскольку у нас все распределения нормальные, то и
q(x
t−1
∣x
t
,x
0
) будет нормальным.
Обозначим
q(x
t−1
∣x
t
,x
0
)=N(x
t−1
Вывод
q(x
t−1
∣x
t
,x
0
)
Применим формулу Байеса и распишем. Тут мы просто пытаемся понять, как будут выглядеть среднее и дисперсия, выделяя квадратичную форму в показателе экспоненты
q(x
t−1
∣x
t
,x
0
)=q(x
t
∣x
t−1
,x
0
)
q(x
t
∣x
0
)
q(x
t−1
∣x
0
)
∝
∝
exp
∝exp(−
t−1
t−1
(x
t−1
−
α
ˉ
t−1
exp
=exp(−
t−1
+α
t
x
t−1
2
+
1−
α
ˉ
t−1
x
t−1
2
−2
α
ˉ
t−1
x
0
x
t−1
+
α
ˉ
t−1
))=
=
exp
=exp(−
t−1
1
)x
t−1
t−1
2
α
ˉ
t−1
x
0
)x
t−1
+C(x
t
,x
0
)))
Далее перепишем красные и синие выражения в более красивой форме
=1/(
t−1
1
)=1/(
β
t
(1−
α
ˉ
t−1
t−1
)=(
t−1
α
ˉ
t−1
x
0
)/(
t−1
t−1
α
ˉ
t−1
t−1
(1−
α
ˉ
t−1
t−1
β
t
x
0
Другой лосс. Предсказываем шум
В прошлой подсекции наша модель предсказывала среднее и дисперсию нормального распределения. Давайте зафиксируем
,t)=σ
t
2
I. Обычно берут
или
t−1
β
t
. Тогда
L
t
−
1
L
t−1
из предыдущей секции можно переписать как
]+const(θ)
Это первый момент, как меняется функционал, если мы не хотим предсказывать
,t), а фиксируем её.
Теперь вспомним, что
q(x
t
∣x
0
)=N(x
,(1−
α
ˉ
t
)I), но благодаря тому, что у нас гауссовское распределение, это можно переписать в виде
,ϵ)=
ϵ,   ϵ∼N(0,I)
Выразим отсюда
x
0
x
0
и получим, что
ϵ), тогда подставим это выражение в формулу для
) (из подсекции «Вывод
q(x
t−1
∣x
t
,x
0
)») и получим
Теперь скажем, что наша модель будет предсказывать
ϵ
ϵ. И просто будем «подставлять» его в выражение для
μ
~
μ
~
выше. Обозначим предсказание модели как
,t) — предсказанный шум
ϵ
ϵ. Тогда лосс
L
t
L
t
превратиться в
(1−
∥ϵ−ϵ
+(1−
α
ˉ
t
)ϵ,t)∥
2
]
Тем не менее лосс можно еще больше упростить и просто обучать с помощью MSE на
simple
=E
x
0
,ϵ,t
[∥ϵ−ϵ
+(1−
α
ˉ
t
)ϵ,t)∥
2
]
Итак, алгоритмы обучения и сэмплирования выглядят вот так (на картинке
z
:
=
ϵ
z:=ϵ).
Алгоритм обучения и сэмплирования диффузионной модели (Изображение взято из: Ho et al. 2020)
Стоит отметить, что важным недостатком диффузионных моделей является низкая скорость сэмплирования. Согласно Song et al. 2020: «Требуется 20 часов на генерацию 50 тысяч картинок размера 32х32, используя DDPM, и меньше минуты, используя GAN» (Nvidia 2080 Ti GPU). Тем не менее, в данном направлении был достигнут значительный прогресс и в целом проблема медленного сэмплирования была частично решена: Jiaming Song et al. (2021), Kong & Ping (2021), Bond-Taylor et al. (2021)
Давайте зафиксируем, какие функции потерь можно использовать. Для всех них справедлив тот факт, что мы сэмплируем шаг равномерно во время обучение
t∼U{1,...,T}) и оптимизируем соответствующий
L
t
L
t
.
Оптимизируя член из суммы
L
V
L
B
L
VLB
. Это KL дивергенция между двумя нормальными распределениями
log
VLB
(q(x
T
∣x
0
)∥p
θ
(x
T
))
++
t=2
∑
T
L
t−1
D
KL
(q(x
t−1
∣x
t
,x
0
)∥p
θ
(x
t−1
∣x
t
))
L
0
−logp
При фиксированной дисперсии
Σ
θ
Σ
θ
можно оптимизировать взвешенную MSE между средними нормальных распределений
]+const(θ)
При фиксированной дисперсии и при предсказании шума с помощью взвешенной MSE. Или просто MSE.
simple
является самым популярным вариантом, который на практике дает лучшие результаты.
(1−
∥ϵ−ϵ
+(1−
α
ˉ
t
)ϵ,t)∥
2
]
L
t
simple
=E
x
0
,z
[∥ϵ−ϵ
+(1−
α
ˉ
t
)ϵ,t)∥
2
]
Выбор расписания
β
t
β
t
Расписание является гиперпараметром, основными требованиями на который являются невозрастание
≤...≤β
T
) и чтобы прямой процесс сходился к
N(0,I) в пределе по
T
T. Второе может гарантироваться тем, что
→0. Вспомним,
q(x
t
∣x
0
)=N(x
,(1−
α
ˉ
t
)I)
Однако на практике оно также проверяется, чтобы
(q(x
T
∣x
0
)∣∣N(0,I)) было близко к 0.
Также стоит упомянуть, что обычно берут
T
=
1000
T=1000. Но также важно помнить про требования выше, ведь расписание шума непосредственно зависит от
T
T.
Чаще всего используют линейное расписание, где
0.02
β
1
=10
−4
, β
T
=0.02. У данных констант нет никакой мотивации, кроме той, которая описана выше. Они были предложены в Ho et al. (2020).
В Nichol & Dhariwal (2021) было предложено косинусное расписание, которое помогло диффузионным моделям достичь лучшего NLL (negative loglikelihood):
β
t
=
clip
0.999
where
f
(
t
)
=
cos
=clip(1−
α
ˉ
t−1
α
ˉ
t
,0.999)
α
ˉ
t
=
f(0)
f(t)
where f(t)=cos(
1+s
t/T+s
⋅
2
π
)
Авторы обнаружили, что линейное расписание плохо работает на картинках 64х64 и меньше. А именно, последнии шаги прямого прохода были шумными и малоинформатиыными (просто зашумляем шум еще больше):
Пример зашумления картинки для линейного (сверху) и косинусного (снизу) расписания.
Также они обнаружили, что если обучать модель с линейным расписанием только на 80% первых шагов, то модель не становится сильно хуже, что подтверждает неиформативность последних шагов. Далее, они подобрали расписание так, чтобы
убывало линейно на большей части отрезка (от 0 до
T
T) и почти не менялось рядом с 0 и
T
T. Разницу в
для разных расписаний можно увидеть на картинке ниже:
Изображение взято из Nichol & Dhariwal, 2021
Детали
Также они ограничивают
β
t
β
t
числом 0.999, чтобы в конце процесса не было проблем с численной устойчивостью. Коэффициент
s
s используется, чтобы
β
t
β
t
не были слишком малы рядом с нулем. Он равен 0.008. Такое число было выбрано так, чтобы «
β
0
β
0
была немного меньше, чем размер бина одного пикселя, то есть
1
/
127.5
1/127.5»
Classifier guidance
В Nichol & Dhariwal (2021) был предложен метод условной генерации, который повышает качество генерируемых картинок, при этом уменьшая их разнообразие. Для этого предобучается «шумный» классификатор на зашумленных картинках, то есть
(y∣x
t
). Затем он используется во время сэмплирования, корректируя предсказанное среднее на
∇
x
log
logp
ϕ
(y∣x
t
). В Nichol & Dhariwal (2021) (Секция 4.1) показывают, что данная добавка позволяет превратить распределение
i−1
∣x
i
) в
i−1
∣x
i
,y). Важно, что исходная диффузионная модель никак не меняется, что делает трюк еще более привлекательным. Алгоритм сэмплирования можно видеть на картинке ниже. Коэффициент
s
s отвечает за силу guidance.
Мотивация
У генеративной модели GAN есть способ, который позволяет «балансировать» между разнообразием картинок и их качеством — truncation trick. Он заключается в сэмплировании латентного вектора truncated normal distibution. Данный трюк был хорошо описан и исследован в статье про BigGAN. Поэтому в диффузионных моделях тоже хотелось бы иметь метод, который позволяет балансировать между качеством и разнообразием. Авторы предложили classifier guidance, сравнили его с truncation trick и показали, что их метод строго лучше.
Изображение взято из Nichol & Dhariwal, 2021
Classifier-free guidance
Ho & Salimans (2021) предложили метод, в котором guidance достигается без использования дополнительной модели, поскольку это достаточно затратно. Для этого они обучали условную модель
∣y), у которой во время обучения реальная метка
y
y заменялась с какой-то фиксированной вероятностью (10%) на пустую метку (
y
=
∅
y=∅). Это по сути позволяет нам обучать безусловную модель
) одновременно с условной
∣y)Тогда во время сэмплирования делаем так, чтобы предсказание немного менялось в сторону
∣y), а именно:
∣y)=ϵ
θ
(x
t
∣∅)+s⋅(ϵ
θ
(x
t
∣y)−ϵ
θ
(x
t
∣∅))
Мотивация этой формулы следовала из формулы Байеса:
log
log
log
log
log
log
log
p(y∣x
t
)∝
p(x
t
)
p(x
t
∣y)
⟹logp(y∣x
t
)∝logp(x
t
∣y)−logp(x
t
)
⟹∇
x
t
logp(y∣x
t
)∝∇
x
t
logp(x
t
∣y)−∇
x
t
logp(x
t
)
⟹∇
x
t
logp(y∣x
t
)∝ϵ(x
t
∣y)−ϵ(x
t
)
Тогда мы можем просто подставить
∇
x
t
log
logp(y∣x
t
) в формулу для classifier guidance из предыдущей подсекции и получить желаемое равенство с точностью до коэффициента
s
s.
Овервью ключевых работ на сегодняшний день
Jonathan Ho et al. «Denoising diffusion probabilistic models.» arxiv Preprint arxiv:2006.11239 (2020)
Основная работа, в которой диффузионные модели (Denoising Diffusion Probabilistic Models, DDPMs) были применены для генерации картинок. Параграф в основном построен на ней.
Jiaming Song et al. «Denoising diffusion implicit models.» arxiv Preprint arxiv:2010.02502 (2020)
Одна из первых попыток ускорить генерацию объектов. Идея следущая: давайте изменим прямой диффузионный процесс так, чтобы используя предобученную DDPM, приближать новый обратный процесс за меньшее число шагов.
Чтобы не обучать новую модель, нам нужен прямой диффузионный процесс, у которого будет такая же (суррогатная) функция потерь, а обратный процесс все еще останется Марковским. Оказалось, что существует целое семейство не-Марковских прямых процессов, удовлетворяющих этим требования. Это семейство имеет следующий вид:
1:T
∣x
0
):=q
t=2
∏
T
q
σ
(x
t−1
∣x
t
,x
0
),
где
)=N(
α
t
x
0
,(1−α
t
)I) и для всех
t
>
1
,
t>1,
t−1
∣x
t
,x
0
)=N(
α
t−1
x
0
+
1−α
t−1
−σ
t
2
⋅
1−α
Среднее было выбрано так, чтобы
)=N(
α
t
x
0
,(1−α
t
)I) для всех
t
t. (см. Лемму 1 в Приложении B к статье). То есть важно лишь то, чтобы маргинальное распределение
) не менялось по сравнению с обычным Марковским случаем. Прямой процесс может быть получен с помощью теоремы Байеса:
t−1
t−1
t−1
Тут
σ
σ контролирует степень стохастичности прямого процесса. Можно заметить, что в отличии от исходного диффузионного процесса, предложенный прямой процесс больше не является Марковским, так как каждый
x
t
x
t
теперь зависит и от
x
t
−
1
x
t−1
и от
x
0
x
0
. Схематично, это можно изобразить как на картинке справа. (Слева исходный диффузионный процесс для сравнения)
Screen
Заметка
Авторы обращают внимание, что функция потерь в DDPM зависит от
q(x
t
∣x
0
), а не от
q(x
1
:x
T
∣x
0
) напрямую. Это означает, что нам нужно выбрать любой другой прямой диффузионный процесс, у которого
q(x
t
∣x
0
) остались те же.
Далее, мы можем переписать обратный процесс в данном виде:
t−1
=
α
t−1
"predictedx
1−α
t
ϵ
θ
(t)
(x
t
)
+
"directionpointingtox
t
"
1−α
t−1
−σ
t
2
⋅ϵ
θ
(t)
(x
t
)
+
randomnoise
σ
t
ϵ
t
Заметим, что при
(1−α
t−1
)(1−α
t
)
1−α
t
/α
t−1
прямой процесс становится марковским, а обратный как у DDPM (обычное сэмплирование, описанное в основной секции). При
=0 процесс сэмплирования становится детерминистичным (данный способ и называется DDIM). Ускорение сэмплирования достигается засчет использования лишь какого-то подмножества шагов (
0≤τ
1
≤...≤τ
S
≤T,   S<T). Также одним из плюсов детерминистичного сэмплирования является возможность делать семантическую интерполяцию в латентном пространстве (как у GANов).
Alex Nichol & Prafulla Dhariwal. «Improved denoising diffusion probabilistic models» arxiv Preprint arxiv:2102.09672 (2021)
Улучшение DDPM, в котором был предложен новое расписание шума, что улучшило NLL. Также был изучен вариант, в котором дисперсия
,t) предсказывается моделью.
Prafula Dhariwal & Alex Nichol. «Diffusion Models Beat GANs on Image Synthesis.» arxiv Preprint arxiv:2105.05233 (2021).
Статья, в которой показывается, что DDPM могут генерировать более качественные картинки по сравнению с GANами. Также был предложен метод conditional сэмплирования. Для этого предобучается классификатор на зашумленных сэмплах, а во время сэмплирования среднее нормального распределения «корректируется» на градиент классификатора.
Jacob Austin et al. «Structured Denoising Diffusion Models in Discrete State-Spaces».arXiv:2107.03006 (2021)
Диффузионные модели на дискретных данных (например, текст). Вместо нормальных распределений используются категориальные. Также была обобщена мультиномиальная диффузия с помощью «матриц перехода», которые задают способ зашумления дискретных данных.
Более подробно: у нас есть
∈{1,...,K} — дискретная величина на всех шагах диффузии, тогда для каждого шага
t
t определена матрица прямого перехода
Q
t
Q
t
такая, что
=q(x
t
=j∣x
t−1
=i). То есть строки матрицы суммируются в единицу. Тогда если обозначить через
one-hot-закодированную версию
x
t
x
t
, то прямой процесс можно описать через категориальные распределения:
q(x
t
∣x
t−1
)=Cat(x
t
;p=x
t−1
Q
t
)
Как и в нормальных распределениях, можем выписать
где
q(x
t
∣x
0
)=Cat(x
t
;p=x
0
Q
ˉ
t
),   где
...Q
q(x
t−1
∣x
t
,x
0
)=Cat(x
t−1
;p=
t−1
)
Поскольку тут нет такой хорошей параметризации через
ϵ
ϵ, как у нормальных распределений, то единственный способ обучать — с помощью KL дивергенции (членами
L
V
L
B
L
VLB
).
Остается только понять, как выбирать
Q
t
Q
t
. Помимо того, чтобы сумма в каждой строчке была один, требуется, чтобы
сходилось (при
t
→
∞
t→∞) к равномерному распределению в каждой строчке (аналог нормального шума). За конкретными примерами стоит обратиться к статье.
Серия работ про text-conditional diffusions: GLIDE, ImaGen, DALLE-2
Опишем работу метода GLIDE. Стоит задача генерировать картинки по заданному текстовому описанию. Для этого используется classifier-free guided diffusion model или CLIP. Это два разных варианта модели, которые авторы сравнивают. В первом случае модель обуславливается на эмбеддинги текста, которые были получены из обучаемого трансформера. Во втором случае guidance осуществляется за счет
⟨f(x
t
),g(c)⟩ (это по сути градиент лосса метода CLIP) . Тут
f
f — это картиночный энкодер (на зашумленных картинках), а
g
g — это энкодер текстового входа. В целом, авторы получили, что classifier-free guidance генерирует более качественные картинки.
Song et al. «Score-Based Generative Modeling through Stochastic Differential Equations»
Способ описать диффузионные модели через стохастические дифференциальные уравнения.
What are Diffusion Models?. Прекрасный блог от Lilian Weng (OpenAI).
Знак вопроса
Пройдите квиз по параграфу
Чтобы закрепить пройденный материал
Сообщить об ошибке
Предыдущий параграф
8.4. Нормализующие потоки
Следующий параграф
8.6. Языковые модели

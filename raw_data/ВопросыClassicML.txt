1. Общие вопросы по линейной регрессии
Вопрос: Что такое линейная регрессия и как она работает?
Ответ: Линейная регрессия – это алгоритм машинного обучения, используемый для прогнозирования, основанного на линейной зависимости между входными и выходными данными. Она задаётся формулой линейной функции:
y=wX+by = wX + by=wX+b,
где X – матрица входных признаков, w – матрица весов признаков, b – смещение (bias). Модель подбирает оптимальные параметры w и b, чтобы минимизировать ошибку между предсказаниями и реальными значениями.
________________


2. Преимущества линейной регрессии
Вопрос: Какие преимущества у линейной регрессии?
Ответ:
* Простота и интерпретируемость: легко понять и объяснить результаты.
* Эффективность: низкая вычислительная сложность, быстрое обучение на больших наборах данных.
* Гибкость: может быть расширена до полиномиальных и взаимодействующих признаков.
________________


3. Функция потерь в линейной регрессии
Вопрос: Какая функция потерь используется в линейной регрессии?
Ответ: Обычно используется среднеквадратичная ошибка (Mean Squared Error, MSE), которая измеряет среднеквадратичное отклонение предсказанных значений от фактических.
Вопрос: Почему в линейной регрессии используется квадратичная функция потерь?
Ответ:
* Простота: квадратичная форма удобна для вычислений.
* Выпуклость: квадратичная функция имеет один глобальный минимум, что упрощает оптимизацию.
* Интерпретируемость: минимизация MSE позволяет находить параметры модели с наилучшей вероятностью.
* Математическая удобность: методы вроде метода наименьших квадратов легко применяются.
________________


4. Обучение линейной регрессии
Вопрос: Как обучается модель линейной регрессии?
Ответ:
Модель обучается с помощью методов оптимизации, таких как градиентный спуск, чтобы найти оптимальные значения весов w и смещения b. В качестве функции потерь используется MSE.
Вопрос: Что представляет собой предсказание линейной регрессии?
Ответ:
Предсказание – это линейная комбинация входных признаков и весов:
y=wX+b.
________________


5. Проблемы и ограничения линейной регрессии
Вопрос: В чём заключаются основные проблемы линейной регрессии?
Ответ:
* Линейная зависимость: плохо справляется с моделированием сложных нелинейных зависимостей.
* Чувствительность к выбросам: выбросы сильно влияют на качество модели.
* Проблемы с мультиколлинеарностью: сильно коррелированные признаки ухудшают качество модели.
Вопрос: Как можно модифицировать линейную регрессию для работы с нелинейными зависимостями?
Ответ:
Можно использовать полиномиальные признаки, преобразовав задачу в полиномиальную регрессию.
________________


6. Регуляризация и большие веса
Вопрос: Какие проблемы возникают при больших значениях весов в линейной регрессии?
Ответ: Большие веса могут привести к переобучению модели, что снижает её обобщающую способность.
Вопрос: Как справляться с большими весами?
Ответ: Используются методы регуляризации:
* L1-регуляризация (Lasso): добавляет штраф за модуль весов.
* L2-регуляризация (Ridge): добавляет штраф за квадрат весов.
________________


7. Метрики регрессии
Вопрос: Какие метрики используются для оценки качества линейной регрессии?
Ответ:
* MAE (Mean Absolute Error): средняя абсолютная ошибка.
* MSE (Mean Squared Error): среднеквадратичная ошибка.
* RMSE (Root Mean Squared Error): корень из MSE.
* MAPE (Mean Absolute Percentage Error): средняя абсолютная ошибка в процентах.
* R^2 (коэффициент детерминации): доля объяснённой дисперсии целевой переменной.
Вопрос: Какая метрика более чувствительна к выбросам: MSE или MAE?
Ответ: MSE более чувствительна к выбросам, так как штрафует их сильнее за счёт возведения ошибки в квадрат. MAE более устойчива и интерпретируема.
8. Регуляризация
Вопрос: Чем отличаются L1- и L2-регуляризация?
Ответ:
* L1-регуляризация (Lasso): добавляет штраф за абсолютную сумму весов (∑ |w_i|), что может занулять некоторые веса, делая модель разреженной.
* L2-регуляризация (Ridge): добавляет штраф за сумму квадратов весов (∑w_i^2​), что уменьшает значения весов, но не зануляет их.
Вопрос: Что такое ElasticNet?
Ответ: ElasticNet – это комбинация L1- и L2-регуляризации. Позволяет учитывать преимущества обеих методик: разреженность (L1) и контроль над большими весами (L2).

________________


9. Особенности обработки данных
Вопрос: Почему важно масштабировать признаки перед использованием линейной регрессии?
Ответ: Линейная регрессия чувствительна к масштабу признаков, так как большие значения одних признаков могут доминировать над малыми значениями других. Масштабирование приводит признаки к одному диапазону, улучшая устойчивость модели.

Вопрос: Как линейная регрессия обрабатывает категориальные признаки?
Ответ:
Категориальные признаки преобразуются в числовую форму с помощью методов:
1. One-Hot Encoding: создаёт бинарные столбцы для каждой категории.
2. Label Encoding: кодирует категории числами (подходит для упорядоченных категорий).
10. Интерпретация результатов
Вопрос: Как интерпретировать коэффициенты линейной регрессии?
Ответ: Коэффициенты показывают, как изменение значения независимого признака на единицу влияет на значение целевой переменной при фиксированных значениях других признаков.
Вопрос: Что такое R^2 и как его интерпретировать?
Ответ: R^2 (коэффициент детерминации) показывает долю дисперсии зависимой переменной, объяснённой регрессией. Значение от 0 до 1:
* R^2 = 1: модель полностью объясняет вариативность данных.
* R^2 = 0: модель не объясняет вариативность данных.
________________


11. Диагностика модели
Вопрос: Как проверить наличие мультиколлинеарности в данных?
Ответ: Используются методы:
1. Матрица корреляций: высокие корреляции между независимыми переменными указывают на мультиколлинеарность.
2. VIF (Variance Inflation Factor): если VIF>5−10VIF > 5-10VIF>5−10, то мультиколлинеарность значительна.
Вопрос: Какие графики помогают проверить качество линейной регрессии?
Ответ:
1. График остатков (Residual Plot): показывает, распределены ли ошибки случайно.
2. QQ-график: проверяет нормальность остатков.
3. График предсказаний против фактических значений: оценивает точность модели.
4. График остатков против прогнозов: выявляет проблемы с гомоскедастичностью.
Вопрос: Что такое мультиколлинеарность и как с ней бороться?
Ответ:  
________________


Логистическая регрессия  
  
1. Основные концепции
Вопрос: Что такое логистическая регрессия?
Ответ: Логистическая регрессия – это алгоритм бинарной классификации, который используется для прогнозирования вероятности принадлежности объекта к определённому классу. Она преобразует линейную комбинацию признаков в вероятность с помощью логистической (сигмоидной) функции.
________________


Вопрос: В чём разница между логистической и линейной регрессией?
Ответ:
* Линейная регрессия предсказывает непрерывные значения, тогда как логистическая регрессия предсказывает вероятность принадлежности к классу.
* Логистическая регрессия использует логистическую (сигмоидную) функцию для сжатия выхода в диапазон [0, 1].
* В логистической регрессии минимизируется логистическая функция потерь (кросс-энтропия), а не среднеквадратичная ошибка.
________________


Вопрос: Как получить логистическую регрессию из линейной?
Ответ:  
формула лог. регрессии целиком
  

2. Математическая модель
Вопрос: Как выглядит формула логистической регрессии?
Ответ:  
________________


Вопрос: Что такое логит?
Ответ:.
  

________________


3. Обучение модели
Вопрос: Как обучается логистическая регрессия?
Ответ: Логистическая регрессия обучается с использованием методов оптимизации, таких как градиентный спуск. Задача состоит в минимизации логистической функции потерь (кросс-энтропии), которая измеряет расхождение между истинными и предсказанными вероятностями.
________________


Вопрос: Как выглядит формула кросс-энтропии (Binary Cross Entropy)?
Ответ:
  

4. Принципы работы
Вопрос: Как логистическая регрессия разделяет классы?
Ответ: Логистическая регрессия использует логистическую функцию для предсказания вероятности принадлежности к классу. Если вероятность выше порога (обычно 0.5), объект относят к классу 1, иначе – к классу 0.
________________


Вопрос: Как проверить статистическую значимость коэффициентов в логистической регрессии?
Ответ:
* Используются z-тест или t-тест, чтобы проверить гипотезу, что коэффициент равен нулю.
* Рассчитывается p-value: если оно меньше уровня значимости (α), коэффициент считается значимым.
* Статистические пакеты автоматически проводят такие проверки при оценке модели.
Проверка статистической значимости коэффициентов в логистической регрессии – пример с расчётом стандартной ошибки (SE)
________________


Ситуация:
Вы строите модель логистической регрессии, чтобы предсказать, купит ли человек продукт (y=1) или нет (y=0). В модели есть два признака:
1. Цена продукта (x_1​)
2. Реклама (x_2​), кодируется как 1, если человек видел рекламу, и 0 – если нет.
После обучения модели нужно проверить, является ли коэффициент для цены (β_1​) статистически значимым.
________________


Данные:
  

________________


Шаг 1: Вычисление стандартной ошибки (SE)  
________________


Упрощённый расчёт SE:  
________________


  

________________


5. Метрики для логистической регрессии
Вопрос: Какие метрики применяются для оценки логистической регрессии?
Ответ:
* Accuracy (точность) – доля правильных предсказаний.
* Precision (точность) – доля истинных положительных среди предсказанных положительных.
* Recall (полнота) – доля истинных положительных среди реальных положительных.
* F1-score – гармоническое среднее Precision и Recall.
* AUC-ROC – площадь под кривой ROC, измеряет способность модели различать классы.
________________


Вопрос: Почему F1-score не является простым средним между Precision и Recall?
Ответ: F1-score рассчитывается как гармоническое среднее:  
Гармоническое среднее более чувствительно к дисбалансу между Precision и Recall, чем обычное среднее.
6. Особенности и ограничения
Вопрос: Какие предположения делает логистическая регрессия?
Ответ:
1. Линейность: логит (логарифм шансов) является линейной функцией признаков.
2. Независимость наблюдений: данные должны быть независимы друг от друга.
3. Отсутствие высокой корреляции между признаками (мультиколлинеарности).
________________


Вопрос: Какие ограничения есть у логистической регрессии?
Ответ:
* Плохо работает с нелинейно разделимыми данными.
* Чувствительна к выбросам.
* Требует масштабирования признаков для лучшей сходимости.
________________


Вопрос: Как справляться с ограничениями логистической регрессии?
Ответ:
* Для нелинейных зависимостей можно добавить полиномиальные признаки.
* Масштабировать данные перед обучением.
* Использовать регуляризацию (L1, L2, ElasticNet) для уменьшения переобучения.
7. Расширенные темы
Вопрос: Как логистическая регрессия справляется с несбалансированными классами?
Ответ:
1. Использование взвешенной логистической регрессии (weighted logistic regression).
2. Ресемплинг данных: oversampling (например, SMOTE) или undersampling.
3. Выбор подходящих метрик (F1-score, ROC-AUC вместо Accuracy).
________________


Вопрос: Чем отличается многоклассовая логистическая регрессия?
Ответ:
Многоклассовая логистическая регрессия использует метод:      
  

________________


SVM
  
  

1. Основная идея метода опорных векторов (SVM)
Вопрос: Что такое SVM, и как он работает?
Ответ:
SVM (Support Vector Machine) – это алгоритм машинного обучения, который используется для классификации данных. Его цель – найти такую линию (или гиперплоскость), которая лучше всего разделяет данные на классы.
Ключевая идея SVM:
* SVM не просто ищет любую разделяющую линию, а выбирает ту, которая максимально увеличивает зазор между точками двух классов.
* Точки, ближайшие к разделяющей линии, называются опорными векторами. Эти точки определяют положение линии.
________________


2. Как SVM работает с нелинейными данными
Вопрос: Что делать, если классы нельзя разделить прямой линией?
Ответ:
Если данные не разделяются прямой линией, SVM использует ядерные функции (kernels). Ядра помогают преобразовать данные в другое пространство, где классы становятся линейно разделимыми.
Пример:
* Представьте, что классы в данных образуют круги, и прямой линией их разделить нельзя. С помощью ядра данные можно "поднять" в 3D-пространство, где они станут разделимыми плоскостью.
Популярные ядра:
1. Линейное ядро: работает, если классы линейно разделимы.
2. Полиномиальное ядро: добавляет зависимости между признаками, например x^2.
3. Радиальное базисное ядро (RBF): работает с любыми сложными зависимостями.
________________


3. Отличия SVM и логистической регрессии
Вопрос: Чем отличается SVM от логистической регрессии?
Ответ:
  
________________

Вопрос: Почему SVM стремится к максимальному зазору между классами?
Ответ:
Максимальный зазор делает модель более устойчивой. Если зазор между классами большой, новые данные, даже с шумом или выбросами, с большей вероятностью будут классифицированы правильно.
________________


4. Функция потерь в SVM
Вопрос: Как SVM оценивает ошибки?
Ответ:  
________________


5. Регуляризация в SVM
Вопрос: Как SVM предотвращает переобучение?
Ответ:
  
________________
6. Применение и особенности
Вопрос: Когда использовать SVM?
Ответ:
Используйте SVM, если:
* Данные линейно или нелинейно разделимы (второе решается с помощью ядер).
* Требуется высокая точность классификации.
* Размер данных небольшой или средний (до нескольких десятков тысяч примеров).
Не используйте SVM, если:
* У вас очень большие данные (миллионы примеров), так как SVM работает медленно.
* Нужны вероятности классов (логистическая регрессия предсказывает вероятности лучше).
________________


Вопрос: Как SVM работает с несбалансированными данными?
Ответ:
SVM справляется с несбалансированными данными, добавляя веса классам. Это позволяет учитывать, что редкий класс важнее, чем более частый.
Пример:
* Если один класс составляет 90% данных, а другой – только 10%, ошибку для редкого класса можно "усилить" (увеличить её вес в функции потерь).
________________


7. Пример выбора между SVM и логистической регрессией
Вопрос: У меня миллион данных, что выбрать: SVM или логистическую регрессию?
Ответ: Выберите логистическую регрессию, если:
1. Данные линейно разделимы или можно сделать их линейно разделимыми (например, добавив полиномиальные признаки).
2. Вам нужно быстрое решение, так как логистическая регрессия обучается быстрее.
3. Вы работаете с очень большими данными, где SVM может быть слишком медленным.
SVM предпочтителен для задач, где важна точность, и размер данных относительно небольшой.


Регуляризация
  

  
  

1. Основные понятия
Вопрос: Что такое регуляризация и зачем она нужна?
Ответ:
Регуляризация — это техника, используемая для предотвращения переобучения (overfitting) моделей машинного обучения путем добавления штрафных (регуляризационных) членов к функции потерь модели. Регуляризация помогает уменьшить сложность модели и сделать её более способной к обобщению, а не к запоминанию деталей тренировочных данных. Модели с большим количеством параметров могут быть склонны к переобучению, так как они легко запоминают случайные шумы и особенности данных. Регуляризация вводит штраф за слишком большие значения параметров модели, что заставляет модель искать более простые и обобщенные решения. 
Основные задачи регуляризации:
1. Предотвращение переобучения: Регуляризация помогает уменьшить переобучение за счёт контроля сложности модели.
2. Улучшение обобщающей способности: Регуляризация позволяет модели лучше работать на новых, невидимых данных.
3. Устойчивость модели: Регуляризация делает модель менее чувствительной к изменениям в данных и выбросам.
Пример: Если модель линейной регрессии чрезмерно подгоняется под обучающие данные (с большими весами признаков), регуляризация поможет уменьшить значения весов и сделает модель более гладкой.
________________


Вопрос: Как регуляризация помогает избежать переобучения?
Ответ:
Регуляризация накладывает ограничения на величины параметров модели, что уменьшает её сложность и обобщает её поведение. Она помогает предотвратить слишком точное подстраивание модели под тренировочные данные и фокусирует её на выявлении общих закономерностей. Это помогает:
Например:
1. L1-регуляризация: Наказывает модель за использование слишком большого числа значимых признаков.
2. L2-регуляризация: Уменьшает влияние любых отдельных признаков за счёт снижения их весов.
Штраф заставляет модель избегать больших весов и учитывать только те признаки, которые наиболее важны для задачи.
________________


2. Виды регуляризации
Вопрос: Какие виды регуляризации существуют?
Ответ:  
________________


Вопрос: Какая разница между регуляризацией L1 и L2?
Ответ:
* L1 (Lasso):
   * Использует сумму абсолютных значений весов.
   * Может занулять веса (полностью исключая некоторые признаки).
   * Полезна для отбора признаков.
* L2 (Ridge):
   * Использует сумму квадратов весов.
   * Уменьшает значения весов, но не зануляет их.
   * Делает модель менее чувствительной к шуму.
* L2-регуляризация "предпочитает" уменьшить все веса пропорционально, не исключая их полностью. Это делает модель более стабильной, так как все признаки сохраняют влияние, хотя и ослабленное.
* L1-регуляризация "выбирает", какие признаки важны, зануляя остальные, что способствует разреженности модели.
________________


3. Механика работы
Вопрос: Как работают L1 и L2 регуляризации?
Ответ:  
________________


Вопрос: Почему L1-регуляризация зануляет веса?
Ответ:
Почему L1 регуляризация отбирает признаки? Понятное объяснение
  

________________


4. Связь регуляризации с переобучением
Вопрос: Что такое переобучение, и как регуляризация помогает с ним бороться?
Ответ:
Переобучение – это ситуация, когда модель слишком хорошо подстраивается под тренировочные данные, включая шум, и плохо обобщает на новые данные.
Регуляризация помогает:
* Контролировать сложность модели.
* Уменьшать влияние шумов и незначимых признаков.
* Делать модель более устойчивой к изменениям данных.
________________


Вопрос: Какие ещё методы помогают бороться с переобучением, кроме регуляризации?
Ответ:
1. Снижение сложности модели:
   * Уменьшение количества признаков.
   * Ограничение числа параметров модели.
2. Увеличение объёма данных:
   * Сбор большего количества данных.
   * Использование аугментации (например, вращение изображений).
3. Кросс-валидация:
   * Оценка модели на разных разбиениях данных (например, k-fold).
4. Раннее завершение обучения (Early Stopping):
   * Прекращение обучения, как только ошибка на валидационной выборке начинает расти.
5. Dropout (для нейросетей):
   * Случайное отключение нейронов во время обучения.
________________


5. Практические аспекты
Вопрос: Как выбрать между L1 и L2 регуляризациями?
Ответ:
* Используйте L1, если:
   * Хотите отобрать наиболее важные признаки.
   * Работаете с высокоразмерными данными.
* Используйте L2, если:
   * Хотите уменьшить переобучение, не исключая признаки.
   * Данные имеют коррелированные признаки.
* Используйте Elastic Net, если признаки коррелированы, и требуется комбинация свойств L1 и L2.
________________


Вопрос: Что такое гиперпараметр λ, и как его выбирать?
Ответ:
λ контролирует степень штрафа за сложность модели.
* Большое λ: сильная регуляризация, модель проще.
* Малое λ: слабая регуляризация, модель сложнее.
Для выбора λ используют:
1. Кросс-валидацию: Разделение данных на подвыборки для оценки качества модели.
2. Методы поиска (Grid Search, Random Search): Подбор оптимального значения с минимальной ошибкой на валидационных данных.
3. Регуляризационные пути: Построение зависимости метрик от λ\lambdaλ.
Пример: В библиотеке Scikit-learn (Ridge, Lasso), параметр α соответствует λ, и его можно настроить с помощью функции GridSearchCV.


________________


Вопрос: Как Elastic Net объединяет свойства L1 и L2 регуляризаций?
Ответ: 
  

Метрики
Чем отличается метрика от Loss?
Ответ: 
  

Что такое несимметричные метрики и зачем они нужны?
Ответ: 
  

________________


Метрики регрессии
1. Основные метрики регрессии
Вопрос: Какие основные метрики используются для оценки моделей регрессии?
Ответ:
1. MAE (Mean Absolute Error, средняя абсолютная ошибка):  
2. MSE (Mean Squared Error, среднеквадратическая ошибка):  
3. RMSE (Root Mean Squared Error, среднеквадратическое отклонение):  
4. MAPE (Mean Absolute Percentage Error, средняя абсолютная ошибка в процентах):  
5. R^2 (Коэффициент детерминации):  
________________


Какая из метрик чувствительнее к выбросам, MSE или MAE?
Ответ:
   * MSE более чувствительна к выбросам, потому что она усредняет квадраты ошибок, увеличивая вклад больших ошибок.
   * MAE менее чувствительна к выбросам, так как она усредняет абсолютные значения ошибок.
   * Выбор метрики зависит от задачи: если важнее учесть большие ошибки, выбирают MSE. Если важна устойчивость к выбросам, используют MAE.
________________


Почему RMSE чаще используется, чем MSE?
Ответ:
   * RMSE измеряется в тех же единицах, что и целевая переменная y, что делает её интерпретацию более понятной.
   * Например, если целевая переменная y измеряется в метрах, то RMSE также будет измеряться в метрах, а не в квадратных метрах, как MSE.
________________


В чём разница между MAPE и другими метриками?
Ответ:
   * MAPE измеряет ошибку в процентах, что позволяет сравнивать модели на разных наборах данных.
   * Однако MAPE чувствительна к малым значениям y, так как при делении на малые значения ошибка становится очень большой.
   * MAE, MSE, и RMSE измеряются в абсолютных значениях или в единицах исходной переменной, а не в процентах.
________________


Какую метрику выбрать для регрессии?
Ответ:
   * MAE: если важна интерпретация ошибки в исходных единицах и устойчивость к выбросам.
   * MSE: если важно сильнее «наказывать» большие ошибки.
   * RMSE: если требуется интерпретация в исходных единицах, но с учётом влияния крупных ошибок.
   * MAPE: для интерпретации ошибок в процентах.
   * R2R^2R2: для оценки объясняющей способности модели.
Метрики классификации
Какие метрики применяются для бинарной классификации?
Ответ: Основные метрики для бинарной классификации:
   1. Accuracy (Точность): Доля правильно классифицированных объектов от общего числа.
   2. Precision (Точность): Доля правильно предсказанных положительных объектов из всех объектов, предсказанных как положительные.
   3. Recall (Полнота): Доля правильно предсказанных положительных объектов из всех истинных положительных объектов.
   4. F1-Score: Гармоническое среднее между Precision и Recall.
   5. ROC-AUC (Area Under the ROC Curve): Площадь под кривой зависимости True Positive Rate (TPR) и False Positive Rate (FPR).
   6. PR-AUC (Area Under the Precision-Recall Curve):
Площадь под кривой зависимости Precision и Recall для различных порогов.
      * Преимущество: более полезна в задачах с несбалансированными классами, где положительный класс встречается редко.
      * В отличие от ROC-AUC, PR-AUC фокусируется на правильной работе модели с положительным классом.
________________


Что такое Confusion Matrix, и как она помогает в оценке модели?
Ответ:
Confusion Matrix (матрица ошибок) — это таблица, которая позволяет визуализировать результаты работы классификационной модели, сравнивая предсказанные классы с истинными.
  

Элементы матрицы:
      1. True Positive (TP): Количество объектов, правильно классифицированных как положительные.
      2. True Negative (TN): Количество объектов, правильно классифицированных как отрицательные.
      3. False Positive (FP): Количество объектов, ошибочно классифицированных как положительные (ошибки первого рода).
      4. False Negative (FN): Количество объектов, ошибочно классифицированных как отрицательные (ошибки второго рода).
  

________________


Расскажите о метрике Accuracy.
Ответ:
Описание:
Accuracy измеряет долю правильно классифицированных объектов от общего числа.
Формула:  
________________


Расскажите про метрику Precision.
Ответ:
  
________________


Расскажите про метрику Recall.
Ответ:
  
________________


Расскажите про F1-Score.
Ответ:
  


  

Какие существуют варианты агрегации Precision и Recall?
Ответ:
Для объединения Precision и Recall можно использовать разные способы агрегации, включая:  
________________


Почему для объединения Precision и Recall используют именно среднее гармоническое?
Ответ:
Среднее гармоническое выбирают, потому что оно лучше всего отражает баланс между Precision и Recall:  
Заключение:
Среднее гармоническое лучше всего подходит для задач, где важно учитывать оба аспекта (и Precision, и Recall). Оно усиливает влияние низких значений, предотвращая ситуацию, когда одна из метрик «перекрывает» другую.
________________


Чем отличаются микро- и макро-усреднения в многоклассовой классификации?
  
  
  

  

Что такое ROC-AUC, и для чего используется эта метрика?
Ответ:
ROC-AUC (Receiver Operating Characteristic - Area Under the Curve) — это метрика оценки качества бинарных классификаторов, которая измеряет способность модели различать между классами.  
Применение:
ROC-AUC особенно полезен в задачах, где нужно оценить способность модели ранжировать объекты, например, в задачах кредитного скоринга или детекции мошенничества.
________________


Как строится ROC-кривая и рассчитывается AUC?
Ответ:
ROC-кривая:  
AUC (Area Under Curve):
AUC — это площадь под ROC-кривой. Она оценивает, насколько хорошо модель различает классы.
Пример:
Если AUC = 0.8, то вероятность того, что модель правильно ранжирует случайный положительный и отрицательный объект, составляет 80%.
________________


Какие недостатки у ROC-AUC? Устойчив ли он к дисбалансу классов?
Ответ:
Недостатки ROC-AUC:
      * Чувствительность к дисбалансу:
ROC-AUC может давать высокое значение даже для моделей, плохо работающих с малым классом, так как учитывает не абсолютные значения, а относительные.
Пример при дисбалансе:
Если положительный класс составляет 1%, ROC-кривая может выглядеть высокой из-за большого числа TN, даже если модель плохо определяет TP.
  

________________


Что произойдёт с ROC-AUC, если модифицировать предсказания?
         1. Применение логарифма или добавление константы:
         * На ROC-AUC это не повлияет, так как она зависит только от порядка предсказаний, а не от их абсолютных значений.
         * График остаётся прежним, изменится только масштаб осей.
         2. Умножение на -1:
         * Порядок предсказаний перевернётся, ROC-кривая изменится, и значение метрики станет 1−ROC−AUC.
         3. Возведение в квадрат:
         * Порядок останется неизменным, ROC-AUC не изменится.
________________


Что такое PR-AUC и как она отличается от ROC-AUC?
Ответ:
  
________________


Как с помощью PR-AUC подбирать баланс между Precision и Recall?
Ответ:
         * PR-кривая позволяет выбрать оптимальный порог классификации в зависимости от задачи.
         * Если важна высокая точность (Precision, нужно искать область кривой, где Precision максимален.
         * Если важна высокая полнота (Recalll), выбираем точку с максимальным Recall.
Пример:
         * В задаче медицинской диагностики лучше повысить Recall, чтобы минимизировать пропуск болезни.
         * В задаче спам-фильтра важно максимизировать Precision, чтобы не пропускать важные письма.
________________


Какая метрика важнее: ROC-AUC или PR-AUC?
Ответ:
         * ROC-AUC лучше подходит, если классы сбалансированы и важна общая способность модели различать классы.
         * PR-AUC предпочтительнее в задачах с несбалансированными классами, где основной интерес сосредоточен на положительном классе.
Пример:
В задаче обнаружения мошенничества (1% мошеннических транзакций):
         * ROC-AUC может быть высоким даже для модели с низкой точностью.
         * PR-AUC покажет реальную картину качества модели для положительного класса.
________________


Какой ROC-AUC лучше: 0.8 или 0.1? Почему?
Ответ:
         * ROC−AUC=0.8 лучше, так как это означает, что модель хорошо различает положительный и отрицательный классы.
         * ROC−AUC=0.1 свидетельствует о перепутанных классах. Если инвертировать предсказания модели, результат станет 1−0.1=0.9, что означает хорошую способность модели.
________________


Что произойдёт с ROC-AUC, если мы продублируем выборку или изменим частоту классов?
Ответ:
         * Дублирование или изменение частот классов не повлияет на ROC-AUC, так как метрика учитывает только порядок предсказаний, а не абсолютные частоты классов.
Пример:
Если модель ранжирует классы одинаково, ROC-AUC останется неизменным, даже если увеличить выборку положительных примеров в 4 раза.
________________


Что произойдёт с PR-AUC, если продублировать классы?
Ответ:
         1. PR-AUC может измениться, так как она зависит от соотношения TP, FP, и FN.
         2. Например, увеличение положительных классов может улучшить Recall, но Precision может ухудшиться, что приведёт к изменению PR-кривой.






Деревья
  

  

  

  

  



Определение порогов для категориальных и числовых признаков
https://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e
  
  



Что такое дерево решений, и как оно работает?
Ответ:
Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.
Каждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).
Пример:
В медицинской задаче:
         * Вершина 1: "Возраст > 40 лет?"
         * Да → Вершина 2: "Курит?"
         * Нет → Прогноз: "Низкий риск заболевания".
         * Вершина 2:
         * Да → Прогноз: "Высокий риск заболевания".
         * Нет → Прогноз: "Средний риск заболевания".
  

  

________________


Как строится дерево решений?
Выбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:
         1. Перебор признаков:
         * На каждом шаге перебираются все доступные признаки в данных.
         * Для каждого признака оценивается, насколько хорошо он разделяет данные.
         2. Перебор порогов:
         * Для каждого числового признака перебираются его значения как возможные пороги разбиения.
         * Например, для признака "возраст" возможными порогами могут быть 20, 30, 40 лет и т.д.
         * Для категориальных признаков проверяются все возможные комбинации значений, например, разбиение на "да/нет".
         3. Оценка качества разбиения:
         * Для каждого разбиения вычисляется метрика качества, такая как:
         * Критерий Джини: измеряет вероятность ошибки случайного выбора класса после разбиения.
  

         * Энтропия: измеряет уровень хаотичности данных.
  

         * Для регрессии: минимизация дисперсии или среднеквадратичной ошибки (MSE).
         4. Выбор наилучшего разбиения:
         * Выбирается тот признак и порог, которые дают наибольшее уменьшение хаотичности (например, снижение критерия Джини или энтропии).
  

Итог:
Признак и порог разбиения выбираются так, чтобы наилучшим образом разделить данные, делая узлы максимально однородными.
         * ________________


Что такое жадный алгоритм построения дерева?
Ответ:
Жадный алгоритм строит дерево решений шаг за шагом, выбирая на каждом этапе лучшее разбиение по текущему критерию качества.
Этапы жадного алгоритма:
         1. Начинаем с корня дерева.
         2. Ищем лучший предикат для текущей вершины.
         3. Разделяем данные и создаём новые узлы.
         4. Проверяем критерий останова: если выполнен — создаём лист, если нет — повторяем шаги для новых узлов.
  

  

Недостаток жадного подхода:
Алгоритм не гарантирует нахождение глобально оптимального дерева, так как каждое разбиение выбирается только на основе локальной оптимальности.
________________


Что такое критерий качества и критерий информативности?
Ответ:
  

Пример:
Если узел содержит 100% объектов одного класса, его энтропия равна 0 (максимальная информативность).
________________


Как подбирается предикат (правило разбиения)?
Ответ:
Подбор предиката основан на максимальном уменьшении хаотичности (или неопределённости) в данных после разбиения.
Процесс:
         1. Перебираются все признаки и их возможные значения.
         2. Для каждого разбиения вычисляется метрика качества (например, уменьшение энтропии).
         3. Выбирается разбиение с максимальным уменьшением хаотичности.
Пример:
Если узел содержит людей разного возраста и курящих/некурящих, предикат "Курит?" может лучше разделить данные на группы, чем "Возраст > 30".
________________


Что такое критерий Джини и энтропия?
Ответ:
  

________________


Какие гиперпараметры есть у дерева решений?
Ответ:
Основные гиперпараметры дерева решений:
  

________________


Как понять важность признака (feature importance) в дереве?
Ответ:
Важность признака определяется его вкладом в уменьшение неопределённости (например, энтропии) при каждом разбиении, где этот признак использовался.
Как вычисляется:
         1. Подсчитывается уменьшение неопределённости при каждом разбиении.
         2. Вклад всех разбиений для признака суммируется.
Пример:
Если признак "Возраст" часто используется для разделения и значительно уменьшает хаотичность, его важность будет высокой.
________________


Что лежит в листьях дерева?
Ответ:
В листьях дерева содержатся прогнозы для данных, которые дошли до этого узла:
         * В задачах классификации: класс с максимальной вероятностью.
         * В задачах регрессии: среднее значение целевой переменной для объектов в листе.
Пример:
Для задачи классификации: если в листе 10 объектов, из которых 8 принадлежат классу A, то прогноз для листа — класс A.
________________


Каковы критерии остановки построения дерева?
Ответ:
Максимальная глубина (max_depth): построение дерева останавливается, если достигнута заданная глубина.
Минимальное число объектов в узле (min_samples_split: разбиение узла прекращается, если объектов в нём меньше указанного значения.
Минимальное уменьшение неопределённости (min_impurity_decrease): построение дерева останавливается, если разбиение не улучшает метрику качества.
Минимальное число объектов в листе (min_samples_leaf): узел становится листом, если в нём осталось меньше объектов, чем указано.


  

    

Как выбираются пороги для категориальных и числовых признаков в решающих деревьях при задаче классификации?
  

    Почему деревья решений склонны к переобучению? Какие подходы используются для борьбы с этим?
  

Что произойдет, если не масштабировать числовые признаки перед использованием дерева решений?
Ответ: Деревья решений не чувствительны к масштабу признаков. Независимо от диапазона значений признаков, они используют их для разбиений, основываясь на критерии, например, Джини или энтропии. Таким образом, масштабирование не влияет на работу деревьев решений.
Почему деревья решений не подходят для экстраполяции?
Ответ: Деревья решений делят данные на дискретные интервалы и предсказывают значения только в пределах диапазона целевой переменной в обучающей выборке. Это делает их неспособными делать корректные предсказания для новых данных, выходящих за пределы обучающего диапазона.
Ансамбли
Случайный лес
Какие основные ансамблевые методы с деревьями решений ты знаешь? Как они работают?
Ответ: Основные методы: случайный лес, градиентный бустинг, бэггинг, стекинг.
         1. Случайный лес:
         * Это метод на основе бэггинга, который создает множество деревьев решений.
         * Для каждого дерева используется случайная подвыборка данных (bootstrap) и случайное подмножество признаков для разбиения.
         * Итоговый прогноз формируется через усреднение (для регрессии) или голосование большинства (для классификации).
         2. Градиентный бустинг:
         * Последовательный метод, где каждое новое дерево обучается на ошибках предыдущих.
         * Итоговый прогноз — это сумма предсказаний всех деревьев с учетом их весов.
         3. Бэггинг:
         * Метод построения ансамбля за счет обучения нескольких моделей на случайных подвыборках данных.
         * Результаты моделей усредняются (регрессия) или определяется большинство (классификация).
         4. Стекинг:
         * Комбинирует прогнозы нескольких моделей с помощью метамодели.
         * Прогнозы базовых моделей используются как входные данные для метамодели, которая делает финальное предсказание.
________________


Что такое случайный лес и как он строится?
Ответ: Случайный лес — это ансамблевый метод, который строится на основе комбинации множества деревьев решений.
Этапы построения случайного леса:
         1. Bootstrap: Из обучающего набора данных создаются случайные подвыборки с возвращением.
         * Одни и те же объекты могут попадать в подвыборку несколько раз, а другие — вообще не попасть.
         2. Строительство деревьев:
         * Каждое дерево обучается на своей подвыборке.
         * При построении дерева в каждом узле выбирается случайное подмножество признаков для определения оптимального разбиения.
         3. Комбинация результатов:
         * Прогнозы деревьев усредняются (для регрессии) или используется голосование большинства (для классификации).
Пример:
При прогнозировании цен недвижимости каждое дерево может делать свои предположения о цене. Финальный прогноз будет средней ценой, предсказанной всеми деревьями.
________________


Как работают случайные выборки семплов и признаков в случайном лесе, и почему это важно для его эффективности?
Ответ: В случайном лесе для каждого дерева случайно выбираются:
         1. Сэмплы по yyy (объекты): используется метод бутстрэппинга (bootstrap). Каждое дерево обучается на случайной подвыборке из обучающей выборки с возвращением. Это означает, что некоторые объекты могут повторяться в одной подвыборке, а другие не попасть вовсе. Средняя доля объектов, не попавших в обучающую выборку для одного дерева, составляет примерно 36% (они используются для OOB-оценки).
         2. Признаки по xxx (фичи): при каждом разбиении узла вместо рассмотрения всех признаков, случайно выбирается подмножество признаков. Размер подмножества часто задаётся как sqrt(M)​ для классификации или M/3 для регрессии, где М— общее количество признаков.
Почему это важно:
         * Бутстрэппинг объектов снижает дисперсию модели за счёт усреднения предсказаний разных деревьев.
         * Случайный выбор признаков уменьшает корреляцию между деревьями, что улучшает общую обобщающую способность ансамбля.
________________


Почему случайный лес устойчив к шуму и выбросам?
Ответ: Случайный лес устойчив к шуму и выбросам благодаря следующим свойствам:
         1. Бутстрэппинг: Шум или выбросы присутствуют только в части деревьев, так как каждое дерево обучается на случайной подвыборке данных. Большинство деревьев остаются "незатронутыми" выбросами.
         2. Усреднение предсказаний:
         * Для задач регрессии: выбросы влияют на отдельные деревья, но их вклад минимизируется благодаря усреднению предсказаний всех деревьев.
         * Для задач классификации: выбросы могут вносить ошибки в некоторые деревья, но итоговое голосование большинства деревьев нивелирует эти ошибки.
Таким образом, случайный лес уменьшает влияние выбросов и шума, делая модель более устойчивой.
________________


Почему случайный лес плохо подходит для задач экстраполяции?
Ответ: Случайный лес, как и деревья решений, не подходит для экстраполяции, поскольку:
         1. Деревья делят данные на интервалы, определённые порогами, и могут предсказывать только значения, лежащие внутри диапазона, встреченного в обучающей выборке.
         2. Усреднение предсказаний деревьев не даёт возможности выходить за пределы существующих данных.
Пример: Если модель обучалась на данных с целевыми значениям и y∈[100,500], то для нового объекта с признаками, выходящими за диапазон обучающей выборки, случайный лес предскажет значение внутри диапазона y, так как ни одно дерево не может "экстраполировать" за пределы видимых данных.
________________


В чем отличие случайного леса от градиентного бустинга?
Ответ:
         1. Архитектура обучения:
         * В случайном лесе деревья обучаются параллельно, независимо друг от друга.
         * В градиентном бустинге деревья обучаются последовательно, каждое новое дерево исправляет ошибки предыдущих.
         2. Цель:
         * Случайный лес уменьшает разброс (variance), комбинируя независимые прогнозы деревьев.
         * Градиентный бустинг направлен на уменьшение смещения (bias), фокусируясь на исправлении ошибок.
         3. Настройка модели:
         * Случайный лес менее чувствителен к гиперпараметрам.
         * Градиентный бустинг требует тщательной настройки learning rate, количества деревьев и их глубины.
         4. Производительность:
         * Случайный лес хорошо работает с шумными и большими данными.
         * Градиентный бустинг лучше адаптируется к данным, но может переобучаться.
         5. Предсказание:
         * Деревья в градиентном бустинге обычно короче, поэтому предсказания делаются быстрее.
________________


Градиентный бустинг
Как работает градиентный бустинг?
Ответ: Градиентный бустинг обучается последовательным исправлением ошибок предыдущих моделей с использованием остаточной ошибки (антиградиента) в качестве целевой переменной.
Этапы:
         1. Инициализация:
         * Стартовая модель предсказывает базовый уровень, например, среднее значение целевой переменной.
         2. Вычисление остатков:
         * Остатки (разница между реальным значением и прогнозом) интерпретируются как направление (антиградиент), в котором модель должна улучшаться.
         3. Обучение нового дерева:
         * Обучается следующее дерево, которое минимизирует остатки.
         * Используется функция потерь, например, MSE (среднеквадратичная ошибка).
         4. Обновление предсказаний:
         * Итоговый прогноз обновляется как сумма предыдущего прогноза и предсказания нового дерева, умноженного на learning rate (коэффициент обучения).
         5. Повторение:
         * Процесс повторяется до заданного количества итераций или достижения приемлемой метрики.
Пример: Прогнозирование стоимости автомобилей: первое дерево предсказывает среднюю цену, второе исправляет отклонения, и так далее.
  

________________


Почему бустинг так называется?
Ответ: Метод назван "бустингом", потому что он улучшает (boost) слабые модели (обычно деревья решений) до сильного ансамбля. Каждое новое дерево добавляет свою "корректировку", улучшая общее качество предсказаний.
________________


Почему бустинг называется градиентным?
  

________________


Каковы основные гиперпараметры градиентного бустинга?
  

________________


Что произойдет, если убрать одно дерево из ансамбля случайного леса и градиентного бустинга?
Ответ:
         * Случайный лес:
Удаление одного дерева практически не повлияет на результат, так как деревья работают независимо и их предсказания усредняются.
Пример: удаление дерева эквивалентно небольшому изменению средней величины.
         * Градиентный бустинг:
Удаление дерева нарушит последовательность исправления ошибок, что может значительно повлиять на итоговый прогноз.
Пример: если удалить второе дерево, все следующие деревья будут обучаться на некорректных остатках.
________________


Какие преимущества и недостатки у градиентного бустинга?
Ответ:
Сильные стороны:
            1. Высокая точность: Градиентный бустинг сочетает множество слабых моделей в одну сильную, достигая высокой производительности.
            2. Адаптивность: Способен эффективно работать с разными типами данных (числовые, категориальные) и их распределениями.
            3. Устойчивость к выбросам: Обучение на остатках позволяет лучше адаптироваться к аномалиям.
            4. Гибкость: Подходит для задач классификации, регрессии и ранжирования.
Слабые стороны:
            1. Длительное обучение: Из-за последовательного обучения деревьев процесс может быть медленным, особенно на больших данных.
            2. Чувствительность к гиперпараметрам: Требуется тщательная настройка (learning rate, глубина деревьев, количество итераций), что может потребовать значительных вычислительных ресурсов.
            3. Риск переобучения: При неправильной настройке гиперпараметров или большом количестве деревьев модель может переобучиться.
________________


Какой глубины деревья используются в случайном лесе и градиентном бустинге?
Ответ:
            * Случайный лес:
Используются глубокие деревья (большая глубина, часто без ограничения), чтобы максимально улавливать закономерности в данных.
            * Градиентный бустинг:
Используются неглубокие деревья (3-6 уровней), чтобы каждое дерево выполняло небольшую корректировку и предотвращалось переобучение.
________________


Может ли градиентный бустинг переобучиться с увеличением количества деревьев?
Ответ: Да, может.
При большом количестве деревьев модель начинает запоминать тренировочные данные вместо того, чтобы обобщать закономерности. Это приводит к ухудшению результатов на тестовых данных.
Пример: Если градиентный бустинг с 500 деревьями обучен на малом наборе данных, он запоминает конкретные значения и плохо работает на новых данных.
Решения:
               1. Уменьшить learning rate.
               2. Ограничить максимальное количество деревьев.
               3. Применять регуляризацию (например, ограничение глубины деревьев или минимального числа объектов в листе).
________________


Как формируется итоговый прогноз в градиентном бустинге?
Ответ:
Итоговый прогноз в градиентном бустинге формируется путем последовательного суммирования предсказаний всех слабых моделей в ансамбле.
Этапы:
               1. Изначально модель дает базовое предсказание, например, среднее значение целевой переменной.
               2. На каждом последующем шаге новое дерево предсказывает остатки предыдущей модели. Эти предсказания масштабируются коэффициентом обучения (learning rate) и добавляются к текущему прогнозу.
               3. Процесс продолжается до заданного числа итераций или достижения приемлемой метрики.
Итоговый прогноз — это сумма всех индивидуальных предсказаний деревьев, скорректированная на каждом этапе.
________________


Может ли градиентный бустинг стать хуже при увеличении количества деревьев?
Ответ:
Да, градиентный бустинг может переобучиться с увеличением числа деревьев. Если деревьев становится слишком много, модель начинает "запоминать" тренировочные данные, что ухудшает ее обобщающую способность на новых данных.
Как предотвратить переобучение:
               1. Установить малый коэффициент обучения (learning rate).
               2. Ограничить максимальное количество деревьев.
               3. Ограничить глубину деревьев.
               4. Использовать регуляризацию, например, минимальное число объектов в листьях или раннюю остановку (early stopping).
________________


Почему в градиентном бустинге используют деревья небольшой глубины?
Ответ:
В градиентном бустинге обычно применяются деревья небольшой глубины (3–6 уровней), чтобы:
               1. Предотвратить переобучение: Неглубокие деревья менее склонны к запоминанию данных.
               2. Обеспечить устойчивость: Неглубокие деревья выполняют только небольшие корректировки, фокусируясь на сложных областях данных.
               3. Снизить вычислительную сложность: Неглубокие деревья обучаются и прогнозируют быстрее, что важно для задач с большим количеством итераций.
Пример: Вместо создания сложных моделей каждая итерация добавляет небольшой вклад в итоговое предсказание.
________________


Как повлияет удаление первого или последнего дерева на метрику ошибки, например MAE, в ансамбле бустинга?
Ответ:
               * Удаление первого дерева:
Удаление первого дерева изменит базовый уровень предсказаний, так как все остальные деревья строились с учетом его вклада. Это может существенно изменить итоговые предсказания и, как следствие, величину метрики ошибки.
               * Удаление последнего дерева:
Удаление последнего дерева меньше повлияет на предсказания, так как оно лишь слегка корректирует результат. Тем не менее, итоговая метрика ошибки также изменится, в зависимости от того, насколько велик вклад удаленного дерева.
Пример: если первое дерево задает основное направление предсказаний, его удаление вызывает сильное отклонение, тогда как последнее дерево выполняет минимальные улучшения.
________________


В каких случаях линейная регрессия предпочтительнее градиентного бустинга?
Ответ:
Линейная регрессия может быть предпочтительнее градиентного бустинга в следующих случаях:
                  1. Линейная зависимость: Если признаки и целевая переменная находятся в линейной зависимости, линейная регрессия обеспечивает хорошее качество при меньших вычислительных затратах.
                  2. Простота модели: На малых объемах данных или для простых задач линейная регрессия может быть более эффективной и интерпретируемой.
                  3. Скорость обучения: Линейная регрессия обучается значительно быстрее, особенно на больших объемах данных.
                  4. Интерпретируемость: Линейная регрессия предоставляет явное представление о влиянии каждого признака, что важно для объяснения результатов.
Пример: если зависимость "цена квартиры – площадь квартиры" линейна, то линейная регрессия даст точный и интерпретируемый результат.
________________


Как осуществляется разбиение данных в узлах дерева у бустинга для задачи регрессии?
Ответ:
Процесс разбиения:
                  1. Для каждого узла дерева вычисляется оптимальный признак и порог разбиения, которые минимизируют функцию потерь (например, MSE).
                  2. Данные делятся на две подгруппы:
                  * Левая группа — объекты, у которых значение признака меньше или равно порогу.
                  * Правая группа — объекты, у которых значение признака больше порога.
                  3. Процесс повторяется рекурсивно для каждой группы до достижения критерия остановки (максимальная глубина, минимальное число объектов в листе).
Особенности:
                  * В бустинге разбиения учитывают текущую ошибку предсказаний, чтобы минимизировать остатки.
                  * При этом каждое дерево обучается на новых остатках, увеличивая точность
________________


Что такое Bias-Variance-Tradeoff?
Ответ:
  

Если я уберу одно дерево из случайного леса, то что случится с смещением, а что с разбросом?
Ответ:
                  * Смещение (bias) - не изменится:
В случайном лесе деревья обучаются независимо друг от друга, и их индивидуальные смещения не влияют на общий результат. Удаление одного дерева практически не изменит среднее значение предсказания ансамбля, следовательно, смещение останется таким же.
                  * Разброс (variance) - увеличится:
Разброс определяется чувствительностью модели к изменениям в данных. Удаление одного дерева уменьшает количество предсказаний, участвующих в усреднении, что делает итоговое предсказание менее устойчивым. Это увеличивает разброс, так как влияние отдельных деревьев становится более значимым.
Пример:
Если случайный лес с 100 деревьями имеет низкий разброс, удаление одного дерева вызовет небольшое, но измеримое увеличение разброса, так как каждый индивидуальный прогноз начнет сильнее влиять на итоговый результат.
________________


Если я уберу один шаг из градиентного бустинга, то что случится с смещением, а что с разбросом?
Ответ:
Да, это утверждение тоже верно.
                     * Смещение (bias) - увеличится:
В градиентном бустинге каждый шаг (новое дерево) добавляет улучшение к модели, уменьшает систематическую ошибку (смещение). Удаление одного шага уменьшает способность модели исправлять ошибки, поэтому смещение увеличивается.
                     * Разброс (variance) - не изменится в среднем:
Поскольку деревья в градиентном бустинге строятся последовательно и не обучаются на разных подвыборках (как в случайном лесе), удаление одного дерева не изменяет общий характер взаимодействия оставшихся деревьев. Разброс в среднем останется примерно таким же, потому что разброс определяется моделью в целом, а не отдельным шагом.
Пример:
Если градиентный бустинг обучен с 50 шагами, удаление одного шага может увеличить ошибку из-за роста смещения, но разброс между прогнозами для различных наборов данных останется примерно одинаковым.
________________


Работа с данными
Что делать, если в данных есть дисбаланс классов?
Ответ:
Дисбаланс классов возникает, когда количество объектов одного класса значительно превышает количество объектов другого класса. Это может привести к тому, что модель будет игнорировать редкие классы. Чтобы решить эту проблему, применяются следующие методы:
                        1. Использование весов классов:
                        * Некоторые алгоритмы, например, логистическая регрессия, случайный лес, позволяют задавать веса классов. Редким классам можно назначить больший вес, чтобы ошибки на этом классе "наказывались" сильнее.
                        * Пример: в задаче классификации болезней, если больные пациенты составляют всего 1% выборки, можно назначить классу "больной" вес 100.
                        2. Undersampling:
                        * Уменьшение числа объектов преобладающего класса.
                        * Пример: в задаче с 10 000 объектами класса "0" и 500 объектами класса "1" можно случайным образом выбрать подвыборку из 500 объектов класса "0".
                        3. Oversampling:
                        * Увеличение числа объектов редкого класса. Это может быть сделано:
                        * Простым дублированием объектов.
                        * Генерацией новых объектов с помощью методов, таких как SMOTE (Synthetic Minority Over-sampling Technique). SMOTE создает новые объекты, интерполируя значения признаков между ближайшими соседями редкого класса.
                        4. Аугментация данных:
                        * Создание новых данных за счет генерации признаков, добавления шума, применения преобразований к редкому классу.
                        5. Алгоритмические подходы:
                        * Использование моделей, устойчивых к дисбалансу, например, деревья решений с модифицированным критерием качества или алгоритмы на основе бустинга (XGBoost, CatBoost).
                        6. Применение специальных метрик:
                        * При дисбалансе классов точность модели (accuracy) становится некорректной метрикой. Используйте F1-score, AUC-ROC или Precision-Recall Curve для оценки модели.
________________


Чем тестовая выборка отличается от валидационной?
Ответ:
Тестовая и валидационная выборки выполняют разные задачи в процессе обучения модели.
                        1. Тестовая выборка (Test Set):
                        * Используется только для окончательной оценки модели.
                        * Никогда не участвует в процессе обучения и настройки гиперпараметров.
                        * Помогает определить, насколько модель способна обобщать данные, которые она не видела ранее.
                        * Пример: если модель показывает на тестовой выборке точность 90%, это предполагает, что она будет давать аналогичные результаты на новых данных.
                        2. Валидационная выборка (Validation Set):
                        * Используется для настройки гиперпараметров модели и выбора оптимальной конфигурации.
                        * Пример: выбор лучшего значения learning_rate в градиентном бустинге.
                        * На практике часто применяется K-Fold кросс-валидация для более точной оценки, где данные многократно разделяются на обучающую и валидационную выборки.
________________


Какие существуют методы борьбы с переобучением?
Ответ:
Переобучение возникает, когда модель слишком хорошо "запоминает" тренировочные данные, теряя способность обобщать на новых. Методы борьбы включают:
                        1. Кросс-валидация:
                        * Деление данных на обучающие и валидационные блоки для проверки обобщающей способности модели.
                        * Пример: K-Fold кросс-валидация делит данные на K частей, обучая модель на K-1 блоке и тестируя на оставшемся.
                        2. Регуляризация:
                        * Добавление штрафа за сложность модели.
                        * L1-регуляризация: уменьшает веса неинформативных признаков до нуля, фактически отбирая признаки.
                        * L2-регуляризация: сглаживает веса модели, уменьшая их разброс.
                        * Пример: линейная регрессия с L1-регуляризацией убирает избыточные признаки.
                        3. Ограничение сложности модели:
                        * Ограничение глубины деревьев решений, минимального количества объектов в узле.
                        * Пример: в случайном лесе можно ограничить максимальную глубину деревьев до 10.
                        4. Ансамблевые методы:
                        * Снижение риска переобучения за счет использования ансамблей моделей, таких как случайный лес или градиентный бустинг.
                        5. Исключение нерелевантных признаков:
                        * Удаление шумовых и избыточных признаков уменьшает вероятность переобучения.
                        6. Увеличение объема данных:
                        * Добавление новых данных делает модель менее склонной к переобучению.
                        * Пример: в задачах классификации изображений можно добавить больше изображений редкого класса.
________________


Что делать, если в данных много признаков?
Ответ:
Работа с большим числом признаков требует подходов, которые уменьшают их количество или повышают качество:
                        1. Отбор признаков (Feature Selection):
                        * Удаление неинформативных или избыточных признаков.
                        * Методы:
                        * Важность признаков в случайном лесе.
                        * Регуляризация (например, L1).
                        2. Снижение размерности (Dimensionality Reduction):
                        * PCA (Principal Component Analysis): проецирует данные в пространство меньшей размерности, сохраняя максимальную дисперсию.
                        * t-SNE: используется для визуализации высокоразмерных данных.
                        3. Инженерия признаков (Feature Engineering):
                        * Создание новых признаков, которые более эффективно представляют данные.
                        * Пример: объединение связанных признаков или их преобразование.
                        4. Удаление коррелированных признаков:
                        * Удаление признаков, которые сильно коррелируют друг с другом, помогает избежать избыточности.
________________


Что такое Dummy Variable Trap и как его избежать?
Ответ:
Dummy Variable Trap возникает при использовании One-Hot-Encoding, если все категории признака закодированы в отдельные столбцы. Это приводит к мультиколлинеарности, так как один из столбцов может быть выражен через остальные.
Как избежать:
                        * Удалить один столбец после кодирования. Например, если есть категории "A", "B", "C", закодируйте их как два столбца: [1,0] для "A", [0,1] для "B", [0,0] для "C".
________________


Что такое TF-IDF и как он работает?
Ответ:
TF-IDF (Term Frequency-Inverse Document Frequency) — это метод, который оценивает важность слов в тексте.
                        1. TF (Term Frequency):
                        * Частота слова в тексте.
                        * Формула:   
                           2. IDF (Inverse Document Frequency):
                           * Оценка редкости слова в наборе текстов.
                           * Формула:​  
                              3. TF-IDF Score:
                              * Умножение TF и IDF. Высокие значения имеют слова, часто встречающиеся в данном тексте, но редкие в других.
Пример:
Для текстов про автомобили слово "двигатель" будет иметь высокий TF-IDF, если оно часто встречается в описаниях конкретного авто, но не во всех текстах.
________________


Как бороться с мультиколлинеарностью?
Ответ:
Мультиколлинеарность — это линейная зависимость между признаками.
                              1. Удаление избыточных признаков:
                              * Удалите один из коррелирующих признаков.
                              * Пример: если два признака "длина" и "ширина" сильно коррелируют, удалите один из них.
                              2. Регуляризация:
                              * Используйте L2-регуляризацию для уменьшения влияния мультиколлинеарности.
                              3. Снижение размерности:
                              * Примените PCA, чтобы преобразовать признаки в независимые компоненты.
________________


Что такое кросс-валидация?
Ответ:
Кросс-валидация — это метод оценки обобщающей способности модели.
                              1. K-Fold Cross Validation:
                              * Данные делятся на K частей. Модель обучается на K-1 части и тестируется на оставшейся. Процедура повторяется K раз.
                              2. Time Series Split:
                              * Для временных рядов обучение проводится на более ранних данных, а тестирование — на более поздних.
Кросс-валидация помогает предотвратить переобучение и выбрать лучшую модель.
Чем отличается нормализация от стандартизации данных?
Ответ:
Нормализация и стандартизация — это два разных подхода к преобразованию числовых данных.
                              1. Нормализация:
                              * Преобразует данные в диапазон от 0 до 1 (или до [-1, 1] в зависимости от метода).
                              * Формула:   
                                 2. Стандартизация:
                                 * Преобразует данные так, чтобы они имели среднее 0 и стандартное отклонение 1.
                                 * Формула: 
  

                                 * Используется, если данные должны соответствовать стандартному нормальному распределению, например, при использовании моделей линейной регрессии или SVM.
Различие:
                                 * Нормализация используется для приведения данных к фиксированному диапазону.
                                 * Стандартизация делает данные нормально распределенными, но сохраняет исходный масштаб.
________________


Когда лучше применять нормализацию, а когда стандартизацию?
Ответ:
                                 1. Нормализация:
                                 * Применяется, когда модели чувствительны к масштабу данных.
                                 * Примеры моделей: K-ближайших соседей (KNN), SVM с линейным ядром, градиентный спуск (особенно в нейронных сетях).
                                 * Пример задачи: кластеризация данных, где расстояние между объектами должно быть приведено к одной шкале.
                                 2. Стандартизация:
                                 * Применяется, когда модели предполагают нормальное распределение данных или используют статистические методы.
                                 * Примеры моделей: линейная регрессия, логистическая регрессия, PCA.
                                 * Пример задачи: если вы анализируете финансовые данные с большими выбросами, стандартизация лучше нормализации, так как она менее чувствительна к выбросам.
________________


Почему важно нормализовать или стандартизировать данные перед обучением модели?
Ответ:
Приведение данных к единому масштабу необходимо, чтобы:
                                 1. Избежать доминирования признаков с большими значениями:
                                 * Признаки с крупным масштабом могут существенно влиять на модель, игнорируя менее масштабные признаки.
                                 * Пример: если один признак варьируется от 1 до 10, а другой — от 1000 до 100000, второй окажет большее влияние на модель, например, в линейной регрессии или KNN.
                                 2. Ускорить сходимость алгоритмов:
                                 * Градиентный спуск работает быстрее на стандартизированных данных, так как уменьшает дисбаланс в масштабах признаков.
                                 3. Улучшить качество кластеризации или расстояний:
                                 * В задачах кластеризации или ранжирования расстояния между объектами зависят от масштаба данных. Нормализация делает их сопоставимыми.
                                 4. Сделать модель более интерпретируемой:
                                 * Преобразованные данные позволяют лучше понимать вклад каждого признака.
________________


Какие существуют методы нормализации данных?
Ответ:
                                 1. Min-Max Scaling:
                                 * Приводит данные к диапазону [0, 1] или [-1, 1].
                                 * Формула:
  

                                 * Применяется для данных, у которых минимальное и максимальное значения имеют значимый смысл.
                                 2. Max Abs Scaling:
                                 * Приводит данные к диапазону [-1, 1] без смещения среднего значения.
                                 * Формула:
  

                                 * Используется, если данные имеют одинаковый масштаб, но разные знаки.
                                 3. Robust Scaling:
                                 * Основан на медиане и интерквартильном размахе.
                                 * Формула: 
  

                                 * Применяется, если данные содержат выбросы.
________________


Какие существуют методы стандартизации данных?
Ответ:
                                 1. Z-Score Scaling:
                                 * Преобразует данные так, чтобы среднее было 0, а стандартное отклонение — 1.
                                 * Формула: 
  

                                 * Используется для данных, близких к нормальному распределению.
                                 2. Robust Standardization:
                                 * Основана на медиане и IQR вместо среднего и стандартного отклонения.
                                 * Формула:
​  
                                 * Подходит для данных с выбросами.
                                 3. Scaling by Mean and Variance:
                                 * Вариант Z-Score, но вместо σ\sigmaσ используется дисперсия.
________________


Влияют ли выбросы на нормализацию и стандартизацию?
Ответ:
                                 * Нормализация (Min-Max Scaling):
                                 * Сильно подвержена влиянию выбросов. Большие выбросы расширяют диапазон данных, "сжимая" основную массу значений в узкий интервал.
                                 * Решение: Использовать Robust Scaling или предварительно обработать выбросы.
                                 * Стандартизация (Z-Score Scaling):
                                 * Также чувствительна к выбросам, так как среднее и стандартное отклонение изменяются при наличии аномальных значений.
                                 * Решение: Использовать Robust Standardization или исключить выбросы.
Пример: в выборке с ценами от $100 до $500 и одним выбросом $10,000, Min-Max Scaling "сожмет" все цены в диапазон около 0.
________________


Какие практические рекомендации для нормализации и стандартизации данных?
Ответ:
                                 1. Если данные имеют естественные границы (например, процентное содержание):
                                 * Используйте Min-Max Scaling.
                                 2. Если данные содержат выбросы:
                                 * Примените Robust Scaling или предварительно обработайте выбросы.
                                 3. Если модель чувствительна к масштабу данных:
                                 * Примените стандартизацию (Z-Score), особенно для методов линейной регрессии, SVM, PCA.
                                 4. Для временных рядов или данных с распределением:
                                 * Проверьте распределение данных. Если оно ненормальное, примените логарифмическое преобразование или Box-Cox.
                                 5. Если вы не уверены в необходимости трансформации:
                                 * Попробуйте модель без нормализации или стандартизации и сравните качество с преобразованными данными.
________________
  

Задачи
Задача 1
Есть train, есть test. Нарисуй мне как на test будет выглядеть:
                                 * Линейная регрессия
                                 * K-Means
                                 * Дерево-решений
  

  

Задача 2
  

Задача 3
  

Задача 4
  



Тренировочная точность ниже валидационной:
                                 * На графике видно, что валидационная точность (оранжевая линия) стабильно выше тренировочной (синяя линия). Это действительно необычное поведение, так как обычно тренировка показывает более высокий результат из-за адаптации модели к тренировочным данным.
Валидационные потери ниже тренировочных:
                                 * Также интересно, что на графике потерь (справа) валидационная потеря (оранжевая линия) оказывается ниже тренировочной на протяжении обучения, что противоположно ожидаемому (обычно потери на тренировке ниже).
Причины:
                                 1. Data-Leak
Регуляризация:
                                 * Сильная регуляризация (например, Dropout или L2-регуляризация) может ограничивать способность модели "запоминать" тренировочные данные. Это приводит к тому, что на тренировке модель демонстрирует более низкую точность, а на валидации — лучшую обобщающую способность.
Аугментация данных:
                                 * Если используется агрессивная аугментация данных в тренировочной выборке (например, повороты, шумы, изменения яркости), тренировочные данные становятся сложнее для модели, чем оригинальные валидационные данные. Это может объяснить, почему модель хуже справляется с тренировочными данными.
Шум в тренировочных данных:
                                 * Если тренировочные данные содержат больше шума или ошибок в разметке, чем валидационные, модель будет хуже справляться с тренировочной выборкой.
Слишком маленькая модель:
                                 * Если модель недостаточно сложная для обучения на тренировочных данных, она может быть неспособна хорошо адаптироваться к ним, но при этом показывать хорошие результаты на более "чистых" валидационных данных.
Задача 5


У нас все y>0, какие алгоритмы могут дать негативный ответ, а какие только положительный (картинка)
  

1. K-ближайших соседей (KNN)
                                 * Может ли дать отрицательный ответ? Нет.
                                 * Объяснение:
                                 * Как работает алгоритм: В случае регрессии KNN предсказывает значение y для новой точки, усредняя значения y её k ближайших соседей из обучающей выборки.
                                 * Почему только положительные результаты: Поскольку все значения y в обучающих данных положительны, среднее этих значений также будет положительным. Следовательно, KNN не сможет предсказать отрицательное значение, так как он просто усредняет положительные числа.
                                 * Пример:
                                 * Допустим, мы хотим предсказать цену дома (всегда > 0) на основе его характеристик. KNN будет искать k ближайших домов в обучающей выборке и усреднять их цены. Полученное значение будет положительным.
________________


2. Линейная регрессия
                                 * Может ли дать отрицательный ответ? Да.
                                 * Объяснение:
                                 * Как работает алгоритм: Линейная регрессия пытается найти линейную зависимость между входными признаками и целевой переменной, подбирая коэффициенты β в уравнении y=β0+β1x1+β2x2+⋯+βnxny​.
                                 * Почему возможны отрицательные результаты: Коэффициенты β могут принимать любые действительные значения, включая отрицательные. При определённых значениях входных признаков модель может предсказать отрицательное y, даже если все обучающие y были положительными. Это особенно вероятно при экстраполяции за пределы обучающих данных.
                                 * Пример:
                                 * Если модель обучена на данных, где x∈[1,10] и соответствующие y>0, но мы подаём на вход x=-5, линейная модель может предсказать отрицательное значение y.
________________


3. Нейронная сеть
                                 * Может ли дать отрицательный ответ? Да.
                                 * Объяснение:
                                 * Как работает алгоритм: Нейронные сети состоят из слоёв нейронов, которые преобразуют входные данные через функции активации.
                                 * Почему возможны отрицательные результаты: Если в выходном слое используется линейная или другая функция активации, допускающая отрицательные значения (например, тангенс гиперболический), сеть может предсказать отрицательные y. Даже если обучающие данные имеют только положительные y, сеть может интерполировать или экстраполировать в отрицательную область без специальных ограничений.
                                 * Пример:
                                 * При решении задачи прогнозирования спроса (всегда y>0), если не использовать нелинейную функцию активации, ограничивающую выход (например, ReLU), сеть может предсказать отрицательный спрос при определённых входных данных.
________________


4. Решающее дерево
                                 * Может ли дать отрицательный ответ? Нет.
                                 * Объяснение:
                                 * Как работает алгоритм: Дерево разделяет пространство признаков на области и в каждой листовой вершине хранит предсказание, обычно среднее значение y для обучающих примеров, попавших в этот лист.
                                 * Почему только положительные результаты: Поскольку среднее положительных чисел положительно, дерево будет предсказывать только положительные значения y.
                                 * Пример:
                                 * При прогнозировании времени выполнения задачи (всегда y>0), дерево решений будет выдавать только положительные оценки, так как в листьях хранятся средние положительных времён.
________________


5. Случайный лес
                                 * Может ли дать отрицательный ответ? Нет.
                                 * Объяснение:
                                 * Как работает алгоритм: Случайный лес объединяет предсказания множества решающих деревьев, обычно посредством усреднения.
                                 * Почему только положительные результаты: Каждое дерево предсказывает положительное значение (как объяснено выше), и их среднее также будет положительным.
                                 * Пример:
                                 * При оценке стоимости страхового случая (всегда y>0), случайный лес будет предсказывать только положительные значения, так как основывается на усреднении положительных предсказаний деревьев.
________________


6. Градиентный бустинг
                                 * Может ли дать отрицательный ответ? Да.
                                 * Объяснение:
                                 * Как работает алгоритм: Градиентный бустинг строит последовательность моделей (обычно деревьев), каждая из которых пытается скорректировать ошибки предыдущих, обучаясь на остатках.
                                 * Почему возможны отрицательные результаты: Поскольку модель обучается на разностях между реальным и предсказанным значением (остатках), которые могут быть как положительными, так и отрицательными, итоговая сумма прогнозов может оказаться отрицательной, даже если все исходные y были положительными.
                                 * Пример:
                                 * При прогнозировании дохода (всегда y>0), если модель переобучается на шум и остатки становятся отрицательными, итоговый прогноз может стать отрицательным из-за суммирования отрицательных корректировок.


Задача 6


Тестовые данные состоят из 99% из y=1 и на 1% из y=-1.Модель на тесте предсказывает с вероятностью 50% y=1 и с 50% вероятности y=-1. Посчитать Accuracy, Precision, Recall. (TP=99, FP=1, FN=99, TN=1, Precision=0.99, Recall=0.5, accuracy = 0.5)
  

Задача 7


В какой выборке дерево будет лучше чем лес? (В той выборке, которая состоит из немногих важных фичей. То есть дерево строится на всех фичах выборки и точно зацепит важные фичи, а лес он может бустрапом их пропустить)


Задача 8
  

Задача 9
[
  {
    "text": "Вопрос: Что такое линейная регрессия и как она работает?\nОтвет: Линейная регрессия – это алгоритм машинного обучения, используемый для прогнозирования, основанного на линейной зависимости между входными и выходными данными. Она задаётся формулой линейной функции:\ny=wX+by = wX + by=wX+b,\nгде X – матрица входных признаков, w – матрица весов признаков, b – смещение (bias). Модель подбирает оптимальные параметры w и b, чтобы минимизировать ошибку между предсказаниями и реальными значениями.",
    "metadata": {
      "section": "Общие вопросы по линейной регрессии",
      "question_number": 1,
      "question": "Что такое линейная регрессия и как она работает?",
      "answer": "Линейная регрессия – это алгоритм машинного обучения, используемый для прогнозирования, основанного на линейной зависимости между входными и выходными данными. Она задаётся формулой линейной функции:\ny=wX+by = wX + by=wX+b,\nгде X – матрица входных признаков, w – матрица весов признаков, b – смещение (bias). Модель подбирает оптимальные параметры w и b, чтобы минимизировать ошибку между предсказаниями и реальными значениями.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие преимущества у линейной регрессии?\nОтвет: * Простота и интерпретируемость: легко понять и объяснить результаты.\n* Эффективность: низкая вычислительная сложность, быстрое обучение на больших наборах данных.\n* Гибкость: может быть расширена до полиномиальных и взаимодействующих признаков.",
    "metadata": {
      "section": "Преимущества линейной регрессии",
      "question_number": 2,
      "question": "Какие преимущества у линейной регрессии?",
      "answer": "* Простота и интерпретируемость: легко понять и объяснить результаты.\n* Эффективность: низкая вычислительная сложность, быстрое обучение на больших наборах данных.\n* Гибкость: может быть расширена до полиномиальных и взаимодействующих признаков.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какая функция потерь используется в линейной регрессии?\nОтвет: Обычно используется среднеквадратичная ошибка (Mean Squared Error, MSE), которая измеряет среднеквадратичное отклонение предсказанных значений от фактических.",
    "metadata": {
      "section": "Функция потерь в линейной регрессии",
      "question_number": 3,
      "question": "Какая функция потерь используется в линейной регрессии?",
      "answer": "Обычно используется среднеквадратичная ошибка (Mean Squared Error, MSE), которая измеряет среднеквадратичное отклонение предсказанных значений от фактических.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему в линейной регрессии используется квадратичная функция потерь?\nОтвет: * Простота: квадратичная форма удобна для вычислений.\n* Выпуклость: квадратичная функция имеет один глобальный минимум, что упрощает оптимизацию.\n* Интерпретируемость: минимизация MSE позволяет находить параметры модели с наилучшей вероятностью.\n* Математическая удобность: методы вроде метода наименьших квадратов легко применяются.",
    "metadata": {
      "section": "Функция потерь в линейной регрессии",
      "question_number": 4,
      "question": "Почему в линейной регрессии используется квадратичная функция потерь?",
      "answer": "* Простота: квадратичная форма удобна для вычислений.\n* Выпуклость: квадратичная функция имеет один глобальный минимум, что упрощает оптимизацию.\n* Интерпретируемость: минимизация MSE позволяет находить параметры модели с наилучшей вероятностью.\n* Математическая удобность: методы вроде метода наименьших квадратов легко применяются.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как обучается модель линейной регрессии?\nОтвет: Модель обучается с помощью методов оптимизации, таких как градиентный спуск, чтобы найти оптимальные значения весов w и смещения b. В качестве функции потерь используется MSE.",
    "metadata": {
      "section": "Обучение линейной регрессии",
      "question_number": 5,
      "question": "Как обучается модель линейной регрессии?",
      "answer": "Модель обучается с помощью методов оптимизации, таких как градиентный спуск, чтобы найти оптимальные значения весов w и смещения b. В качестве функции потерь используется MSE.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что представляет собой предсказание линейной регрессии?\nОтвет: Предсказание – это линейная комбинация входных признаков и весов:\ny=wX+b.",
    "metadata": {
      "section": "Обучение линейной регрессии",
      "question_number": 6,
      "question": "Что представляет собой предсказание линейной регрессии?",
      "answer": "Предсказание – это линейная комбинация входных признаков и весов:\ny=wX+b.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: В чём заключаются основные проблемы линейной регрессии?\nОтвет: * Линейная зависимость: плохо справляется с моделированием сложных нелинейных зависимостей.\n* Чувствительность к выбросам: выбросы сильно влияют на качество модели.\n* Проблемы с мультиколлинеарностью: сильно коррелированные признаки ухудшают качество модели.",
    "metadata": {
      "section": "Проблемы и ограничения линейной регрессии",
      "question_number": 7,
      "question": "В чём заключаются основные проблемы линейной регрессии?",
      "answer": "* Линейная зависимость: плохо справляется с моделированием сложных нелинейных зависимостей.\n* Чувствительность к выбросам: выбросы сильно влияют на качество модели.\n* Проблемы с мультиколлинеарностью: сильно коррелированные признаки ухудшают качество модели.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как можно модифицировать линейную регрессию для работы с нелинейными зависимостями?\nОтвет: Можно использовать полиномиальные признаки, преобразовав задачу в полиномиальную регрессию.",
    "metadata": {
      "section": "Проблемы и ограничения линейной регрессии",
      "question_number": 8,
      "question": "Как можно модифицировать линейную регрессию для работы с нелинейными зависимостями?",
      "answer": "Можно использовать полиномиальные признаки, преобразовав задачу в полиномиальную регрессию.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие проблемы возникают при больших значениях весов в линейной регрессии?\nОтвет: Большие веса могут привести к переобучению модели, что снижает её обобщающую способность.",
    "metadata": {
      "section": "Регуляризация и большие веса",
      "question_number": 9,
      "question": "Какие проблемы возникают при больших значениях весов в линейной регрессии?",
      "answer": "Большие веса могут привести к переобучению модели, что снижает её обобщающую способность.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как справляться с большими весами?\nОтвет: Используются методы регуляризации:\n* L1-регуляризация (Lasso): добавляет штраф за модуль весов.\n* L2-регуляризация (Ridge): добавляет штраф за квадрат весов.",
    "metadata": {
      "section": "Регуляризация и большие веса",
      "question_number": 10,
      "question": "Как справляться с большими весами?",
      "answer": "Используются методы регуляризации:\n* L1-регуляризация (Lasso): добавляет штраф за модуль весов.\n* L2-регуляризация (Ridge): добавляет штраф за квадрат весов.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие метрики используются для оценки качества линейной регрессии?\nОтвет: * MAE (Mean Absolute Error): средняя абсолютная ошибка.\n* MSE (Mean Squared Error): среднеквадратичная ошибка.\n* RMSE (Root Mean Squared Error): корень из MSE.\n* MAPE (Mean Absolute Percentage Error): средняя абсолютная ошибка в процентах.\n* R^2 (коэффициент детерминации): доля объяснённой дисперсии целевой переменной.",
    "metadata": {
      "section": "Метрики регрессии",
      "question_number": 11,
      "question": "Какие метрики используются для оценки качества линейной регрессии?",
      "answer": "* MAE (Mean Absolute Error): средняя абсолютная ошибка.\n* MSE (Mean Squared Error): среднеквадратичная ошибка.\n* RMSE (Root Mean Squared Error): корень из MSE.\n* MAPE (Mean Absolute Percentage Error): средняя абсолютная ошибка в процентах.\n* R^2 (коэффициент детерминации): доля объяснённой дисперсии целевой переменной.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какая метрика более чувствительна к выбросам: MSE или MAE?\nОтвет: MSE более чувствительна к выбросам, так как штрафует их сильнее за счёт возведения ошибки в квадрат. MAE более устойчива и интерпретируема.",
    "metadata": {
      "section": "Метрики регрессии",
      "question_number": 12,
      "question": "Какая метрика более чувствительна к выбросам: MSE или MAE?",
      "answer": "MSE более чувствительна к выбросам, так как штрафует их сильнее за счёт возведения ошибки в квадрат. MAE более устойчива и интерпретируема.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Чем отличаются L1- и L2-регуляризация?\nОтвет: * L1-регуляризация (Lasso): добавляет штраф за абсолютную сумму весов (∑ |wi|), что может занулять некоторые веса, делая модель разреженной.\n* L2-регуляризация (Ridge): добавляет штраф за сумму квадратов весов (∑wi^2​), что уменьшает значения весов, но не зануляет их.",
    "metadata": {
      "section": "Регуляризация",
      "question_number": 13,
      "question": "Чем отличаются L1- и L2-регуляризация?",
      "answer": "* L1-регуляризация (Lasso): добавляет штраф за абсолютную сумму весов (∑ |wi|), что может занулять некоторые веса, делая модель разреженной.\n* L2-регуляризация (Ridge): добавляет штраф за сумму квадратов весов (∑wi^2​), что уменьшает значения весов, но не зануляет их.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое ElasticNet?\nОтвет: ElasticNet – это комбинация L1- и L2-регуляризации. Позволяет учитывать преимущества обеих методик: разреженность (L1) и контроль над большими весами (L2).",
    "metadata": {
      "section": "Регуляризация",
      "question_number": 14,
      "question": "Что такое ElasticNet?",
      "answer": "ElasticNet – это комбинация L1- и L2-регуляризации. Позволяет учитывать преимущества обеих методик: разреженность (L1) и контроль над большими весами (L2).",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему важно масштабировать признаки перед использованием линейной регрессии?\nОтвет: Линейная регрессия чувствительна к масштабу признаков, так как большие значения одних признаков могут доминировать над малыми значениями других. Масштабирование приводит признаки к одному диапазону, улучшая устойчивость модели.",
    "metadata": {
      "section": "Особенности обработки данных",
      "question_number": 15,
      "question": "Почему важно масштабировать признаки перед использованием линейной регрессии?",
      "answer": "Линейная регрессия чувствительна к масштабу признаков, так как большие значения одних признаков могут доминировать над малыми значениями других. Масштабирование приводит признаки к одному диапазону, улучшая устойчивость модели.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как линейная регрессия обрабатывает категориальные признаки?\nОтвет: Категориальные признаки преобразуются в числовую форму с помощью методов:",
    "metadata": {
      "section": "Особенности обработки данных",
      "question_number": 16,
      "question": "Как линейная регрессия обрабатывает категориальные признаки?",
      "answer": "Категориальные признаки преобразуются в числовую форму с помощью методов:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как интерпретировать коэффициенты линейной регрессии?\nОтвет: Коэффициенты показывают, как изменение значения независимого признака на единицу влияет на значение целевой переменной при фиксированных значениях других признаков.",
    "metadata": {
      "section": "Интерпретация результатов",
      "question_number": 17,
      "question": "Как интерпретировать коэффициенты линейной регрессии?",
      "answer": "Коэффициенты показывают, как изменение значения независимого признака на единицу влияет на значение целевой переменной при фиксированных значениях других признаков.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое R^2 и как его интерпретировать?\nОтвет: R^2 (коэффициент детерминации) показывает долю дисперсии зависимой переменной, объяснённой регрессией. Значение от 0 до 1:\n* R^2 = 1: модель полностью объясняет вариативность данных.\n* R^2 = 0: модель не объясняет вариативность данных.",
    "metadata": {
      "section": "Интерпретация результатов",
      "question_number": 18,
      "question": "Что такое R^2 и как его интерпретировать?",
      "answer": "R^2 (коэффициент детерминации) показывает долю дисперсии зависимой переменной, объяснённой регрессией. Значение от 0 до 1:\n* R^2 = 1: модель полностью объясняет вариативность данных.\n* R^2 = 0: модель не объясняет вариативность данных.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как проверить наличие мультиколлинеарности в данных?\nОтвет: Используются методы:",
    "metadata": {
      "section": "Диагностика модели",
      "question_number": 19,
      "question": "Как проверить наличие мультиколлинеарности в данных?",
      "answer": "Используются методы:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие графики помогают проверить качество линейной регрессии?\nОтвет: ",
    "metadata": {
      "section": "VIF (Variance Inflation Factor): если VIF>5−10VIF > 5-10VIF>5−10, то мультиколлинеарность значительна.",
      "question_number": 20,
      "question": "Какие графики помогают проверить качество линейной регрессии?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое мультиколлинеарность и как с ней бороться?\nОтвет: Логистическая регрессия",
    "metadata": {
      "section": "График остатков против прогнозов: выявляет проблемы с гомоскедастичностью.",
      "question_number": 21,
      "question": "Что такое мультиколлинеарность и как с ней бороться?",
      "answer": "Логистическая регрессия",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое логистическая регрессия?\nОтвет: Логистическая регрессия – это алгоритм бинарной классификации, который используется для прогнозирования вероятности принадлежности объекта к определённому классу. Она преобразует линейную комбинацию признаков в вероятность с помощью логистической (сигмоидной) функции.",
    "metadata": {
      "section": "Основные концепции",
      "question_number": 22,
      "question": "Что такое логистическая регрессия?",
      "answer": "Логистическая регрессия – это алгоритм бинарной классификации, который используется для прогнозирования вероятности принадлежности объекта к определённому классу. Она преобразует линейную комбинацию признаков в вероятность с помощью логистической (сигмоидной) функции.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: В чём разница между логистической и линейной регрессией?\nОтвет: * Линейная регрессия предсказывает непрерывные значения, тогда как логистическая регрессия предсказывает вероятность принадлежности к классу.\n* Логистическая регрессия использует логистическую (сигмоидную) функцию для сжатия выхода в диапазон [0, 1].\n* В логистической регрессии минимизируется логистическая функция потерь (кросс-энтропия), а не среднеквадратичная ошибка.",
    "metadata": {
      "section": "Основные концепции",
      "question_number": 23,
      "question": "В чём разница между логистической и линейной регрессией?",
      "answer": "* Линейная регрессия предсказывает непрерывные значения, тогда как логистическая регрессия предсказывает вероятность принадлежности к классу.\n* Логистическая регрессия использует логистическую (сигмоидную) функцию для сжатия выхода в диапазон [0, 1].\n* В логистической регрессии минимизируется логистическая функция потерь (кросс-энтропия), а не среднеквадратичная ошибка.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как получить логистическую регрессию из линейной?\nОтвет: формула лог. регрессии целиком",
    "metadata": {
      "section": "Основные концепции",
      "question_number": 24,
      "question": "Как получить логистическую регрессию из линейной?",
      "answer": "формула лог. регрессии целиком",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как выглядит формула логистической регрессии?\nОтвет: ",
    "metadata": {
      "section": "Математическая модель",
      "question_number": 25,
      "question": "Как выглядит формула логистической регрессии?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое логит?\nОтвет: .",
    "metadata": {
      "section": "Математическая модель",
      "question_number": 26,
      "question": "Что такое логит?",
      "answer": ".",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как обучается логистическая регрессия?\nОтвет: Логистическая регрессия обучается с использованием методов оптимизации, таких как градиентный спуск. Задача состоит в минимизации логистической функции потерь (кросс-энтропии), которая измеряет расхождение между истинными и предсказанными вероятностями.",
    "metadata": {
      "section": "Обучение модели",
      "question_number": 27,
      "question": "Как обучается логистическая регрессия?",
      "answer": "Логистическая регрессия обучается с использованием методов оптимизации, таких как градиентный спуск. Задача состоит в минимизации логистической функции потерь (кросс-энтропии), которая измеряет расхождение между истинными и предсказанными вероятностями.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как выглядит формула кросс-энтропии (Binary Cross Entropy)?\nОтвет: ",
    "metadata": {
      "section": "Обучение модели",
      "question_number": 28,
      "question": "Как выглядит формула кросс-энтропии (Binary Cross Entropy)?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как логистическая регрессия разделяет классы?\nОтвет: Логистическая регрессия использует логистическую функцию для предсказания вероятности принадлежности к классу. Если вероятность выше порога (обычно 0.5), объект относят к классу 1, иначе – к классу",
    "metadata": {
      "section": "Принципы работы",
      "question_number": 29,
      "question": "Как логистическая регрессия разделяет классы?",
      "answer": "Логистическая регрессия использует логистическую функцию для предсказания вероятности принадлежности к классу. Если вероятность выше порога (обычно 0.5), объект относят к классу 1, иначе – к классу",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: \nОтвет: * Используются z-тест или t-тест, чтобы проверить гипотезу, что коэффициент равен нулю.\n* Рассчитывается p-value: если оно меньше уровня значимости (α), коэффициент считается значимым.\n* Статистические пакеты автоматически проводят такие проверки при оценке модели.\nПроверка статистической значимости коэффициентов в логистической регрессии – пример с расчётом стандартной ошибки (SE)\n\nСитуация:\nВы строите модель логистической регрессии, чтобы предсказать, купит ли человек продукт (y=1) или нет (y=0). В модели есть два признака:",
    "metadata": {
      "section": "Вопрос: Как проверить статистическую значимость коэффициентов в логистической регрессии?",
      "question_number": 30,
      "question": "",
      "answer": "* Используются z-тест или t-тест, чтобы проверить гипотезу, что коэффициент равен нулю.\n* Рассчитывается p-value: если оно меньше уровня значимости (α), коэффициент считается значимым.\n* Статистические пакеты автоматически проводят такие проверки при оценке модели.\nПроверка статистической значимости коэффициентов в логистической регрессии – пример с расчётом стандартной ошибки (SE)\n\nСитуация:\nВы строите модель логистической регрессии, чтобы предсказать, купит ли человек продукт (y=1) или нет (y=0). В модели есть два признака:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие метрики применяются для оценки логистической регрессии?\nОтвет: * Accuracy (точность) – доля правильных предсказаний.\n* Precision (точность) – доля истинных положительных среди предсказанных положительных.\n* Recall (полнота) – доля истинных положительных среди реальных положительных.\n* F1-score – гармоническое среднее Precision и Recall.\n* AUC-ROC – площадь под кривой ROC, измеряет способность модели различать классы.",
    "metadata": {
      "section": "Метрики для логистической регрессии",
      "question_number": 31,
      "question": "Какие метрики применяются для оценки логистической регрессии?",
      "answer": "* Accuracy (точность) – доля правильных предсказаний.\n* Precision (точность) – доля истинных положительных среди предсказанных положительных.\n* Recall (полнота) – доля истинных положительных среди реальных положительных.\n* F1-score – гармоническое среднее Precision и Recall.\n* AUC-ROC – площадь под кривой ROC, измеряет способность модели различать классы.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему F1-score не является простым средним между Precision и Recall?\nОтвет: F1-score рассчитывается как гармоническое среднее:  \nГармоническое среднее более чувствительно к дисбалансу между Precision и Recall, чем обычное среднее.",
    "metadata": {
      "section": "Метрики для логистической регрессии",
      "question_number": 32,
      "question": "Почему F1-score не является простым средним между Precision и Recall?",
      "answer": "F1-score рассчитывается как гармоническое среднее:  \nГармоническое среднее более чувствительно к дисбалансу между Precision и Recall, чем обычное среднее.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие предположения делает логистическая регрессия?\nОтвет: ",
    "metadata": {
      "section": "Особенности и ограничения",
      "question_number": 33,
      "question": "Какие предположения делает логистическая регрессия?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие ограничения есть у логистической регрессии?\nОтвет: * Плохо работает с нелинейно разделимыми данными.\n* Чувствительна к выбросам.\n* Требует масштабирования признаков для лучшей сходимости.",
    "metadata": {
      "section": "Отсутствие высокой корреляции между признаками (мультиколлинеарности).",
      "question_number": 34,
      "question": "Какие ограничения есть у логистической регрессии?",
      "answer": "* Плохо работает с нелинейно разделимыми данными.\n* Чувствительна к выбросам.\n* Требует масштабирования признаков для лучшей сходимости.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как справляться с ограничениями логистической регрессии?\nОтвет: * Для нелинейных зависимостей можно добавить полиномиальные признаки.\n* Масштабировать данные перед обучением.\n* Использовать регуляризацию (L1, L2, ElasticNet) для уменьшения переобучения.",
    "metadata": {
      "section": "Отсутствие высокой корреляции между признаками (мультиколлинеарности).",
      "question_number": 35,
      "question": "Как справляться с ограничениями логистической регрессии?",
      "answer": "* Для нелинейных зависимостей можно добавить полиномиальные признаки.\n* Масштабировать данные перед обучением.\n* Использовать регуляризацию (L1, L2, ElasticNet) для уменьшения переобучения.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как логистическая регрессия справляется с несбалансированными классами?\nОтвет: ",
    "metadata": {
      "section": "Расширенные темы",
      "question_number": 36,
      "question": "Как логистическая регрессия справляется с несбалансированными классами?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Чем отличается многоклассовая логистическая регрессия?\nОтвет: Многоклассовая логистическая регрессия использует метод:      \n  \n\nSVM",
    "metadata": {
      "section": "Выбор подходящих метрик (F1-score, ROC-AUC вместо Accuracy).",
      "question_number": 37,
      "question": "Чем отличается многоклассовая логистическая регрессия?",
      "answer": "Многоклассовая логистическая регрессия использует метод:      \n  \n\nSVM",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое SVM, и как он работает?\nОтвет: SVM (Support Vector Machine) – это алгоритм машинного обучения, который используется для классификации данных. Его цель – найти такую линию (или гиперплоскость), которая лучше всего разделяет данные на классы.\nКлючевая идея SVM:\n* SVM не просто ищет любую разделяющую линию, а выбирает ту, которая максимально увеличивает зазор между точками двух классов.\n* Точки, ближайшие к разделяющей линии, называются опорными векторами. Эти точки определяют положение линии.",
    "metadata": {
      "section": "Основная идея метода опорных векторов (SVM)",
      "question_number": 38,
      "question": "Что такое SVM, и как он работает?",
      "answer": "SVM (Support Vector Machine) – это алгоритм машинного обучения, который используется для классификации данных. Его цель – найти такую линию (или гиперплоскость), которая лучше всего разделяет данные на классы.\nКлючевая идея SVM:\n* SVM не просто ищет любую разделяющую линию, а выбирает ту, которая максимально увеличивает зазор между точками двух классов.\n* Точки, ближайшие к разделяющей линии, называются опорными векторами. Эти точки определяют положение линии.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что делать, если классы нельзя разделить прямой линией?\nОтвет: Если данные не разделяются прямой линией, SVM использует ядерные функции (kernels). Ядра помогают преобразовать данные в другое пространство, где классы становятся линейно разделимыми.\nПример:\n* Представьте, что классы в данных образуют круги, и прямой линией их разделить нельзя. С помощью ядра данные можно \"поднять\" в 3D-пространство, где они станут разделимыми плоскостью.\nПопулярные ядра:",
    "metadata": {
      "section": "Как SVM работает с нелинейными данными",
      "question_number": 39,
      "question": "Что делать, если классы нельзя разделить прямой линией?",
      "answer": "Если данные не разделяются прямой линией, SVM использует ядерные функции (kernels). Ядра помогают преобразовать данные в другое пространство, где классы становятся линейно разделимыми.\nПример:\n* Представьте, что классы в данных образуют круги, и прямой линией их разделить нельзя. С помощью ядра данные можно \"поднять\" в 3D-пространство, где они станут разделимыми плоскостью.\nПопулярные ядра:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Чем отличается SVM от логистической регрессии?\nОтвет: ",
    "metadata": {
      "section": "Отличия SVM и логистической регрессии",
      "question_number": 40,
      "question": "Чем отличается SVM от логистической регрессии?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему SVM стремится к максимальному зазору между классами?\nОтвет: Максимальный зазор делает модель более устойчивой. Если зазор между классами большой, новые данные, даже с шумом или выбросами, с большей вероятностью будут классифицированы правильно.",
    "metadata": {
      "section": "Отличия SVM и логистической регрессии",
      "question_number": 41,
      "question": "Почему SVM стремится к максимальному зазору между классами?",
      "answer": "Максимальный зазор делает модель более устойчивой. Если зазор между классами большой, новые данные, даже с шумом или выбросами, с большей вероятностью будут классифицированы правильно.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как SVM оценивает ошибки?\nОтвет: ",
    "metadata": {
      "section": "Функция потерь в SVM",
      "question_number": 42,
      "question": "Как SVM оценивает ошибки?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как SVM предотвращает переобучение?\nОтвет: ",
    "metadata": {
      "section": "Регуляризация в SVM",
      "question_number": 43,
      "question": "Как SVM предотвращает переобучение?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Когда использовать SVM?\nОтвет: Используйте SVM, если:\n* Данные линейно или нелинейно разделимы (второе решается с помощью ядер).\n* Требуется высокая точность классификации.\n* Размер данных небольшой или средний (до нескольких десятков тысяч примеров).\nНе используйте SVM, если:\n* У вас очень большие данные (миллионы примеров), так как SVM работает медленно.\n* Нужны вероятности классов (логистическая регрессия предсказывает вероятности лучше).",
    "metadata": {
      "section": "Применение и особенности",
      "question_number": 44,
      "question": "Когда использовать SVM?",
      "answer": "Используйте SVM, если:\n* Данные линейно или нелинейно разделимы (второе решается с помощью ядер).\n* Требуется высокая точность классификации.\n* Размер данных небольшой или средний (до нескольких десятков тысяч примеров).\nНе используйте SVM, если:\n* У вас очень большие данные (миллионы примеров), так как SVM работает медленно.\n* Нужны вероятности классов (логистическая регрессия предсказывает вероятности лучше).",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как SVM работает с несбалансированными данными?\nОтвет: SVM справляется с несбалансированными данными, добавляя веса классам. Это позволяет учитывать, что редкий класс важнее, чем более частый.\nПример:\n* Если один класс составляет 90% данных, а другой – только 10%, ошибку для редкого класса можно \"усилить\" (увеличить её вес в функции потерь).",
    "metadata": {
      "section": "Применение и особенности",
      "question_number": 45,
      "question": "Как SVM работает с несбалансированными данными?",
      "answer": "SVM справляется с несбалансированными данными, добавляя веса классам. Это позволяет учитывать, что редкий класс важнее, чем более частый.\nПример:\n* Если один класс составляет 90% данных, а другой – только 10%, ошибку для редкого класса можно \"усилить\" (увеличить её вес в функции потерь).",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: У меня миллион данных, что выбрать: SVM или логистическую регрессию?\nОтвет: Выберите логистическую регрессию, если:",
    "metadata": {
      "section": "Пример выбора между SVM и логистической регрессией",
      "question_number": 46,
      "question": "У меня миллион данных, что выбрать: SVM или логистическую регрессию?",
      "answer": "Выберите логистическую регрессию, если:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое регуляризация и зачем она нужна?\nОтвет: Регуляризация — это техника, используемая для предотвращения переобучения (overfitting) моделей машинного обучения путем добавления штрафных (регуляризационных) членов к функции потерь модели. Регуляризация помогает уменьшить сложность модели и сделать её более способной к обобщению, а не к запоминанию деталей тренировочных данных. Модели с большим количеством параметров могут быть склонны к переобучению, так как они легко запоминают случайные шумы и особенности данных. Регуляризация вводит штраф за слишком большие значения параметров модели, что заставляет модель искать более простые и обобщенные решения. \nОсновные задачи регуляризации:",
    "metadata": {
      "section": "Основные понятия",
      "question_number": 47,
      "question": "Что такое регуляризация и зачем она нужна?",
      "answer": "Регуляризация — это техника, используемая для предотвращения переобучения (overfitting) моделей машинного обучения путем добавления штрафных (регуляризационных) членов к функции потерь модели. Регуляризация помогает уменьшить сложность модели и сделать её более способной к обобщению, а не к запоминанию деталей тренировочных данных. Модели с большим количеством параметров могут быть склонны к переобучению, так как они легко запоминают случайные шумы и особенности данных. Регуляризация вводит штраф за слишком большие значения параметров модели, что заставляет модель искать более простые и обобщенные решения. \nОсновные задачи регуляризации:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как регуляризация помогает избежать переобучения?\nОтвет: Регуляризация накладывает ограничения на величины параметров модели, что уменьшает её сложность и обобщает её поведение. Она помогает предотвратить слишком точное подстраивание модели под тренировочные данные и фокусирует её на выявлении общих закономерностей. Это помогает:\nНапример:",
    "metadata": {
      "section": "Устойчивость модели: Регуляризация делает модель менее чувствительной к изменениям в данных и выбросам.",
      "question_number": 48,
      "question": "Как регуляризация помогает избежать переобучения?",
      "answer": "Регуляризация накладывает ограничения на величины параметров модели, что уменьшает её сложность и обобщает её поведение. Она помогает предотвратить слишком точное подстраивание модели под тренировочные данные и фокусирует её на выявлении общих закономерностей. Это помогает:\nНапример:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие виды регуляризации существуют?\nОтвет: ",
    "metadata": {
      "section": "Виды регуляризации",
      "question_number": 49,
      "question": "Какие виды регуляризации существуют?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какая разница между регуляризацией L1 и L2?\nОтвет: * L1 (Lasso):\n   * Использует сумму абсолютных значений весов.\n   * Может занулять веса (полностью исключая некоторые признаки).\n   * Полезна для отбора признаков.\n* L2 (Ridge):\n   * Использует сумму квадратов весов.\n   * Уменьшает значения весов, но не зануляет их.\n   * Делает модель менее чувствительной к шуму.\n* L2-регуляризация \"предпочитает\" уменьшить все веса пропорционально, не исключая их полностью. Это делает модель более стабильной, так как все признаки сохраняют влияние, хотя и ослабленное.\n* L1-регуляризация \"выбирает\", какие признаки важны, зануляя остальные, что способствует разреженности модели.",
    "metadata": {
      "section": "Виды регуляризации",
      "question_number": 50,
      "question": "Какая разница между регуляризацией L1 и L2?",
      "answer": "* L1 (Lasso):\n   * Использует сумму абсолютных значений весов.\n   * Может занулять веса (полностью исключая некоторые признаки).\n   * Полезна для отбора признаков.\n* L2 (Ridge):\n   * Использует сумму квадратов весов.\n   * Уменьшает значения весов, но не зануляет их.\n   * Делает модель менее чувствительной к шуму.\n* L2-регуляризация \"предпочитает\" уменьшить все веса пропорционально, не исключая их полностью. Это делает модель более стабильной, так как все признаки сохраняют влияние, хотя и ослабленное.\n* L1-регуляризация \"выбирает\", какие признаки важны, зануляя остальные, что способствует разреженности модели.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как работают L1 и L2 регуляризации?\nОтвет: ",
    "metadata": {
      "section": "Механика работы",
      "question_number": 51,
      "question": "Как работают L1 и L2 регуляризации?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему L1-регуляризация зануляет веса?\nОтвет: Почему L1 регуляризация отбирает признаки? Понятное объяснение",
    "metadata": {
      "section": "Механика работы",
      "question_number": 52,
      "question": "Почему L1-регуляризация зануляет веса?",
      "answer": "Почему L1 регуляризация отбирает признаки? Понятное объяснение",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Что такое переобучение, и как регуляризация помогает с ним бороться?\nОтвет: Переобучение – это ситуация, когда модель слишком хорошо подстраивается под тренировочные данные, включая шум, и плохо обобщает на новые данные.\nРегуляризация помогает:\n* Контролировать сложность модели.\n* Уменьшать влияние шумов и незначимых признаков.\n* Делать модель более устойчивой к изменениям данных.",
    "metadata": {
      "section": "Связь регуляризации с переобучением",
      "question_number": 53,
      "question": "Что такое переобучение, и как регуляризация помогает с ним бороться?",
      "answer": "Переобучение – это ситуация, когда модель слишком хорошо подстраивается под тренировочные данные, включая шум, и плохо обобщает на новые данные.\nРегуляризация помогает:\n* Контролировать сложность модели.\n* Уменьшать влияние шумов и незначимых признаков.\n* Делать модель более устойчивой к изменениям данных.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие ещё методы помогают бороться с переобучением, кроме регуляризации?\nОтвет: ",
    "metadata": {
      "section": "Связь регуляризации с переобучением",
      "question_number": 54,
      "question": "Какие ещё методы помогают бороться с переобучением, кроме регуляризации?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как выбрать между L1 и L2 регуляризациями?\nОтвет: * Используйте L1, если:\n   * Хотите отобрать наиболее важные признаки.\n   * Работаете с высокоразмерными данными.\n* Используйте L2, если:\n   * Хотите уменьшить переобучение, не исключая признаки.\n   * Данные имеют коррелированные признаки.\n* Используйте Elastic Net, если признаки коррелированы, и требуется комбинация свойств L1 и L",
    "metadata": {
      "section": "Практические аспекты",
      "question_number": 55,
      "question": "Как выбрать между L1 и L2 регуляризациями?",
      "answer": "* Используйте L1, если:\n   * Хотите отобрать наиболее важные признаки.\n   * Работаете с высокоразмерными данными.\n* Используйте L2, если:\n   * Хотите уменьшить переобучение, не исключая признаки.\n   * Данные имеют коррелированные признаки.\n* Используйте Elastic Net, если признаки коррелированы, и требуется комбинация свойств L1 и L",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: \nОтвет: λ контролирует степень штрафа за сложность модели.\n* Большое λ: сильная регуляризация, модель проще.\n* Малое λ: слабая регуляризация, модель сложнее.\nДля выбора λ используют:",
    "metadata": {
      "section": "Вопрос: Что такое гиперпараметр λ, и как его выбирать?",
      "question_number": 56,
      "question": "",
      "answer": "λ контролирует степень штрафа за сложность модели.\n* Большое λ: сильная регуляризация, модель проще.\n* Малое λ: слабая регуляризация, модель сложнее.\nДля выбора λ используют:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как Elastic Net объединяет свойства L1 и L2 регуляризаций?\nОтвет: Метрики\nЧем отличается метрика от Loss?",
    "metadata": {
      "section": "Регуляризационные пути: Построение зависимости метрик от λ\\lambdaλ.",
      "question_number": 57,
      "question": "Как Elastic Net объединяет свойства L1 и L2 регуляризаций?",
      "answer": "Метрики\nЧем отличается метрика от Loss?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какие основные метрики используются для оценки моделей регрессии?\nОтвет: ",
    "metadata": {
      "section": "Основные метрики регрессии",
      "question_number": 58,
      "question": "Какие основные метрики используются для оценки моделей регрессии?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какая из метрик чувствительнее к выбросам, MSE или MAE?\nОтвет: * MSE более чувствительна к выбросам, потому что она усредняет квадраты ошибок, увеличивая вклад больших ошибок.\n   * MAE менее чувствительна к выбросам, так как она усредняет абсолютные значения ошибок.\n   * Выбор метрики зависит от задачи: если важнее учесть большие ошибки, выбирают MSE. Если важна устойчивость к выбросам, используют MAE.\n\nПочему RMSE чаще используется, чем MSE?",
    "metadata": {
      "section": "R^2 (Коэффициент детерминации):",
      "question_number": 59,
      "question": "Какая из метрик чувствительнее к выбросам, MSE или MAE?",
      "answer": "* MSE более чувствительна к выбросам, потому что она усредняет квадраты ошибок, увеличивая вклад больших ошибок.\n   * MAE менее чувствительна к выбросам, так как она усредняет абсолютные значения ошибок.\n   * Выбор метрики зависит от задачи: если важнее учесть большие ошибки, выбирают MSE. Если важна устойчивость к выбросам, используют MAE.\n\nПочему RMSE чаще используется, чем MSE?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Площадь под кривой зависимости Precision и Recall для различных порогов.\n      * Преимущество: более полезна в задачах с несбалансированными классами, где положительный класс встречается редко.\n      * В отличие от ROC-AUC, PR-AUC фокусируется на правильной работе модели с положительным классом.\n\nЧто такое Confusion Matrix, и как она помогает в оценке модели?\nОтвет: Confusion Matrix (матрица ошибок) — это таблица, которая позволяет визуализировать результаты работы классификационной модели, сравнивая предсказанные классы с истинными.\n  \n\nЭлементы матрицы:",
    "metadata": {
      "section": "PR-AUC (Area Under the Precision-Recall Curve):",
      "question_number": 60,
      "question": "Площадь под кривой зависимости Precision и Recall для различных порогов.\n      * Преимущество: более полезна в задачах с несбалансированными классами, где положительный класс встречается редко.\n      * В отличие от ROC-AUC, PR-AUC фокусируется на правильной работе модели с положительным классом.\n\nЧто такое Confusion Matrix, и как она помогает в оценке модели?",
      "answer": "Confusion Matrix (матрица ошибок) — это таблица, которая позволяет визуализировать результаты работы классификационной модели, сравнивая предсказанные классы с истинными.\n  \n\nЭлементы матрицы:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Расскажите о метрике Accuracy.\nОтвет: Описание:\nAccuracy измеряет долю правильно классифицированных объектов от общего числа.\nФормула:  \n\nРасскажите про метрику Precision.",
    "metadata": {
      "section": "False Negative (FN): Количество объектов, ошибочно классифицированных как отрицательные (ошибки второго рода).",
      "question_number": 61,
      "question": "Расскажите о метрике Accuracy.",
      "answer": "Описание:\nAccuracy измеряет долю правильно классифицированных объектов от общего числа.\nФормула:  \n\nРасскажите про метрику Precision.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Порядок останется неизменным, ROC-AUC не изменится.\n\nЧто такое PR-AUC и как она отличается от ROC-AUC?\nОтвет: Как с помощью PR-AUC подбирать баланс между Precision и Recall?",
    "metadata": {
      "section": "Возведение в квадрат:",
      "question_number": 62,
      "question": "* Порядок останется неизменным, ROC-AUC не изменится.\n\nЧто такое PR-AUC и как она отличается от ROC-AUC?",
      "answer": "Как с помощью PR-AUC подбирать баланс между Precision и Recall?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Деревья\n  \n\n  \n\n  \n\n  \n\n  \n\nОпределение порогов для категориальных и числовых признаков\nhttps://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e\n  \n  \n\nЧто такое дерево решений, и как оно работает?\nОтвет: Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.\nКаждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).\nПример:\nВ медицинской задаче:\n         * Вершина 1: \"Возраст > 40 лет?\"\n         * Да → Вершина 2: \"Курит?\"\n         * Нет → Прогноз: \"Низкий риск заболевания\".\n         * Вершина 2:\n         * Да → Прогноз: \"Высокий риск заболевания\".\n         * Нет → Прогноз: \"Средний риск заболевания\".\n  \n\n  \n\nКак строится дерево решений?\nВыбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:",
    "metadata": {
      "section": "Например, увеличение положительных классов может улучшить Recall, но Precision может ухудшиться, что приведёт к изменению PR-кривой.",
      "question_number": 63,
      "question": "Деревья\n  \n\n  \n\n  \n\n  \n\n  \n\nОпределение порогов для категориальных и числовых признаков\nhttps://chatgpt.com/share/676a9d69-d938-800e-9da3-1cc56e197f2e\n  \n  \n\nЧто такое дерево решений, и как оно работает?",
      "answer": "Дерево решений — это алгоритм машинного обучения, представляющий процесс принятия решений в виде структуры дерева.\nКаждая вершина дерева содержит правило разбиения (предикат), которое делит данные на подмножества. Конечные вершины дерева (листья) содержат прогноз: класс (для задач классификации) или числовое значение (для задач регрессии).\nПример:\nВ медицинской задаче:\n         * Вершина 1: \"Возраст > 40 лет?\"\n         * Да → Вершина 2: \"Курит?\"\n         * Нет → Прогноз: \"Низкий риск заболевания\".\n         * Вершина 2:\n         * Да → Прогноз: \"Высокий риск заболевания\".\n         * Нет → Прогноз: \"Средний риск заболевания\".\n  \n\n  \n\nКак строится дерево решений?\nВыбор признака и порога разбиения в узле дерева решений — это ключевой шаг, направленный на минимизацию хаотичности (неопределённости) данных в каждом подмножестве после разбиения. Этот процесс включает несколько этапов:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Выбирается тот признак и порог, которые дают наибольшее уменьшение хаотичности (например, снижение критерия Джини или энтропии).\n  \n\nИтог:\nПризнак и порог разбиения выбираются так, чтобы наилучшим образом разделить данные, делая узлы максимально однородными.\n         * \n\nЧто такое жадный алгоритм построения дерева?\nОтвет: Жадный алгоритм строит дерево решений шаг за шагом, выбирая на каждом этапе лучшее разбиение по текущему критерию качества.\nЭтапы жадного алгоритма:",
    "metadata": {
      "section": "Выбор наилучшего разбиения:",
      "question_number": 64,
      "question": "* Выбирается тот признак и порог, которые дают наибольшее уменьшение хаотичности (например, снижение критерия Джини или энтропии).\n  \n\nИтог:\nПризнак и порог разбиения выбираются так, чтобы наилучшим образом разделить данные, делая узлы максимально однородными.\n         * \n\nЧто такое жадный алгоритм построения дерева?",
      "answer": "Жадный алгоритм строит дерево решений шаг за шагом, выбирая на каждом этапе лучшее разбиение по текущему критерию качества.\nЭтапы жадного алгоритма:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Недостаток жадного подхода:\nАлгоритм не гарантирует нахождение глобально оптимального дерева, так как каждое разбиение выбирается только на основе локальной оптимальности.\n\nЧто такое критерий качества и критерий информативности?\nОтвет: Пример:\nЕсли узел содержит 100% объектов одного класса, его энтропия равна 0 (максимальная информативность).\n\nКак подбирается предикат (правило разбиения)?",
    "metadata": {
      "section": "Проверяем критерий останова: если выполнен — создаём лист, если нет — повторяем шаги для новых узлов.",
      "question_number": 65,
      "question": "Недостаток жадного подхода:\nАлгоритм не гарантирует нахождение глобально оптимального дерева, так как каждое разбиение выбирается только на основе локальной оптимальности.\n\nЧто такое критерий качества и критерий информативности?",
      "answer": "Пример:\nЕсли узел содержит 100% объектов одного класса, его энтропия равна 0 (максимальная информативность).\n\nКак подбирается предикат (правило разбиения)?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Пример:\nЕсли узел содержит людей разного возраста и курящих/некурящих, предикат \"Курит?\" может лучше разделить данные на группы, чем \"Возраст > 30\".\n\nЧто такое критерий Джини и энтропия?\nОтвет: Какие гиперпараметры есть у дерева решений?",
    "metadata": {
      "section": "Выбирается разбиение с максимальным уменьшением хаотичности.",
      "question_number": 66,
      "question": "Пример:\nЕсли узел содержит людей разного возраста и курящих/некурящих, предикат \"Курит?\" может лучше разделить данные на группы, чем \"Возраст > 30\".\n\nЧто такое критерий Джини и энтропия?",
      "answer": "Какие гиперпараметры есть у дерева решений?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Пример:\nЕсли признак \"Возраст\" часто используется для разделения и значительно уменьшает хаотичность, его важность будет высокой.\n\nЧто лежит в листьях дерева?\nОтвет: В листьях дерева содержатся прогнозы для данных, которые дошли до этого узла:\n         * В задачах классификации: класс с максимальной вероятностью.\n         * В задачах регрессии: среднее значение целевой переменной для объектов в листе.\nПример:\nДля задачи классификации: если в листе 10 объектов, из которых 8 принадлежат классу A, то прогноз для листа — класс A.\n\nКаковы критерии остановки построения дерева?",
    "metadata": {
      "section": "Вклад всех разбиений для признака суммируется.",
      "question_number": 67,
      "question": "Пример:\nЕсли признак \"Возраст\" часто используется для разделения и значительно уменьшает хаотичность, его важность будет высокой.\n\nЧто лежит в листьях дерева?",
      "answer": "В листьях дерева содержатся прогнозы для данных, которые дошли до этого узла:\n         * В задачах классификации: класс с максимальной вероятностью.\n         * В задачах регрессии: среднее значение целевой переменной для объектов в листе.\nПример:\nДля задачи классификации: если в листе 10 объектов, из которых 8 принадлежат классу A, то прогноз для листа — класс A.\n\nКаковы критерии остановки построения дерева?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Комбинирует прогнозы нескольких моделей с помощью метамодели.\n         * Прогнозы базовых моделей используются как входные данные для метамодели, которая делает финальное предсказание.\n\nЧто такое случайный лес и как он строится?\nОтвет: Случайный лес — это ансамблевый метод, который строится на основе комбинации множества деревьев решений.\nЭтапы построения случайного леса:",
    "metadata": {
      "section": "Стекинг:",
      "question_number": 68,
      "question": "* Комбинирует прогнозы нескольких моделей с помощью метамодели.\n         * Прогнозы базовых моделей используются как входные данные для метамодели, которая делает финальное предсказание.\n\nЧто такое случайный лес и как он строится?",
      "answer": "Случайный лес — это ансамблевый метод, который строится на основе комбинации множества деревьев решений.\nЭтапы построения случайного леса:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Прогнозы деревьев усредняются (для регрессии) или используется голосование большинства (для классификации).\nПример:\nПри прогнозировании цен недвижимости каждое дерево может делать свои предположения о цене. Финальный прогноз будет средней ценой, предсказанной всеми деревьями.\n\nКак работают случайные выборки семплов и признаков в случайном лесе, и почему это важно для его эффективности?\nОтвет: В случайном лесе для каждого дерева случайно выбираются:",
    "metadata": {
      "section": "Комбинация результатов:",
      "question_number": 69,
      "question": "* Прогнозы деревьев усредняются (для регрессии) или используется голосование большинства (для классификации).\nПример:\nПри прогнозировании цен недвижимости каждое дерево может делать свои предположения о цене. Финальный прогноз будет средней ценой, предсказанной всеми деревьями.\n\nКак работают случайные выборки семплов и признаков в случайном лесе, и почему это важно для его эффективности?",
      "answer": "В случайном лесе для каждого дерева случайно выбираются:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему это важно:\n         * Бутстрэппинг объектов снижает дисперсию модели за счёт усреднения предсказаний разных деревьев.\n         * Случайный выбор признаков уменьшает корреляцию между деревьями, что улучшает общую обобщающую способность ансамбля.\n\nПочему случайный лес устойчив к шуму и выбросам?\nОтвет: Случайный лес устойчив к шуму и выбросам благодаря следующим свойствам:",
    "metadata": {
      "section": "Признаки по xxx (фичи): при каждом разбиении узла вместо рассмотрения всех признаков, случайно выбирается подмножество признаков. Размер подмножества часто задаётся как sqrt(M)​ для классификации или M/3 для регрессии, где М— общее количество признаков.",
      "question_number": 70,
      "question": "Почему это важно:\n         * Бутстрэппинг объектов снижает дисперсию модели за счёт усреднения предсказаний разных деревьев.\n         * Случайный выбор признаков уменьшает корреляцию между деревьями, что улучшает общую обобщающую способность ансамбля.\n\nПочему случайный лес устойчив к шуму и выбросам?",
      "answer": "Случайный лес устойчив к шуму и выбросам благодаря следующим свойствам:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Для задач регрессии: выбросы влияют на отдельные деревья, но их вклад минимизируется благодаря усреднению предсказаний всех деревьев.\n         * Для задач классификации: выбросы могут вносить ошибки в некоторые деревья, но итоговое голосование большинства деревьев нивелирует эти ошибки.\nТаким образом, случайный лес уменьшает влияние выбросов и шума, делая модель более устойчивой.\n\nПочему случайный лес плохо подходит для задач экстраполяции?\nОтвет: Случайный лес, как и деревья решений, не подходит для экстраполяции, поскольку:",
    "metadata": {
      "section": "Усреднение предсказаний:",
      "question_number": 71,
      "question": "* Для задач регрессии: выбросы влияют на отдельные деревья, но их вклад минимизируется благодаря усреднению предсказаний всех деревьев.\n         * Для задач классификации: выбросы могут вносить ошибки в некоторые деревья, но итоговое голосование большинства деревьев нивелирует эти ошибки.\nТаким образом, случайный лес уменьшает влияние выбросов и шума, делая модель более устойчивой.\n\nПочему случайный лес плохо подходит для задач экстраполяции?",
      "answer": "Случайный лес, как и деревья решений, не подходит для экстраполяции, поскольку:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Пример: Если модель обучалась на данных с целевыми значениям и y∈[100,500], то для нового объекта с признаками, выходящими за диапазон обучающей выборки, случайный лес предскажет значение внутри диапазона y, так как ни одно дерево не может \"экстраполировать\" за пределы видимых данных.\n\nВ чем отличие случайного леса от градиентного бустинга?\nОтвет: ",
    "metadata": {
      "section": "Усреднение предсказаний деревьев не даёт возможности выходить за пределы существующих данных.",
      "question_number": 72,
      "question": "Пример: Если модель обучалась на данных с целевыми значениям и y∈[100,500], то для нового объекта с признаками, выходящими за диапазон обучающей выборки, случайный лес предскажет значение внутри диапазона y, так как ни одно дерево не может \"экстраполировать\" за пределы видимых данных.\n\nВ чем отличие случайного леса от градиентного бустинга?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Деревья в градиентном бустинге обычно короче, поэтому предсказания делаются быстрее.\n\nГрадиентный бустинг\nКак работает градиентный бустинг?\nОтвет: Градиентный бустинг обучается последовательным исправлением ошибок предыдущих моделей с использованием остаточной ошибки (антиградиента) в качестве целевой переменной.\nЭтапы:",
    "metadata": {
      "section": "Предсказание:",
      "question_number": 73,
      "question": "* Деревья в градиентном бустинге обычно короче, поэтому предсказания делаются быстрее.\n\nГрадиентный бустинг\nКак работает градиентный бустинг?",
      "answer": "Градиентный бустинг обучается последовательным исправлением ошибок предыдущих моделей с использованием остаточной ошибки (антиградиента) в качестве целевой переменной.\nЭтапы:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Процесс повторяется до заданного количества итераций или достижения приемлемой метрики.\nПример: Прогнозирование стоимости автомобилей: первое дерево предсказывает среднюю цену, второе исправляет отклонения, и так далее.\n  \n\nПочему бустинг так называется?\nОтвет: Метод назван \"бустингом\", потому что он улучшает (boost) слабые модели (обычно деревья решений) до сильного ансамбля. Каждое новое дерево добавляет свою \"корректировку\", улучшая общее качество предсказаний.\n\nПочему бустинг называется градиентным?\n  \n\nКаковы основные гиперпараметры градиентного бустинга?\n  \n\nЧто произойдет, если убрать одно дерево из ансамбля случайного леса и градиентного бустинга?",
    "metadata": {
      "section": "Повторение:",
      "question_number": 74,
      "question": "* Процесс повторяется до заданного количества итераций или достижения приемлемой метрики.\nПример: Прогнозирование стоимости автомобилей: первое дерево предсказывает среднюю цену, второе исправляет отклонения, и так далее.\n  \n\nПочему бустинг так называется?",
      "answer": "Метод назван \"бустингом\", потому что он улучшает (boost) слабые модели (обычно деревья решений) до сильного ансамбля. Каждое новое дерево добавляет свою \"корректировку\", улучшая общее качество предсказаний.\n\nПочему бустинг называется градиентным?\n  \n\nКаковы основные гиперпараметры градиентного бустинга?\n  \n\nЧто произойдет, если убрать одно дерево из ансамбля случайного леса и градиентного бустинга?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Какой глубины деревья используются в случайном лесе и градиентном бустинге?\nОтвет: * Случайный лес:\nИспользуются глубокие деревья (большая глубина, часто без ограничения), чтобы максимально улавливать закономерности в данных.\n            * Градиентный бустинг:\nИспользуются неглубокие деревья (3-6 уровней), чтобы каждое дерево выполняло небольшую корректировку и предотвращалось переобучение.\n\nМожет ли градиентный бустинг переобучиться с увеличением количества деревьев?",
    "metadata": {
      "section": "Риск переобучения: При неправильной настройке гиперпараметров или большом количестве деревьев модель может переобучиться.",
      "question_number": 75,
      "question": "Какой глубины деревья используются в случайном лесе и градиентном бустинге?",
      "answer": "* Случайный лес:\nИспользуются глубокие деревья (большая глубина, часто без ограничения), чтобы максимально улавливать закономерности в данных.\n            * Градиентный бустинг:\nИспользуются неглубокие деревья (3-6 уровней), чтобы каждое дерево выполняло небольшую корректировку и предотвращалось переобучение.\n\nМожет ли градиентный бустинг переобучиться с увеличением количества деревьев?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Как формируется итоговый прогноз в градиентном бустинге?\nОтвет: Итоговый прогноз в градиентном бустинге формируется путем последовательного суммирования предсказаний всех слабых моделей в ансамбле.\nЭтапы:",
    "metadata": {
      "section": "Применять регуляризацию (например, ограничение глубины деревьев или минимального числа объектов в листе).",
      "question_number": 76,
      "question": "Как формируется итоговый прогноз в градиентном бустинге?",
      "answer": "Итоговый прогноз в градиентном бустинге формируется путем последовательного суммирования предсказаний всех слабых моделей в ансамбле.\nЭтапы:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Итоговый прогноз — это сумма всех индивидуальных предсказаний деревьев, скорректированная на каждом этапе.\n\nМожет ли градиентный бустинг стать хуже при увеличении количества деревьев?\nОтвет: Да, градиентный бустинг может переобучиться с увеличением числа деревьев. Если деревьев становится слишком много, модель начинает \"запоминать\" тренировочные данные, что ухудшает ее обобщающую способность на новых данных.\nКак предотвратить переобучение:",
    "metadata": {
      "section": "Процесс продолжается до заданного числа итераций или достижения приемлемой метрики.",
      "question_number": 77,
      "question": "Итоговый прогноз — это сумма всех индивидуальных предсказаний деревьев, скорректированная на каждом этапе.\n\nМожет ли градиентный бустинг стать хуже при увеличении количества деревьев?",
      "answer": "Да, градиентный бустинг может переобучиться с увеличением числа деревьев. Если деревьев становится слишком много, модель начинает \"запоминать\" тренировочные данные, что ухудшает ее обобщающую способность на новых данных.\nКак предотвратить переобучение:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Почему в градиентном бустинге используют деревья небольшой глубины?\nОтвет: В градиентном бустинге обычно применяются деревья небольшой глубины (3–6 уровней), чтобы:",
    "metadata": {
      "section": "Использовать регуляризацию, например, минимальное число объектов в листьях или раннюю остановку (early stopping).",
      "question_number": 78,
      "question": "Почему в градиентном бустинге используют деревья небольшой глубины?",
      "answer": "В градиентном бустинге обычно применяются деревья небольшой глубины (3–6 уровней), чтобы:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Пример: Вместо создания сложных моделей каждая итерация добавляет небольшой вклад в итоговое предсказание.\n\nКак повлияет удаление первого или последнего дерева на метрику ошибки, например MAE, в ансамбле бустинга?\nОтвет: * Удаление первого дерева:\nУдаление первого дерева изменит базовый уровень предсказаний, так как все остальные деревья строились с учетом его вклада. Это может существенно изменить итоговые предсказания и, как следствие, величину метрики ошибки.\n               * Удаление последнего дерева:\nУдаление последнего дерева меньше повлияет на предсказания, так как оно лишь слегка корректирует результат. Тем не менее, итоговая метрика ошибки также изменится, в зависимости от того, насколько велик вклад удаленного дерева.\nПример: если первое дерево задает основное направление предсказаний, его удаление вызывает сильное отклонение, тогда как последнее дерево выполняет минимальные улучшения.\n\nВ каких случаях линейная регрессия предпочтительнее градиентного бустинга?",
    "metadata": {
      "section": "Снизить вычислительную сложность: Неглубокие деревья обучаются и прогнозируют быстрее, что важно для задач с большим количеством итераций.",
      "question_number": 79,
      "question": "Пример: Вместо создания сложных моделей каждая итерация добавляет небольшой вклад в итоговое предсказание.\n\nКак повлияет удаление первого или последнего дерева на метрику ошибки, например MAE, в ансамбле бустинга?",
      "answer": "* Удаление первого дерева:\nУдаление первого дерева изменит базовый уровень предсказаний, так как все остальные деревья строились с учетом его вклада. Это может существенно изменить итоговые предсказания и, как следствие, величину метрики ошибки.\n               * Удаление последнего дерева:\nУдаление последнего дерева меньше повлияет на предсказания, так как оно лишь слегка корректирует результат. Тем не менее, итоговая метрика ошибки также изменится, в зависимости от того, насколько велик вклад удаленного дерева.\nПример: если первое дерево задает основное направление предсказаний, его удаление вызывает сильное отклонение, тогда как последнее дерево выполняет минимальные улучшения.\n\nВ каких случаях линейная регрессия предпочтительнее градиентного бустинга?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Пример: если зависимость \"цена квартиры – площадь квартиры\" линейна, то линейная регрессия даст точный и интерпретируемый результат.\n\nКак осуществляется разбиение данных в узлах дерева у бустинга для задачи регрессии?\nОтвет: Процесс разбиения:",
    "metadata": {
      "section": "Интерпретируемость: Линейная регрессия предоставляет явное представление о влиянии каждого признака, что важно для объяснения результатов.",
      "question_number": 80,
      "question": "Пример: если зависимость \"цена квартиры – площадь квартиры\" линейна, то линейная регрессия даст точный и интерпретируемый результат.\n\nКак осуществляется разбиение данных в узлах дерева у бустинга для задачи регрессии?",
      "answer": "Процесс разбиения:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: Особенности:\n                  * В бустинге разбиения учитывают текущую ошибку предсказаний, чтобы минимизировать остатки.\n                  * При этом каждое дерево обучается на новых остатках, увеличивая точность\n\nЧто такое Bias-Variance-Tradeoff?\nОтвет: Если я уберу одно дерево из случайного леса, то что случится с смещением, а что с разбросом?",
    "metadata": {
      "section": "Процесс повторяется рекурсивно для каждой группы до достижения критерия остановки (максимальная глубина, минимальное число объектов в листе).",
      "question_number": 81,
      "question": "Особенности:\n                  * В бустинге разбиения учитывают текущую ошибку предсказаний, чтобы минимизировать остатки.\n                  * При этом каждое дерево обучается на новых остатках, увеличивая точность\n\nЧто такое Bias-Variance-Tradeoff?",
      "answer": "Если я уберу одно дерево из случайного леса, то что случится с смещением, а что с разбросом?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * При дисбалансе классов точность модели (accuracy) становится некорректной метрикой. Используйте F1-score, AUC-ROC или Precision-Recall Curve для оценки модели.\n\nЧем тестовая выборка отличается от валидационной?\nОтвет: Тестовая и валидационная выборки выполняют разные задачи в процессе обучения модели.",
    "metadata": {
      "section": "Применение специальных метрик:",
      "question_number": 82,
      "question": "* При дисбалансе классов точность модели (accuracy) становится некорректной метрикой. Используйте F1-score, AUC-ROC или Precision-Recall Curve для оценки модели.\n\nЧем тестовая выборка отличается от валидационной?",
      "answer": "Тестовая и валидационная выборки выполняют разные задачи в процессе обучения модели.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Используется для настройки гиперпараметров модели и выбора оптимальной конфигурации.\n                        * Пример: выбор лучшего значения learningrate в градиентном бустинге.\n                        * На практике часто применяется K-Fold кросс-валидация для более точной оценки, где данные многократно разделяются на обучающую и валидационную выборки.\n\nКакие существуют методы борьбы с переобучением?\nОтвет: Переобучение возникает, когда модель слишком хорошо \"запоминает\" тренировочные данные, теряя способность обобщать на новых. Методы борьбы включают:",
    "metadata": {
      "section": "Валидационная выборка (Validation Set):",
      "question_number": 83,
      "question": "* Используется для настройки гиперпараметров модели и выбора оптимальной конфигурации.\n                        * Пример: выбор лучшего значения learningrate в градиентном бустинге.\n                        * На практике часто применяется K-Fold кросс-валидация для более точной оценки, где данные многократно разделяются на обучающую и валидационную выборки.\n\nКакие существуют методы борьбы с переобучением?",
      "answer": "Переобучение возникает, когда модель слишком хорошо \"запоминает\" тренировочные данные, теряя способность обобщать на новых. Методы борьбы включают:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Добавление новых данных делает модель менее склонной к переобучению.\n                        * Пример: в задачах классификации изображений можно добавить больше изображений редкого класса.\n\nЧто делать, если в данных много признаков?\nОтвет: Работа с большим числом признаков требует подходов, которые уменьшают их количество или повышают качество:",
    "metadata": {
      "section": "Увеличение объема данных:",
      "question_number": 84,
      "question": "* Добавление новых данных делает модель менее склонной к переобучению.\n                        * Пример: в задачах классификации изображений можно добавить больше изображений редкого класса.\n\nЧто делать, если в данных много признаков?",
      "answer": "Работа с большим числом признаков требует подходов, которые уменьшают их количество или повышают качество:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Удаление признаков, которые сильно коррелируют друг с другом, помогает избежать избыточности.\n\nЧто такое Dummy Variable Trap и как его избежать?\nОтвет: Dummy Variable Trap возникает при использовании One-Hot-Encoding, если все категории признака закодированы в отдельные столбцы. Это приводит к мультиколлинеарности, так как один из столбцов может быть выражен через остальные.\nКак избежать:\n                        * Удалить один столбец после кодирования. Например, если есть категории \"A\", \"B\", \"C\", закодируйте их как два столбца: [1,0] для \"A\", [0,1] для \"B\", [0,0] для \"C\".\n\nЧто такое TF-IDF и как он работает?",
    "metadata": {
      "section": "Удаление коррелированных признаков:",
      "question_number": 85,
      "question": "* Удаление признаков, которые сильно коррелируют друг с другом, помогает избежать избыточности.\n\nЧто такое Dummy Variable Trap и как его избежать?",
      "answer": "Dummy Variable Trap возникает при использовании One-Hot-Encoding, если все категории признака закодированы в отдельные столбцы. Это приводит к мультиколлинеарности, так как один из столбцов может быть выражен через остальные.\nКак избежать:\n                        * Удалить один столбец после кодирования. Например, если есть категории \"A\", \"B\", \"C\", закодируйте их как два столбца: [1,0] для \"A\", [0,1] для \"B\", [0,0] для \"C\".\n\nЧто такое TF-IDF и как он работает?",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Умножение TF и IDF. Высокие значения имеют слова, часто встречающиеся в данном тексте, но редкие в других.\nПример:\nДля текстов про автомобили слово \"двигатель\" будет иметь высокий TF-IDF, если оно часто встречается в описаниях конкретного авто, но не во всех текстах.\n\nКак бороться с мультиколлинеарностью?\nОтвет: Мультиколлинеарность — это линейная зависимость между признаками.",
    "metadata": {
      "section": "TF-IDF Score:",
      "question_number": 86,
      "question": "* Умножение TF и IDF. Высокие значения имеют слова, часто встречающиеся в данном тексте, но редкие в других.\nПример:\nДля текстов про автомобили слово \"двигатель\" будет иметь высокий TF-IDF, если оно часто встречается в описаниях конкретного авто, но не во всех текстах.\n\nКак бороться с мультиколлинеарностью?",
      "answer": "Мультиколлинеарность — это линейная зависимость между признаками.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Примените PCA, чтобы преобразовать признаки в независимые компоненты.\n\nЧто такое кросс-валидация?\nОтвет: Кросс-валидация — это метод оценки обобщающей способности модели.",
    "metadata": {
      "section": "Снижение размерности:",
      "question_number": 87,
      "question": "* Примените PCA, чтобы преобразовать признаки в независимые компоненты.\n\nЧто такое кросс-валидация?",
      "answer": "Кросс-валидация — это метод оценки обобщающей способности модели.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Для временных рядов обучение проводится на более ранних данных, а тестирование — на более поздних.\nКросс-валидация помогает предотвратить переобучение и выбрать лучшую модель.\nЧем отличается нормализация от стандартизации данных?\nОтвет: Нормализация и стандартизация — это два разных подхода к преобразованию числовых данных.",
    "metadata": {
      "section": "Time Series Split:",
      "question_number": 88,
      "question": "* Для временных рядов обучение проводится на более ранних данных, а тестирование — на более поздних.\nКросс-валидация помогает предотвратить переобучение и выбрать лучшую модель.\nЧем отличается нормализация от стандартизации данных?",
      "answer": "Нормализация и стандартизация — это два разных подхода к преобразованию числовых данных.",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Используется, если данные должны соответствовать стандартному нормальному распределению, например, при использовании моделей линейной регрессии или SVM.\nРазличие:\n                                 * Нормализация используется для приведения данных к фиксированному диапазону.\n                                 * Стандартизация делает данные нормально распределенными, но сохраняет исходный масштаб.\n\nКогда лучше применять нормализацию, а когда стандартизацию?\nОтвет: ",
    "metadata": {
      "section": "* Формула:",
      "question_number": 89,
      "question": "* Используется, если данные должны соответствовать стандартному нормальному распределению, например, при использовании моделей линейной регрессии или SVM.\nРазличие:\n                                 * Нормализация используется для приведения данных к фиксированному диапазону.\n                                 * Стандартизация делает данные нормально распределенными, но сохраняет исходный масштаб.\n\nКогда лучше применять нормализацию, а когда стандартизацию?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Применяется, когда модели предполагают нормальное распределение данных или используют статистические методы.\n                                 * Примеры моделей: линейная регрессия, логистическая регрессия, PCA.\n                                 * Пример задачи: если вы анализируете финансовые данные с большими выбросами, стандартизация лучше нормализации, так как она менее чувствительна к выбросам.\n\nПочему важно нормализовать или стандартизировать данные перед обучением модели?\nОтвет: Приведение данных к единому масштабу необходимо, чтобы:",
    "metadata": {
      "section": "Стандартизация:",
      "question_number": 90,
      "question": "* Применяется, когда модели предполагают нормальное распределение данных или используют статистические методы.\n                                 * Примеры моделей: линейная регрессия, логистическая регрессия, PCA.\n                                 * Пример задачи: если вы анализируете финансовые данные с большими выбросами, стандартизация лучше нормализации, так как она менее чувствительна к выбросам.\n\nПочему важно нормализовать или стандартизировать данные перед обучением модели?",
      "answer": "Приведение данных к единому масштабу необходимо, чтобы:",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Преобразованные данные позволяют лучше понимать вклад каждого признака.\n\nКакие существуют методы нормализации данных?\nОтвет: ",
    "metadata": {
      "section": "Сделать модель более интерпретируемой:",
      "question_number": 91,
      "question": "* Преобразованные данные позволяют лучше понимать вклад каждого признака.\n\nКакие существуют методы нормализации данных?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Основан на медиане и интерквартильном размахе.\n                                 * Формула: \n  \n\n                                 * Применяется, если данные содержат выбросы.\n\nКакие существуют методы стандартизации данных?\nОтвет: ",
    "metadata": {
      "section": "Robust Scaling:",
      "question_number": 92,
      "question": "* Основан на медиане и интерквартильном размахе.\n                                 * Формула: \n  \n\n                                 * Применяется, если данные содержат выбросы.\n\nКакие существуют методы стандартизации данных?",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: * Вариант Z-Score, но вместо σ\\sigmaσ используется дисперсия.\n\nВлияют ли выбросы на нормализацию и стандартизацию?\nОтвет: * Нормализация (Min-Max Scaling):\n                                 * Сильно подвержена влиянию выбросов. Большие выбросы расширяют диапазон данных, \"сжимая\" основную массу значений в узкий интервал.\n                                 * Решение: Использовать Robust Scaling или предварительно обработать выбросы.\n                                 * Стандартизация (Z-Score Scaling):\n                                 * Также чувствительна к выбросам, так как среднее и стандартное отклонение изменяются при наличии аномальных значений.\n                                 * Решение: Использовать Robust Standardization или исключить выбросы.\nПример: в выборке с ценами от $100 до $500 и одним выбросом $10,000, Min-Max Scaling \"сожмет\" все цены в диапазон около",
    "metadata": {
      "section": "Scaling by Mean and Variance:",
      "question_number": 93,
      "question": "* Вариант Z-Score, но вместо σ\\sigmaσ используется дисперсия.\n\nВлияют ли выбросы на нормализацию и стандартизацию?",
      "answer": "* Нормализация (Min-Max Scaling):\n                                 * Сильно подвержена влиянию выбросов. Большие выбросы расширяют диапазон данных, \"сжимая\" основную массу значений в узкий интервал.\n                                 * Решение: Использовать Robust Scaling или предварительно обработать выбросы.\n                                 * Стандартизация (Z-Score Scaling):\n                                 * Также чувствительна к выбросам, так как среднее и стандартное отклонение изменяются при наличии аномальных значений.\n                                 * Решение: Использовать Robust Standardization или исключить выбросы.\nПример: в выборке с ценами от $100 до $500 и одним выбросом $10,000, Min-Max Scaling \"сожмет\" все цены в диапазон около",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  },
  {
    "text": "Вопрос: \nОтвет: ",
    "metadata": {
      "section": "Какие практические рекомендации для нормализации и стандартизации данных?",
      "question_number": 94,
      "question": "",
      "answer": "",
      "source_file": "ВопросыClassicML.txt",
      "description": "Вопросы по классическому машинному обучению"
    }
  }
]
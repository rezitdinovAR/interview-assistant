import asyncio
import json

from aiogram import F, Router, types
from aiogram.fsm.context import FSMContext
from app.keyboards import (
    get_cancel_menu,
    get_main_menu,
    get_persona_keyboard,
)
from app.redis_client import redis_client
from app.states import InterviewState
from app.utils import llm_chat, typing_loop

router = Router()

PERSONA_PROMPTS = {
    "friendly": "–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π HR-—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç. –¢–≤–æ—è —Ü–µ–ª—å - –ø–æ–¥–¥–µ—Ä–∂–∞—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞. –ó–∞–¥–∞–≤–∞–π –≤–æ–ø—Ä–æ—Å—ã –º—è–≥–∫–æ, —Ö–≤–∞–ª–∏ –∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏.",
    "nerd": "–¢—ã - —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –≥–∏–∫-—Å–µ–Ω—å–æ—Ä. –¢–µ–±—è –∏–Ω—Ç–µ—Ä–µ—Å—É—é—Ç —Ç–æ–ª—å–∫–æ –≥–ª—É–±–æ–∫–∏–µ –¥–µ—Ç–∞–ª–∏, —Ä–∞–±–æ—Ç–∞ –ø–∞–º—è—Ç–∏, —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –∏ '–ø–æ–¥ –∫–∞–ø–æ—Ç–æ–º'. –ë—É–¥—å –¥–æ—Ç–æ—à–Ω—ã–º.",
    "toxic": "–¢—ã - –æ—á–µ–Ω—å —Å—Ç—Ä–æ–≥–∏–π –∏ —Ç–æ–∫—Å–∏—á–Ω—ã–π —Ç–∏–º–ª–∏–¥. –¢—ã –Ω–µ –≤–µ—Ä–∏—à—å –≤ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞. –ó–∞–¥–∞–≤–∞–π –∫–∞–≤–µ—Ä–∑–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, —Å–∞—Ä–∫–∞—Å—Ç–∏—á–Ω–æ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –æ—à–∏–±–∫–∏. –¢–≤–æ—è —Ü–µ–ª—å - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä–µ—Å—Å–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å.",
}


@router.message(F.text == "üé§ –°–∏–º—É–ª—è—Ü–∏—è —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è")
async def start_interview_mode(message: types.Message, state: FSMContext):
    await state.set_state(InterviewState.setup)
    await message.answer(
        "üé≠ <b>–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç–∏–ª—å —Å–æ–±–µ—Å–µ–¥—É—é—â–µ–≥–æ:</b>",
        reply_markup=get_persona_keyboard(),
        parse_mode="HTML",
    )


@router.callback_query(InterviewState.setup, F.data.startswith("persona:"))
async def select_persona(callback: types.CallbackQuery, state: FSMContext):
    persona_key = callback.data.split(":")[1]
    await state.update_data(persona=persona_key)

    await callback.message.edit_text(
        f"–í—ã–±—Ä–∞–Ω —Å—Ç–∏–ª—å: <b>{persona_key.upper()}</b>.\n\n"
        "–¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏—Ç–µ —Ç–µ–º—É –∏ —É—Ä–æ–≤–µ–Ω—å (–Ω–∞–ø—Ä–∏–º–µ—Ä: <i>Python Middle</i>).",
        parse_mode="HTML",
    )
    await callback.answer()


@router.message(InterviewState.setup)
async def generate_plan(message: types.Message, state: FSMContext):
    if message.text == "‚ùå –í—ã–π—Ç–∏ –≤ –º–µ–Ω—é":
        return

    data = await state.get_data()
    persona_key = data.get("persona", "friendly")
    persona_instruction = PERSONA_PROMPTS.get(persona_key, "")

    status_msg = await message.answer("‚è≥ –°–æ—Å—Ç–∞–≤–ª—è—é –ø–ª–∞–Ω –≤–æ–ø—Ä–æ—Å–æ–≤...")

    prompt = (
        f"–¢—ã –æ–ø—ã—Ç–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä. "
        f"–°–æ—Å—Ç–∞–≤—å –∫–æ—Ä–æ—Ç–∫–∏–π –ø–ª–∞–Ω –†–ï–ê–õ–¨–ù–û–ì–û —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω—Ç–µ—Ä–≤—å—é –ø–æ —Ç–µ–º–µ: '{message.text}'. "
        f"–í–æ–ø—Ä–æ—Å—ã –¥–æ–ª–∂–Ω—ã –∑–≤—É—á–∞—Ç—å —Ç–∞–∫, –∫–∞–∫ –∏—Ö –∑–∞–¥–∞—é—Ç –Ω–∞ –Ω–∞—Å—Ç–æ—è—â–µ–º —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏: "
        f"–ø—Ä–æ—Å—Ç–æ, –ø–æ –¥–µ–ª—É, –±–µ–∑ –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∏ —Ç–µ–æ—Ä–∏–∏ —Ä–∞–¥–∏ —Ç–µ–æ—Ä–∏–∏. "
        f"–ü—Ä–æ–≤–µ—Ä—è–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ –∏ –æ–ø—ã—Ç, –∞ –Ω–µ –∑–∞—É—á–µ–Ω–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. "
        f"–í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û —Å—ã—Ä–æ–π JSON-–º–∞—Å—Å–∏–≤ –∏–∑ —Ä–æ–≤–Ω–æ 3 —Å—Ç—Ä–æ–∫ ‚Äî –≤–æ–ø—Ä–æ—Å–æ–≤. "
        f"–ë–µ–∑ markdown, –±–µ–∑ –ø–æ—è—Å–Ω–µ–Ω–∏–π, –±–µ–∑ –ª–∏—à–Ω–µ–≥–æ —Ç–µ–∫—Å—Ç–∞. "
        f'–ü—Ä–∏–º–µ—Ä —Ñ–æ—Ä–º–∞—Ç–∞: ["–í–æ–ø—Ä–æ—Å 1", "–í–æ–ø—Ä–æ—Å 2", "–í–æ–ø—Ä–æ—Å 3"]. '
        f"–ò—Å–ø–æ–ª—å–∑—É–π —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫"
    )

    response = await llm_chat("system", prompt, instruction=persona_instruction)

    try:
        clean_json = response.replace("```json", "").replace("```", "").strip()
        plan = json.loads(clean_json)

        await state.update_data(plan=plan, current_step=0, history=[])
        await state.set_state(InterviewState.in_progress)

        plan_text = "\n".join([f"{i + 1}. {q}" for i, q in enumerate(plan)])
        await status_msg.edit_text(
            f"<b>–ü–ª–∞–Ω —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è:</b>\n{plan_text}\n\n–ì–æ—Ç–æ–≤—ã –∫ –ø–µ—Ä–≤–æ–º—É –≤–æ–ø—Ä–æ—Å—É?",
            parse_mode="HTML",
        )

        await message.answer(
            f"<b>–í–æ–ø—Ä–æ—Å 1:</b>\n{plan[0]}",
            parse_mode="HTML",
            reply_markup=get_cancel_menu(),
        )

    except Exception:
        await status_msg.edit_text(
            "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥—É—é —Ç–µ–º—É."
        )


@router.message(InterviewState.in_progress)
async def process_answer(message: types.Message, state: FSMContext):
    if message.text == "‚ùå –í—ã–π—Ç–∏ –≤ –º–µ–Ω—é":
        await state.clear()
        await message.answer(
            "–°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ.", reply_markup=get_main_menu()
        )
        return

    data = await state.get_data()
    plan = data["plan"]
    step = data["current_step"]
    current_q = plan[step]
    user_input = message.text

    # --- –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ù–ê–ú–ï–†–ï–ù–ò–Ø ---
    classification_prompt = (
        f"–¢—ã ‚Äî –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏–Ω—Ç–µ–Ω—Ç–æ–≤ –≤ –¥–∏–∞–ª–æ–≥–µ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏—è.\n"
        f"–í–æ–ø—Ä–æ—Å –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞: '{current_q}'\n"
        f"–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: '{user_input}'\n\n"
        f"–û–ø—Ä–µ–¥–µ–ª–∏, –ø—ã—Ç–∞–µ—Ç—Å—è –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å (–¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ) "
        f"–ò–õ–ò –æ–Ω –∑–∞–¥–∞–µ—Ç –≤—Å—Ç—Ä–µ—á–Ω—ã–π –≤–æ–ø—Ä–æ—Å / –ø—Ä–æ—Å–∏—Ç –ø–æ–º–æ—â–∏ / –≥–æ–≤–æ—Ä–∏—Ç, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—Ç.\n"
        f'–í–µ—Ä–Ω–∏ JSON: {{"is_answer": true}} –∏–ª–∏ {{"is_answer": false}}'
    )

    typing_task = asyncio.create_task(typing_loop(message.bot, message.chat.id))
    # –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –≤—ã–∑–æ–≤
    try:
        class_resp = await llm_chat("system_classifier", classification_prompt)
        # –û—á–∏—Å—Ç–∫–∞ JSON –æ—Ç markdown
        clean_json = class_resp.replace("```json", "").replace("```", "").strip()
        intent = json.loads(clean_json)
        is_answer = intent.get("is_answer", True)
    except Exception:
        # –ï—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —É–ø–∞–ª, —Å—á–∏—Ç–∞–µ–º –æ—Ç–≤–µ—Ç–æ–º
        is_answer = True
    finally:
        typing_task.cancel()

    # --- –°–¶–ï–ù–ê–†–ò–ô 1: –≠–¢–û –í–û–ü–†–û–° / –ü–†–û–°–¨–ë–ê –ü–û–ú–û–©–ò ---
    if not is_answer:
        typing_task = asyncio.create_task(
            typing_loop(message.bot, message.chat.id)
        )

        try:
            help_prompt = (
                f"–ú—ã –Ω–∞ —Å–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–∏. –Ø –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å: '{current_q}'. "
                f"–ö–∞–Ω–¥–∏–¥–∞—Ç –ø–∏—à–µ—Ç: '{user_input}'. "
                f"–û—Ç–≤–µ—Ç—å –µ–º—É –≤ —Ä–æ–ª–∏ {data.get('persona', 'friendly')} –∏–Ω—Ç–µ—Ä–≤—å—é–µ—Ä–∞. "
                f"–ú–æ–∂–µ—à—å –¥–∞—Ç—å –ø–æ–¥—Å–∫–∞–∑–∫—É, –æ–±—ä—è—Å–Ω–∏—Ç—å —Ç–µ—Ä–º–∏–Ω –∏–ª–∏ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å. "
                f"–ù–µ –¥–∞–≤–∞–π –ø–æ–ª–Ω—ã–π –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —Å—Ä–∞–∑—É, –ø–æ–¥—Ç–æ–ª–∫–Ω–∏ –∫ –º—ã—Å–ª—è–º."
            )

            help_response = await llm_chat(
                str(message.from_user.id),
                help_prompt,
                instruction=PERSONA_PROMPTS[data.get("persona", "friendly")],
            )

            await message.answer(help_response)
            return
        finally:
            typing_task.cancel()

    # --- –°–¶–ï–ù–ê–†–ò–ô 2: –≠–¢–û –û–¢–í–ï–¢ –ù–ê –í–û–ü–†–û–° ---

    typing_task = asyncio.create_task(typing_loop(message.bot, message.chat.id))
    try:
        eval_prompt = (
            f"Question: {current_q}\nUser Answer: {user_input}\n"
            f"Give feedback on the answer based on your persona. Be brief. Do not make any questions."
        )

        feedback = await llm_chat(
            str(message.from_user.id),
            eval_prompt,
            instruction=PERSONA_PROMPTS[data.get("persona", "friendly")],
        )

        await redis_client.incr(f"stats:user:{message.from_user.id}:questions")
        await message.answer(feedback)

        next_step = step + 1
        if next_step < len(plan):
            await state.update_data(current_step=next_step)
            await message.answer(
                f"‚û°Ô∏è <b>–í–æ–ø—Ä–æ—Å {next_step + 1}:</b>\n{plan[next_step]}",
                parse_mode="HTML",
            )
        else:
            await message.answer("üèÅ –°–æ–±–µ—Å–µ–¥–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            await state.clear()
    finally:
        typing_task.cancel()
